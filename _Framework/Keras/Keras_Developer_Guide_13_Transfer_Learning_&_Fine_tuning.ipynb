{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_Developer_Guide_13_Transfer_Learning_&_Fine-tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNHXgjRwSeOOhw+ABHJuneS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inyong37/Study/blob/master/_Framework/Keras/Keras_Developer_Guide_13_Transfer_Learning_%26_Fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6L8AWfRKyi3v"
      },
      "outputs": [],
      "source": [
        "# Title: Keras Developer Guide - Transfer Learning & Fine-tuning\n",
        "# Re-Author: Inyong Hwang\n",
        "# Date: 2021-12-30-Thu.\n",
        "# Reference: https://keras.io/guides/\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "'''\n",
        "# Introduction\n",
        "The most common incarnation of transfer learning in the context of deep learning is the following workflow:\n",
        "1. Take layers from a previously trained model.\n",
        "2. Freeze them, so as to avoid destroying any of the information they contain during future training rounds.\n",
        "3. Add some new, trainable layers on top of the frozen layers. They will learn to turn the old features into predictions on a new dataset.\n",
        "4. Train the new layers on your dataset.\n",
        "\n",
        "A last, optional step, is fine-tuning, which consists of unfreezing the entire model you obtained above (or part of it), and re-training it on the new data with a very low learning rate.\n",
        "This can potentially achieve meaningful improvements, by incrementally adapting the pretrained features to the new data.\n",
        "'''\n",
        "\n",
        "# Freezing layers: understanding the trainable attribute\n",
        "layer = keras.layers.Dense(3)\n",
        "layer.build((None, 4)) # Create the weights\n",
        "\n",
        "print('weights:', len(layer.weights))\n",
        "print('trainable_weights:', len(layer.trainable_weights))\n",
        "print('non_trainable_weights:', len(layer.non_trainable_weights))"
      ]
    }
  ]
}
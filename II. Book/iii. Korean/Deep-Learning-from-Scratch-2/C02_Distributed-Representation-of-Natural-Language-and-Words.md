# Chapter 2. Distributed Representation of Natural Language and Words

컴퓨터가 우리의 말을 알아듣게(이해하게) 만드는 것

고전적인 기법(딥러닝 등장 이전의 기법)

딥러닝(신경망) 기반 기법들

파이썬으로 텍스트를 다루는 연습, 텍스트를 단어로 분할하는 처리, 단어를 단어 ID로 변환하는 처리 등을 구현

## 2.1. 자연어 처리란

평소에 쓰는 말을 자연어(natural language), 우리의 말을 컴퓨터에게 이해시키기 위한 기술(분야), 사람의 말을 컴퓨터가 이해하도록 만들어서, 컴퓨터가 우리에게 도움이 되는 일을 수행하게 하는 것

프로그래밍 언어, 마크업 언어, 모든 코드의 의미를 고유하게 해석할 수 있도록 문법이 정의, 컴퓨터는 이 정해진 규칙에 따라서 코드를 해석

일반적인 프로그래밍 언어는 기계적, 고정, 딱딱한 언어, 자연어는 부드러운 언어, 똑같은 의미의 문장도 여러 형태로 표현할 수 있다거나, 문장의 뜻이 애매할 수 있다거나, 그 의미나 형태가 유연하게 바뀐다는 뜻, 세월이 흐르면서 새로운 말이나 새로운 의미가 생겨나거나 있던 것이 사라짐

자연어는 살아 있는 언어, 부드러움, 검색 엔진이나 기계 번역, 질의응답 시스템, IME(입력기 전환), 문장 자동요약과 감정분석 등

### 2.1.1. 단어의 의미

말은 문자로 구성되며, 말의 의미는 단어로 구성, 단어는 의미의 최소 단위, 자연어를 컴퓨터에게 이해시키는 데는 무엇보다 단어의 의미를 이해시키는 게 중요

컴퓨터에게 단어의 의미 이해시키기, 단어의 의미를 잘 파악하는 표현 방법

- 시소러스를 활용한 기법 (이전 장)
- 통계 기반 기법 (이번 장)
- 추론 기반 기법(word2vec) (다음 장)

사람 손으로 만든 시소러스(thesaurus, 유의어 사전)를 이용하는 방법, 통계 정보로부터 단어를 표현하는 통계 기반 기법, 신경망을 활용한 추론 기반 기법(구체적으로는 word2vec)

## 2.2. 시소러스

단어의 의미를 나타내는 방법으로는 먼저 사람이 직접 단어의 의미를 정의하는 방식을 생각, 그중 한 방법으로는 표준국어대사전처럼 각각의 단어에 그 의미를 설명해 넣을 수 있을 것

자연어 처리의 역사를 되돌아보면 단어의 의미를 인력을 동원해 정의하려는 시도는 수없이 있어왔음, 단, 표준국어대사전 같이 사람이 이용하는 일반적인 사전이 아니라 시소러스 형태의 사전을 애용함, 시소러스란 (기본적으로는) 유의어 사전으로, '뜻이 같은 단어(동의어)'나 '뜻이 비슷한 단어(유의어)'가 한 그룹으로 분류

또한 자연어 처리에 이용되는 시소러스에서는 단어 사이의 '상위와 하위' 혹은 '전체와 부분' 등, 더 세세한 관계까지 정의해둔 경우가 있음. 각 단어의 관계를 그래프 구조로 정의

모든 단어에 대한 유의어 집합을 만든 다음, 단어들의 관계를 그래프로 표현하여 단어 사이의 연결을 정의할 수 있음. 그러면 이 '단어 네트워크'를 이용하여 컴퓨터에게 단어 사이의 관계를 가르칠 수 있음. 이 정도면 컴퓨터에게 단어의 의므를 (간접적으로라도) 이해시켰다고 주장할 수 있을 것.

:bulb: 시소러스를 어떻게 사용하는가는 자언어 처리 애플리케이션에 따라 다름.

### 2.2.1. WordNet

자연어 처리 분야에서 가장 유명한 시소러스는 'WordNet'. WordNet은 프린스턴 대학교에서 1085년부터 구축하기 시작한 전통 있는 시소러스. 많은 연구와 다양한 자연어 처리 애플리케이션에서 활용.

WordNet을 사용하면 유의어를 얻거나 '단어 네트워크'를 이용할 수 있음. 또한 단어 네트워크를 사용해 단어 사이의 유사도를 구할 수도 있음. '부록 B. WordNet 맛보기'. WordNet(정확하게는 NLTK 모듈)

:bulb: 실제로 WordNet을 사용하여 단어의 유사도를 구하는 실험. 사람이 직접 정의한 '단어 네트워크'를 기초로 단어 사이의 유사도를 구하는 사례, 단어의 유사도를 (어느 정도 정확하게) 구할 수 있다면 '단어의 의미'를 이해하는 첫걸음을 내디뎠다고 말할 수 있을 것.

### 2.2.2. 시소러스의 문제점

사람이 수작업으로 레이블링하는 방식에는 크나큰 결점이 존재

- 시대 변화에 대응하기 어렵다.

때때로 새로운 단어가 생겨나고, 옛말은 언젠가 잊혀짐.

시대에 따라 언어의 의미가 변하기도 함. 이런 단어의 변화에 대응하려면 시소러스를 사람이 수작업으로 끊임없이 갱신해야 함.

- 사람을 쓰는 비용은 크다.

시소러스를 만드는 데는 엄청난 인적 비용이 발생. 현존하는 영어 단어의 수는 1,000만 개가 넘음. 이상적으로는 이 방대한 단어들 모두에 대해 단어 사이의 관계를 정의해줘야 함. WordNet에 등록된 단어는 20만 개 이상.

- 단어의 미묘한 차이를 표현할 수 없다.

시소러스에서는 뜻이 비슷한 단어들을 묶음. 그러나 실제로 비슷한 단어들이라도 미묘한 차이가 있는 법.

시소러스를 활용하는 기법(단어의 의미를 사람이 정의하는 기법)에는 문제가 있음. 이 문제를 피하기 위해, '통계 기반 기법'과 신경망을 사용한 '추론 기반 기법'을 알아볼 것. 이 두 기법에서는 대량의 텍스트 데이터로부터 '단어의 의미'를 자동으로 추출. 그 덕분에 사람은 손수 단어를 연결짓는 중노동에서 해방.

:bulb: 자연어 처리뿐 아니라, 이미지 인식에서도 특징(feature)을 사람이 수동으로 설계하는 일이 오랜 세월 계속됨. 그러다가 딥러닝이 실용화되면서 실생활 이미지로부터 원하는 결과를 곧바로 얻을 수 있게 됨. 사람이 개입할 필요가 현격히 줄어든 것. 즉, 사람의 개입을 최소로 줄이고 텍스트 데이터만으로 원하는 결과를 얻어내는 방향으로 패러다임이 바뀜.

## 2.3. 통계 기반 기법

말뭉치(corpus)를 이용. 말뭉치란 간단히 말하면 대량의 텍스트 데이터. 다만 맹목적으로 수집된 텍스트 데이터가 아닌 자연어 처리 연구나 애플리케이션을 염두에 두고 수집된 텍스트 데이터르 일반적으로 '말뭉치'라고 함.

결국 말뭉치란 텍스트 데이터, 그 안에 담긴 문장들은 사람이 쓴 글. 말뭉치에는 자연어에 대한 사람의 '지식'이 충분히 담겨 있다고 볼 수 있음. 문장을 쓰는 방법, 단어를 선택하는 방법, 단어의 의미 등 사람이 알고 있는 자연어에 대한 지식이 포함되어 있음. 통계 기반 기법의 목표는 이처럼 사람의 지식으로 가득한 말뭉치에서 자동으로, 효율적으로 그 핵심을 추출하는 것.

:bulb: 자연어 처리에 사용되는 말뭉치에는 텍스트 데이터에 대한 추가 정보가 포함되는 경우가 있음. 텍스트 데이터의 단어 각각에 '품사'가 레이블링될 수 있음. 이럴 경우 말뭉치는 컴퓨터가 다루기 쉬운 형태(트리 구조 등)로 가공되어 주어지는 것이 일반적임. 이 책에서는 이러한 추가 레이블을 이용하지 않고, 단순한 텍스트 데이터(하나의 큰 텍스트 파일)로 주어졌다고 가정.

### 2.3.1. 파이썬으로 말뭉치 전처리하기

자연어 처리에는 다양한 말뭉치가 사용됨. 위키백과(Wikipedia)와 구글 뉴스(Google News) 등의 텍스트 데이터. 셰익스피어나 나쓰메 소세키 같은 작품들도 말뭉치로 이용됨. 우선 문장 하나로 이뤄진 단순한 텍스트를 사용함. 

파이썬의 대화 모드를 이용하여 매우 작은 텍스트 데이터(말뭉치)에 전처리(preprocessing). 전처리란 텍스트 데이터를 단어로 분할하고 그 분할된 단어들을 단어 ID 목록으로 변환하는 일.

```Python
>>> text = 'You say goodby and I say hello.'
```

쉽게 설명하기 위해 작은 텍스트 데이터만으로 전처리를 수행함. 이 text를 단어 단위로 분할함.

```Python
>>> text = text.lower()
>>> text = text.replace('.', ' .')
>>> text
'you say goodby and i say hello .'
>>> words = text.split(' ')
>>> words
['you', 'say', 'goodby', 'and', 'i', 'say', 'hello', '.']
```

lower() 메서드를 사용해 모든 문자를 소문자로 변환. 문장 첫머리의 대문자로 시작하는 단어도 소문자 단어와 똑같이 취급하기 위한 조치. 그리고 split(' ') 메서드를 호출해 공백을 기준으로 분할. 문장 끝의 마침표(.)를 고려해 마침표 앞에 공백을 삽입한 다음 분할을 수행.

### 2.3.2. 단어의 분산 표현

:bulb: 단어를 분할할 때 마침표 앞에 공백을 넣는 임시변통을 적용, 범용적인 방법. '정규표헌식(regular expression)'을 이용하는 방법. 정규표현식 모듈인 re를 임포트하고 re.split('(\W+)?'.text)라고 호출하면 단어 단위로 분할할 수 있음.

원래 문장을 단어 목록 형태로 이용할 수 있게 됨. 단어 단위로 분할되어 다루기가 쉬워졌지만, 단어를 텍스트 그대로 조작하기란 불편. 단어에 ID를 부여하고, ID의 리스트로 이용할 수 있도록 한 번 더 손질. 파이썬의 딕셔너리를 이용하여 단어 ID와 단어를 짝지어주는 대응표를 작성.

```Python

```

### 2.3.3. 분포 가설

### 2.3.4. 동시발생 행렬

### 2.3.5. 벡터 간 유사도

### 2.3.6. 유사 단어의 랭킹 표시

## 2.4. 통계 기반 기법 개선하기

### 2.4.1. 상호정보량

### 2.4.2. 차원 감소

### 2.4.3. SVD에 의한 차원 감소

### 2.4.4. PTB 데이터셋

### 2.4.5. PTB 데이터셋 평가

## 2.5. 정리

# Chapter 1. 소개

패턴 인식은 컴퓨터 알고리즘을 활용하여 데이터의 규칙성을 자동적으로 찾아내고, 이 규칙성을 이용하여 데이터를 각각의 카테고리로 분류하는 등의 일을 하는 분야다.

training set -> target vector

training phase ~ learning phase

test set

generalization

preprocessed or feature extraction or dimensionality reduction

supervised learning:
- classification
- regression

unsupervised learning:
- clustering
- density estimation
- visualization

reinforcement learning: 
- credit assignment
- exploration <-> exploitation; trade off

## 1.1. 예시: 다항식 곡선 피팅

order

error function

model comparison or model selection

over-fitting

root mean square error, RMS error

maximum likelihood

Bayesian

regularization

shrinkage method

quadratic - ridge regression

weight decay

training set, validation set, hold-out set

## 1.2. 확률론

확률의 두 가지 기본 법칙은 바로 합의 법칙(sum rule)과 곱의 법칙(product rule)이다.

X와 Y라는 두 가지 확률 변수가 있다. X는 xi(i=1, ..., M) 중 아무 값이나 취할 수 있고, Y는 yi(i=1, ..., L) 중 아무 값이나 취할 수 있다고 하자. 또한, X와 Y 각각에서 표본을 추출하는 시도를 N번 한다고 하자. 그리고 X=xi, Y=yi인 시도의 개수를 nij라 표현하자. 그리고 Y의 값과는 상관없이 X=xi인 시도의 숫자를 ci, X의 값과는 상관없이 Y=yi인 시도의 숫자를 rj로 표현할 것이다.

X가 xi, Y가 yj일 확률을 p(X=xi, Y=yj)로 적고 이를 X=xi, Y=yj일 결합 확률(joint probability)이라 칭한다. 이는 i, j칸에 있는 포인트의 숫자를 전체 포인트들의 숫자로 나눠서 구할 수 있다. 따라서 다음의 식 1.5와 같이 표현된다.

p(X=xi, Y=yj) = nij/N ... (식 1.5)

여기서 lim N->inf를 가정하였다. 비슷하게 Y값과 무관하게 X가 xi값을 가질 확률을 p(X=xi)로 적을 수 있다. 이는 i열에 있는 포인트들의 숫자를 전체 포인트들의 숫자로 나눔으로써 구할 수 있다.

p(X=xi) = ci/N ... (식 1.6)

이는 ci = sum j (nij)로 표현 가능하다. 따라서 식 1.5와 식 1.6을 바탕으로 다음을 도출해 낼 수 있다.

p(X=xi) = sum j=1~L (pX=xi, Y=yj) ... (식 1.7)

이것이 바로 확률의 합의 법칙(sum rule)이다. 때때로 p(X=xi)는 주변 확률(marginal probability)이라고 불린다.

X=xi인 사례들만 고려해 보자. 그들 중에서 Y=yj인 사례들의 비율을 생각해 볼 수 있고, 이를 확률 p(Y=yj|X=xi)로 적을 수 있다. 이를 조건부 확률(conditional probability)이라고 부른다. 이 경우엔 X=xi가 주어졌을 경우 Y=yj일 조건부 확률이다. 이 확률은 i행에 있는 전체 포인트 수와 i, j칸에 있는 포인트 수의 비율을 통해서 계산할 수 있다.

p(Y=yj|X=xi) = nij/ci ... (식 1.8)

식 1.5, 식 1.6, 식 1.8에서 다음의 관계를 도출해 낼 수 있다.

p(X=xi, Y=yj) = nij/N = nij/ci * ci/N = p(Y=yj|X=xi)p(X=xi) ... (식 1.9)

이것이 바로 확률의 곱의 법칙(product rule)이다.

간단한 표현법을 사용해서 확률의 두 가지 기본 법칙을 다음과 같이 적을 수 있다.

확률의 법칙

합의 법칙 p(X) = sum Y p(X, Y) ... (식 1.10)

곱의 법칙 p(X, Y) = p(Y|X)(X) ... (식 1.11)

여기서 p(X, Y)는 결합 확률인데 'X와 Y의 확률'이라고 읽으면 된다. 조건부 확률 p(Y|X)는 'X가 주어졌을 경우 Y의 확률'이라고 읽을 수 있다. p(X)는 주변 확률이며, 'X의 확률'이라고 읽으면 된다. 이 두 법칙은 이 책 전반에서 사용할 확률과 관련된 내용의 기본 토대가 된다.

곱의 법칙과 대칭성 p(X, Y)=P(Y, X)로부터 조건부 확률 간의 관계인 다음 식을 도출해 낼 수 있다.

p(Y|X) = p(X|Y)p(Y) / p(X) ... (식 1.12)

이 식 1.12가 머신 러닝과 패턴 인식 전반에 걸쳐서 아주 중요한 역할을 차지하고 있는 베이즈 정리(Bayes' theorem)다. 합의 법칙을 사용해서 베이지안 정리의 분모를 분자에 있는 항들로 표현할 수 있다.

p(X) = sum Y p(X|Y)p(Y) ... (식 1.13)

베이지안 정리의 분모는 정규화 상수로 볼 수 있다. 식 1.12의 왼쪽 항을 모든 Y 값에 대하여 합했을 때 1이 되도록 하는 역할인 것이다.

만약 어떤 과일이 선택되었는지를 알기 전에 어떤 박스를 선택했냐고 묻는다면 그 확률은 p(B)일 것이다. 이를 사전 확률(prior probability)이라고 부른다. 왜냐하면 어떤 과일이 선택되었는지 관찰하기 '전'의 확률이기 때문이다. 선택된 과일이 오렌지라는 것을 알게 된다면 베이지안 정리를 활용하여 p(B|F)를 구할 수 있다. 이는 사후 확률(posterior probability)이라고 부를 수 있는데, 그 이유는 사건 F를 관측한 '후'의 확률이라 그렇다.

p(X, Y) = p(X)p(Y)인 경우를 고려해 보자. 이처럼 각각의 주변 확률을 곱한 것이 결합 확률과 같을 경우 두 확률 변수를 독립적(independent)이라고 한다. 곱의 법칙에 따라 p(Y|X)=p(Y)임을 알 수 있고 따라서 X가 주어졌을 때 Y의 조건부 확률은 실제로 X의 값과 독립적임을 확인할 수 있다. 이를 우리의 과일 상자 예시에 적용해 보자. 만약에 각각의 상자가 같은 수의 사과와 오렌지를 가지고 있다면 p(F|B)=P(F)가 된다. 즉, 사과(또는 오렌지)를 고를 확률은 어떤 상자를 골랐는지와는 독립적이 된다는 것이다.

### 1.2.1. 확률 밀도

연속적인 변수에서의 확률에 대해 알아보도록 하자. 만약 실수 변수 x가 (x, x+sx) 구간 안의 값을 가지고 그 변수의 확률이 p(x)sx(sx->0일 경우)로 주어진다면, p(x)를 x의 확률 밀도(probability density)라고 부른다. 이때 x가 (a, b)구간 사이의 값을 가질 확률은 다음과 같이 주어진다.

p(x in (a, b)) = integral a~b p(x)dx ... (식 1.24)

확률은 양의 값을 가지고 x의 값은 실수축상에 존재해야 한다. 따라서 확률 밀도 함수 p(x)는 다음의 두 조건을 만족시켜야 한다.

p(x) >= 0 ... (식 1.29)

integral p(x)dx = 1 ... (식 1.30)

위의 식에서 적분은 전체 x공간에 대해 시행했다. 이산 변수와 연속 변수가 조합된 경우에 대해서도 결합 확률 분포를 고려하는 것이 가능하다.

만약 x가 이산 변수일 경우 p(x)를 때때로 확률 질량 함수(probability mass function)라고 부르기도 한다. 각 x 값에 대해서 몇몇 확률 질량들이 모여 있는 것으로 볼 수 있기 때문이다.

연속 변수의 확률 밀도와 이산 변수/연속 변수가 조합된 경우의 확률 밀도에도 합의 법칙, 곱의 법칙, 베이지안 정리를 적용할 수 있다. 예를 들어 만약 x와 y가 각각 실수와 변수일 경우, 합과 곱의 법칙은 다음의 형태를 띤다. 

p(x) = integral p(x, y)dy ... (식 1.31)

p(x, y) = p(y|x)p(x) ... (식 1.32)

연속 변수의 합과 곱의 법칙에 대해서 정식으로 정의를 내리기 위해서는 수학의 한 분야인 측도 이론(measure theory)에 대해 살펴봐야 한다. 측도 이론에서는 각각의 실수 변수를 폭 delta인 범위들로 쪼개고 각각의 범위를 이산 확률 분포로 간주한다. 여기서 limit delta->0을 취하고 합을 적분으로 바꾸면 우리가 우너하는 결과를 얻게 된다. 

### 1.2.2. 기댓값과 공분산

### 1.2.3. 베이지안 확률

확률을 '반복 가능한 임의의 사건의 빈도수'라는 측면에서 살펴보았다. 이러한 해석을 고전적(classical) 또는 빈도적(frequentist) 관점이라 일컫는다. 이보다 더 포괄적인 베이지안(Bayesian) 관점에 대해서 살펴보도록 하자. 베이지안 관점을 이용하면 확률을 이용해서 불확실성을 정량화하는 것이 가능하다.

우리는 주어진 불확실성을 정량화할 수 있다. 그리고 새 증거가 주어질 때마다 불확실성을 수정하고 그 결과에 따라 최적의 선택을 내리고 싶을 것이다. 이 모든 것을 가능하게 해주는 일반적인 방법론이 바로 확률의 베이지안 해석이다.

불확실성을 나타내는 도구로써의 확률은 임의적으로 선택된 것이 아니다. 상식을 바탕으로 이성적으로 추론한다면 확률을 사용하는 것이 피할 수 없는 선택이라는 것을 알 수 있다. 

확률에 대한 개념을 더 일반적으로 확장하는 것은 패턴 인식 분야에서도 큰 도움이 된다.

베이지안 정리는 관측값들을 이용하여 사전 확률을 사후 확률로 바꾸는 역할을 했다. 다항식 곡선 피팅 예시의 매개변수 w와 같은 값들을 추론해 내는 데 있어서도 비슷한 방식을 사용할 수가 있다. 일단, 첫 번째로 데이터를 관측하기 전의 w에 대한 우리의 가정을 사전 확률 분포 p(w)로 표현할 수 있다. 관측된 데이터 D={t1, ..., tn}은 조건부 확률 p(D|w)로써 작용하게 된다. 이 경우 베이지안 정리는 다음의 형태를 띤다.

p(w|D) = p(D|w)p(w)/p(D) ... (식 1.43)

D를 관측한 후의 w에 대한 불확실성을 사후 확률 p(w|D)로 표현한 것이다.

베이지안 정리의 오른쪽에 있는 값 p(D|w)는 관측 데이터 집합 D를 바탕으로 계산된다. 이 값은 매개변수 벡터 w의 함수로 볼 수 있으며, 가능도 함수(likelihood function)라고 불린다. 가능도 함수는 각각의 다른 매개변수 벡터 w에 대해 관측된 데이터 집합이 얼마나 '그렇게 나타날 가능성이 있었는지'를 표현한다. 가능도 함수는 w에 대한 확률 분포가 아니며, 따라서 w에 대해 가능도 함수를 적분하여도 1이 될 필요가 없다.

가능도 함수에 대한 정의를 바탕으로 베이지안 정리를 다음처럼 적을 수가 있다.

사후 확률 ~ 가능도 X 사전 확률 ... (식 1.44)

식 1.44의 각 값은 전부 w에 대한 함수다. 식 1.43 오른쪽 변의 분모는 식 왼쪽 변의 사후 분포가 적법한 확률 분포가 되고 적분값이 1이 되도록 하기 위한 정규화 상수다. 식 1.43의 양쪽 변을 w에 대해 적분하면 베이지안 정리의 분모를 사전 확률과 가능도 함수로 표현할 수 있다.

p(D) = integral p(D|w)p(w)dw ... (식 1.45)

가능도 함수 p(D|w)는 베이지안 확률 관점과 빈도적 확률 관점 양측에서 굉장히 중요한 역할을 차지한다. 하지만 가능도 함수가 사용되는 방식은 양 접근법에서 근본적으로 다르다. 빈도적 확률 관점에서는 w가 고정된 매개변수로 여겨지며, 그 값은 어떤 형태의 '추정값'을 통해서 결정된다. 그리고 추정에서의 오류는 가능한 데이터 집합들 D의 분포를 고려함으로써 구할 수 있다. 이외는 대조적으로 베이지안 확률 관점에서는 오직 하나의 (실제로 관측된) 데이터 집합 D만이 존재하고 매개변수의 불확실성은 w의 확률 분포를 통해 표현된다.

빈도적 확률 관점에서 널리 사용되는 추정값 중 하나는 바로 최대 가능도(maximum likelihood)다. 최대 가능도를 사용할 경우에 w는 가능도 함수 p(D|w)를 최대화하는 값으로 선택된다. 머신 러닝 문헌에서는 종종 음의 로그 가능도 함숫값을 오차 함수(error function)라고 일컫는다. 음의 로그 함수는 단조 감소하는 함수이기 때문에 가능도의 최댓값을 찾는 것이 오차를 최소화하는 것과 동일하다.

빈도적 확률론자들이 오차를 측정하는 방법 중에 하나가 바로 부트스트랩(bootstrap) 방법이다. 부트스트랩 방법에서는 다음과 같은 방식으로 여러 데이터 집합을 만든다. 원 데이터 집합이 N개의 데이터 포인트 X={x1, ..., xN}라고 가정해 보자. X에서 N개의 데이터 포인트를 임의로 추출하여 데이터 집합 XB를 만드는데, 이때 한번 추출된 값도 다시 추출 대상으로 고려될 수 있도록 하는 방식을 사용할 것이다. 즉, X의 어떤 값들은 XB에 중복될 수 있는 반면, 어떤 값들은 XB에 포함되지 않을 수도 있다는 것이다. 이 과정을 L번 반복하면 원래 데이터 집합의 표본에 해당하는 크기 N의 데이터 집합 L개를 만들 수 있다. 각각의 부트스트랩 데이터 집합에서의 예측치와 실제 매개변수 값과의 차이를 바탕으로 매개변수 추정값의 통계적 정확도를 판단할 수 있다.

베이지안 관점의 장점 중 하나는 사전 지식을 추론 과정에 자연스럽게 포함시킬 수가 있다는 것이다. 예를 들어 멀쩡하게 생긴 동전 하나를 세 번 던졌는데, 세 번 다 앞면이 나왔다고 해보자. 고전적인 최대 가능도 추정을 통해 추론한다면 앞으로는 앞면이 나올 확률이 1일 것이다. 미래의 모든 동전 던지기에서 앞면만 나올 것이라고 예측한다는 말이다. 대조적으로 베이지안적으로 접근할 경우 적당히 합리적인 사전 확률을 사용한다면 이렇게까지 과도한 결론이 나오지는 않을 것이다.

빈도적 확률 관점과 베이지안 확률 관점 중 어떤 것이 더 상대적으로 우수한지에 대해서는 끊임없는 논쟁이 있었다. 물론, 어떠한 확률론자도 하나의 관점을 전적으로 받아들이지는 않는다. 베이지안 접근법에 대해 널리 알려진 비판 중 하나는 사전 분포가 실제 사전의 믿음을 반영하기보다는 수학적인 편리성을 위해서 선택된다는 것이다. 베이지안 관점에서는 사전 확률의 선택에 따라 결론이 나기 때문에 추론 과정에 주관이 포함될 수밖에 없다. 이 때문에 적절한 사전 확률을 선택하는 것이 어려운 경우도 있다. 사전 분포에 대해 의존도를 낮추기 위해 무정보적(noninformative) 사전 분포를 사용하는 경우도 있다. 하지만 이는 서로 다른 모델들을 비교하는 것을 어렵게 만든다. 그리고 실제로 좋지 않은 사전 분포를 바탕으로 한 베이지안 방법은 부족한 결과물을 높은 확신으로 내놓기도 한다. 빈도적 확률론자들의 평가 방법이 때때로 이런 문제들에 대한 해결책이 된다. 교차 검증법(cross validation)과 같은 테크닉은 모델 비교 등의 분야에서 유요하게 쓰이고 있다.

베이지안 방법론은 지난 수년간 실용적인 측면에서 그 중요도를 키워왔다. 이 책은 베이지안 관점에 매우 큰 가중치를 두고 있지만, 필요할 경우에는 유용한 빈도적 확률론의 콘셉트에 대해서도 논의할 것이다.

베이지안 방법론의 토대는 18세기에 만들어졌다. 하지만 실제적으로 베이지안 방법론을 활용하는 데 있어서는 오랫동안 많은 제약이 있었다. 그 제약 중 하나는 바로 베이지안 절차를 완전히 활용하기 위해서는 전체 매개변수 공간에 대한 주변화(합산 또는 적분)를 하는 과정이 필요하다는 것이다. 예측치를 계산하거나 서로 다른 모델들을 비교하는 데 있어서 이 과정이 필요하기 때문이다. 마르코프 연쇄나 몬테 카를로 등의 표본 추출 방법이 개발되고, 컴퓨터의 연산 속도와 메모리 용량이 크게 개선됨에 따라 다양한 분야에서 베이지안 테크닉을 실제로 사용할 수 있게 되었다. 몬테 카를로 방법론은 아주 유연하며, 다양한 범위의 모델에 적용할 수 있다. 하지만 이 몬테 카를로 방법을 활용하기 위해서는 고도의 계산이 많이 필요하다. 그래서 이 방법은 주로 작은 규모의 문제들에 대해서만 사용되어 왔다.

더 최근에는 변분적 베이지안, 기대 전파법 등의 효율적인 결정론적 근사 방법들이 개발되었다. 이를 바탕으로 더 큰 규모의 문제들에 베이지안 테크닉을 사용할 수 있게 되었다.

### 1.2.4. 가우시안 분포

normal distribution = Gaussian distribution

### 1.2.5. 곡선 피팅

### 1.2.6. 베이지안 곡선 피팅

## 1.3. 모델 선택

최소 제곱법을 이용한 다항식 곡선 피팅의 예시처럼 가장 좋은 일반화값을 주는 최적의 다항식 차수가 있다는 것을 확인할 수 있었다. 다항식의 차수에 따라서 모델의 자유 매개변수의 수가 결정되며, 이에 의해서 모델의 복잡도가 결정된다. 또한, 정규화된 최소 제곱법의 경우에는 정규화 계수 λ도 모델의 실제적인 복잡도에 영향을 미쳤다. 혼합 분포나 뉴럴 네트워크 등의 더 복잡한 모델의 경우에는 복잡도를 통제하는 매개변수가 더 많을지도 모른다. 실제 응용 사례에서는 이러한 매개변수들의 값을 결정해야 하며, 이때의 목표는 보통 새로운 데이터에 대한 예측 성능을 최적화하는 것이다. 주어진 한 모델의 매개변수의 값을 결정하는 것뿐만이 아니라 다양한 여러 모델들을 고려하여 해당 응용 사례에 가장 적합한 모델을 선택해야 할 경우도 있다.

최대 가능도 접근법에서 이미 확인한 것과 같이 훈련 집합에서의 좋은 성능이 반드시 좋은 예측 성능을 보장해 주지는 못한다. 이는 과적합 문제 때문이다. 이를 해결할 한 가지 방법은 데이터가 충분할 경우 일부의 데이터만 사용하여 다양한 모델과 모델의 매개변수들을 훈련시키고 독립적인 데이터 집한인 검증 집합(validation set)에서 이 모델들과 매개변수들을 비교/선택하는 것이다. 만약 한정된 크기의 데이터 집합을 바탕으로 반복적으로 모델 디자인을 시행하면, 검증 집합에 대해서도 과적합 문제가 발생할 수 있다. 이런 경우에는 세 번째의 시험 집합(test set)을 따로 분리해 두고 이 잡합을 통해서 선택된 모델의 최종 성능을 판단하는 것이 좋을 수도 있다. 

하지만 대부분의 실제 경우에는 훈련과 시험을 위한 데이터의 공급이 제한적이다. 이런 상황에서 좋은 모델을 만들기 위해서는 가능한 한 많은 데이터를 활용하여 모델을 훈련시키는 것이 좋다. 하지만 검증 집합의 크기가 작을 경우는 예측 성능에 대한 추정값이 정확하지 않을 수도 있다. 이런 딜레마를 해결할 수 있는 한 가지 방법은 바로 교차 검증법(cross validation)이다. 교차 검증법을 활용하면 전체 데이터(S) 중 데이터의 (S-1)/S 비율만큼 훈련에 사용하고, 모든 데이터를 다 활용하여 성능을 추정할 수 있다. 특히 데이터가 부족할 경우에는 S=N의 교차 검증법을 고려할 수도 있다. 여기서 N은 전체 데이터 포인트의 숫자다. 따라서 S=N 교차 검증법은 데이터 포인트 하나만 남겨 두고(leave-one-out) 모델을 훈련시키는 테크닉이다.

교차 검증법의 주요 단점 하나는 S으 수가 늘어남에 따라서 모델 훈련의 시행 횟수가 함께 늘어난다는 것이다. 이는 훈련 자체가 계산적으로 복잡할 경우에 문제가 될 수 있다. 분리된 데이터를 활용하여 성능을 측정하는 교차 검증법과 같은 방식의 또 다른 문제점은, 한 가지 모델에 여러 가지 복잡도 매개변수가 있을 경우(예를 들면 여러 종류의 정규화 매개변수)에 발생한다. 여러 매개변수들의 조합들을 확인해 보기 위해서는 최악의 경우 매개변수 숫자에 대해 기하급수적인 수의 훈련 실행이 필요할지도 모른다. 덕분에 확실히 이보다 더 나은 방식이 필요하다는 것을 알 수 있다. 이상적인 방식에서는 훈련 집합만을 활용해서 여러 종류의 초 매개변수와 각 모델 종류에 대한 비교를 한 번의 훈련 과정동안 시행할 수 있어야 한다. 이를 위해서는 오직 훈련 집합만을 활용하는 성능 척도가 필요하다. 또한, 이 척도는 과적합으로 인한 편향으로부터 자유로워야 한다.

역사적으로 다양한 '정보 기준(information criteria)'들이 최대 가능도 방법의 편향 문제에 대한 대안으로 제시되어 왔다. 이는 더 복잡한 모델에서 과적합이 일어나지 않도록 하는 페널티항을 추가하는 방식이었다. 예를 들어서 아카이케의 정보량 기준(akaike information criterition, AIC)은 다음의 식 1.73의 값이 가장 큰 모델을 선택하는 방식이다.

ln p(D|wML) - M ... (식 1.73)

여기서 p(D|wML)은 가장 잘 피팅된 로그 가능도이며, M은 모델의 수정 가능한 매개변수의 숫자다. 베이지안 정보 기준(Bayesian information criterion, BIC)은 AIC의 약간 변형된 버전이다. 이러한 기준들은 모델 매개변수들의 불확실성을 고려하지 않으며, 또한 실제 적용에서 과하게 간단한 모델을 선택하는 경향이 있다. 완전한 베이지안 접근법을 바탕으로 해서 복잡하게 불이익을 주는 방식을 자연스럽고 원칙에 맞게 유도해 볼 것이다.

## 1.4. 차원의 저주 (Curse of Dimensionality)

## 1.5. 결정 이론 (Decision Theory)

inference

decision

### 1.5.1. 오분류 비율의 최소화

decision region

decision boundary = decision surface

### 1.5.2. 기대 손실의 최소화

cost function = loss function

utility function

loss matrix

### 1.5.3. 거부 옵션 (Reject Option)

몇몇 적용 사례에서는 오류 비율을 최소화하기 위해 이처럼 결정을 내리기 힘든 지역에 대해서는 결정을 피하는 것이 적절할 수도 있다. 이것이 바로 거부 옵션이다. 예를 들면 우리의 가상 의학 진단 예시에서 어떤 클래스에 속하는지가 비교적 확실한 엑스레이 이미지들은 자동화 시스템이 분류하고, 다소 불확실한 이미지들은 사람이 직접 확인하도록 하는 것이 적절할 수도 있다.

### 1.5.4. 추론과 결정

inference stage

decision stage

discriminant function

1. 직간접적으로 입력값과 출력값의 분포를 모델링하는 이러한 방식을 생성 모델(generative model)이라고 한다. 왜냐하면 이렇게 만들어진 분포로부터 표본을 추출함으로써 입력 공간에 합성 데이터 포인트들을 생성해 넣는 것이 가능하기 때문이다.
2. 사후 확률을 직접 모델링하는 이러한 방식을 판별 모델(discriminative model)이라고 한다.
3. 각각의 입력값 x를 클래스에 사상하는 판별 함수 f(x)를 찾는다. 예를 들어, 두 개의 클래스를 가진 문제의 경우에 f(.)은 이진값을 출력으로 가지는 함수로써, f=0일 경우 클래스 C1을, f=1일 경우 클래스 C2를 표현할 수 있다. 이 방식에서는 확률론이 사용되지 않는다.

이러한 데이터 포인트들에 대해서는 예측 모델이 낮은 정확도를 보이게 될 것이다. 이런 검출 방식을 이상점 검출(outlier detection) 혹은 새것 검출(novelty detection)이라고 한다.

위험의 최소화

거부 옵션

클래스 사전 확률에 대한 보상

모델들의 결합

조건부 독립(conditional independence)

특정 조건부 독립 가정은 나이브 베이즈 모델(naive Bayes model)의 예시다.

### 1.5.5. 회귀에서의 손실 함수

회귀 함수(regression function)

제곱 손실을 일반화한 예시인 민코프스키 손실(Minkowski loss)

## 1.6. 정보 이론

entropy

엔트로피와 가장 짧은 코드 길이 사이의 관계는 일반적인 것이다. 노이즈 없는 코딩 이론(noiseless coding theorem)에 따르면 엔트로피는 확률 변수의 상태를 전송하기 위해 필요한 비트 숫자의 하한선이다. 

내트(nats)

다중도(multiplicity)

스털링 근사식(Stirling's approximation)

통 안의 물체들의 순서를 미시 상태(microstate)라 하며, ni/N으로 표현되는 통 각각이 가지고 있는 물체의 숫자 비율을 일컬어 거시 상태(macrostate)라 한다. 다중도 W를 거시 상태의 가중치(weight)라 일컫기도 한다.

옌센의 부등식(Jensen's inequality)

평균값의 정리(mean value theorem)

미분 엔트로프(differential entropy)

조건부 엔트로프(conditional entropy)

### 1.6.1. 상대적 엔트로피와 상호 정보량

상대 엔트로피(relative entropy) 또는 쿨백 라이블러 발산(Kullback-Leibler divergence, KL divergence)

볼록 함수(convex function)

순볼록(strictly convex)

오목(concav)

순오목(strictly concave)

상호 정보량(mutual information)

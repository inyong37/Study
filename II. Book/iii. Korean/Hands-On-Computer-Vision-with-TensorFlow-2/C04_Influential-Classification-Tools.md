# Chapter 4. 유력한 분류 도구

- VGG, Inception, ResNet 같은 아키텍처가 컴퓨터 비전 분야에 가져온 것
- 이 솔루션들을 분류 작업을 위해 재구현하거나 직접 재활용할 방법
- 전이학습의 정의와 훈련된 네트워크를 다른 용도에 맞게 효율적으로 바꾸는 방법

## 4.1. 기술 요구사항

## 4.2. 고급 CNN 아키텍처의 이해

### 4.2.1. VGG, 표준 CNN 아키텍처

### VGG 아키텍처 개요

### 동기

AlexNet은 그처럼 복잡한 인식 작업을 위해 성공적으로 훈련된 최초의 CNN으로 여러 가지 기여한 바가 있으며, 다음은 지금도 유효하다.

- 활성화 함수로 정류형 선형 유닛(rectified linear unit, ReLU)을 사용해 경사 소실 문제를 피해서 훈련을 개선한다(시그모이드나 탄 함수와 비교해서).
- CNN에 드롭아웃을 적용한다.
- 합성곱과 풀링 계층으로 구성된 블록과 최종 예측을 위한 밀집 계층을 결합한 전형적인 CNN 아키텍처
- 인위적으로 데이터셋을 늘리기(원본 샘플을 무작위로 편집해 다양한 훈련 이미지 개수를 확대 위해 무작위 변환(이미지 변환, 좌우 반전 등)을 적용한다.

:bulb: ILSVRC의 주요 분류 메트릭 중 하나는 top-5 정확도다. 이 메트릭은 어떤 기법의 상위 5개 예측 안에 정확한 클래스가 포함되면 제대로 예측한 것으로 간주한다. 실제로 많은 애플리케이션에서 다수의 클래스 후보를 그보다 적은 수로 줄일 수 있는 기법을 찾는 것만으로도 충분하다(예를 들어 남은 후보에서 최종 선택하는 일은 전문가에게 맡기는 것). Top-5 메트릭은 더 일반적인 top-k 메트릭의 특정 케이스에 해당한다.

### 아키텍처

네트워크를 이전 네트워크 대부분보다 더 깊게 개발하는 방법을 설명했다. 11개부터 25개의 계층으로 구성되는 여섯 가지 다양한 CNN 아키텍처를 소개했다. 각 네트워크는 몇 개의 합성곱 계층이 연이어 나오고 그 뒤를 최대-풀링 계층이 따르는 블록 다섯 개, 마지막으로 세 개의 밀집 계층(훈련할 때는 드롭아웃과 함께)으로 구성돼 있다. 모든 합성곱과 최대-풀링 계층에서는 패딩 기법으로 "SAME"을 사용한다. 합성곱 계층에서는 보폭으로 s=1을 사용하고 활성화 함수로는 'ReLU'를 사용한다.

가장 성능이 우수해 지금도 보편적으로 사용되는 아키텍처는 VGG-16과 VGG-19다. 아키텍처 이름에서 숫자(16과 19)는 이 CNN 아키텍처의 깊이, 즉 스택으로 쌓인 훈련 가능한 계층의 개수를 나타낸다. 예를 들어 VGG-16에는 13개의 합성곱 계층과 3개의 밀집 계층이 있어 이를 합쳐 깊이가 16이 된 것이다(여기서는 훈련할 수 없는 연산 즉, 5개의 최대-풀링 계층과 2개의 드롭아웃 계층은 제외한다). VGG_16에 세 개의 합성곱 계층을 추가해 구성된 VGG-19도 마찬가지다.

### 기여 - CNN 아키텍처 표준화

### A. 규모가 큰 합성곱을 여러 작은 합성곱으로 대체

처음에는 3 * 3 커널을 갖는 두 합성곱 계층을 쌓은 스택이 5 * 5 커널을 갖는 하나의 합성곱 계층과 동일한 수용 영역을 갖는다는 단순한 관측에서 시작됐다.

이와 마찬가지로 3 * 3 합성곱 계층을 3개 연이어 배치하면 수용 영역은 7 * 7이 되고 5개의 3 * 3 합성곱의 수용 영역은 11 * 11이 된다. 따라서 AlexNet의 필터는 11 * 11까지로 규모가 크지만, VGG 네트워크는 이보다 작은 합성곱 계층을 더 많이 포함해 더 큰 ERF를 얻을 수 있다. 이러한 변경 내역에는 두 가지 이점이 있다.

- 매개변수 개수를 줄인다: 실제로 11 * 11 합성곱 계층에 N개의 필터를 적용한다는 것은 커널만을 위해 훈련시켜야 할 값이 11 * 11 * D * N=121DN개라는 것을 뜻한다. 반면 5개의 3 * 3 합성곱에는 커널을 위한 가중치가 총 1 * (3 * 3 * D * N) + 4 (3 * 3 * N * N)=9DN + 36N^2개가 있다. N < 3.6D 이기만 하면 매개변수 개수가 더 작다는 뜻이다. 예를 들어 N = 2D이면 매개변수 개수는 242D^2에서 153D^2개로 떨어진다. 이렇게 되면 네트워크를 최적화하기 쉬워지고 훨씬 가벼워진다.

- 비선형을 증가시킨다: 합성곱 계층 개수가 커지면, 그리고 각 합성곱 계층 다음에 ReLU 같은 '비선형' 활성화 함수가 오면 네트워크가 복잡한 특징을 학습할 수 있는 능력이 증대된다(즉, 더 많은 비선형 연산을 결합함으로써).

전반적으로 큰 규모의 합성곱 대신 더 작은 합성곱을 연이어 배치함으로써 VGG 저자들은 효과적으로 더 깊이 들어갈 수 있게 됐다.

### B. 특징 맵 깊이를 증가

직관을 기반으로 각 합성곱 블록에 대한 특징 맵의 깊이를 두 배로 늘렸다(첫 번째 합성곱 다음에 64에서 512로). 각 집합 다음에는 윈도우 크기가 2 * 2이고 보폭이 2인 최대-풀링 계층이 나오므로 깊이가 두 배로 늘고 공간 차원은 반으로 줄게 된다.

이를 통해 공간 정보를 분류에 사용할 더 복잡하고 차별적인 특징으로 인코딩할 수 있다.

### C. 척도 변경을 통한 데이터 보강

척도 변경(scale jittering)이라고 하는 데이터 보강 기법도 소개했다. 이 기법은 훈련이 반복될 때마다 이미지 배치를 적절한 입력 크기로 자르기 전에 그 척도를 무작위로 조정(더 작은 변의 크기를 256픽셀에서 512픽셀로)한다. 이렇게 무작위로 변환함으로써 네트워크는 다양한 척도의 샘플을 경험하게 되고 이러한 척도 변경에도 불구하고 이미지를 적절히 분류하는 방법을 학습하게 된다. 다양한 범위의 현실적인 변환을 포괄하는 이미지에서 훈련됐기 때문에 그 결과 네트워크가 더 견고해진다.

:bulb: 데이터 보강(data augmentation)은 이미지에 무작위 변환을 적용해 다양한 버전을 생성함으로써 훈련 데이터세트의 크기를 인위적으로 늘리는 절차다.

VGG 저자들은 테스트 시점에 무작위로 척도를 변경하고 이미지를 자를 것을 제안한다. 이 방식으로 쿼리 이미지를 여러 버전으로 생성하고 이를 모두 네트워크에 제공하면 해당 네트워크가 특별히 익숙한 척도의 콘텐츠를 제공할 가능성이 증가할 것이라는 직관에 의거한다. 최종 예측은 각 버전에 대한 결과의 평균을 구해 얻는다.

이 논문에서는 이 절차가 정확도를 얼마나 개선하는지도 보여준다.

이미지를 추가적으로 변환할 때 콘텐츠의 가로 세로 비율을 유지하지 않는 것이 일반적이다.

:bulb: 동일한 원칙을 AlexNet 저자들도 사용했다. 훈련과 테스트에서 모두 이미지 자르기(cropping)와 이미지 반전(flipping)의 다양한 조합으로 여러 이미지를 생성한다.

### D. 완전 연결 계층을 합성곱 계층으로 대체

전통적인 VGG 아키텍처는 마지막에 여러 개의 오나전 연결 계층이 오지만(AlexNet처럼), 이 논문에서는 다른 방식을 제안한다. 여기서 제안한 아키텍처에서는 밀집 계층을 합성곱 계층으로 대체한다. 크기가 좀 더 큰 커널(7 * 7과 3 * 3)을 적용한 첫 번째 합성곱 세트는 특징 맵의 공간 크기를 1 * 1로 줄이고(그 전에 패딩을 적용하지 않았다면) 특징 맵의 깊이를 4096으로 늘린다. 마지막으로 1 * 1 합성곱 계층이 예측해야 할 클래스 개수만큼의 필터(즉, ImageNet의 경우 N=1000)와 함께 사용된다. 그 결과 얻게 된 1 * 1 * N 벡터는 softmax 함수로 정규화된 다음 평면화되어 최종 클래스 예층으로 출력된다(벡터의 각 값은 예측된 클래스 확률을 나타낸다).

밀집 계층을 두지 않는 이러한 네트워크를 완전 합성곱 계층(Fully Connected Network, FCN)이라고 한다. FCN은 사전에 이미지를 자르지 않고도 다양한 크기의 이미지에 적용될 수 있다.

:bulb: 흥미롭게도 ILSVRC에서 가장 높은 정확도를 얻기 위해 저자는 일반 합성곱 신경망과 FCN을 모두 훈련시켜 사용하고 두 결과의 평균을 구해 최종 예측을 얻었다. 이러한 기법을 모델 평균법(Model Averaging)이라고 하고 실제 운영 환경에서 자주 사용한다.

### 텐서플로와 케라스로 구현하기

### 텐서플로 모델

### 케라스 모델

:bulb: 케라스 용어에서 최상단 계층은 마지막에 연이어 놓인 밀집 계층을 말한다. 따라서 include_top=False로 설정하면 VGG 밀집 계층을 제외한다는 뜻이고 이 때 네트워크 출력은 마지막 합성곱/최대-풀링 블록의 특징 맵이 된다. 이는 분류 작업뿐 아니라 의미 있는 특징을 추출하기 위해(보다 발전된 작업에 적용할 수 있는) 사전에 훈련된 VGG 네트워크를 재사용하고자 할 경우 유용하다. pooling 함수 매개변수는 이러한 경우(즉 include_top=False일 때) 특징 맵을 반환하기 전에 적용할 선택적인 연산을 지정하기 위해 사용될 수 있다(평균-풀링 또는 최대-풀링을 적용한다면 pooling='avg' 또는 pooling='max').

:bulb: 케라스 용어에서 최상단 계층은 마지막에 연이어 놓인 밀집 계층을 말한다. 따라서 `include_top=False`로 설정하면 VGG 밀집 계층을 제외한다는 뜻이고 이 때 네트워크 출력은 마지막 합성곱/최대-풀링 블록의 특징 맵이 된다. 이는 분류 작업뿐 아니라 의미 있는 특징을 추출하기 위해(보다 발전된 작업에 적용할 수 있는) 사전에 훈련된 VGG 네트워크를 재사용하고자 할 경우 유용하다. `pooling` 함수 매개변수는 이러한 경우(즉 `include_top=False`일 때) 특징 맵을 반환하기 전에 적용할 선택적인 연산을 지정하기 위해 사용될 수 있다(평균-풀링 또는 최대-풀링을 적용한다면 `pooling='avg'` 또는 `pooling='max'`).

### 4.2.2. GoogLeNet, Inception 모듈

GoogLeNet('Google'과 'LeNet'에서 따온 이름으로 이 선구적인 네트워크에 대한 경의를 담고 있음)은 구조적으로 '인셉션 블록'(이 네트워크를 보통 인셉션 네트워크[Inception Network]라고도 함)이라는 개념을 도입한다는 점에서 선형 네트워크와 매우 다르다.

### GoogLeNet 아키텍처 개요

### 동기

첫 번째로 CNN 계산 용량을 초적화하는 것을 고려했다.

사실 신중하게 제작해도 .CNN 깊이가 깊어지면 훈련 가능한 매개변수 개수와 예측당 계산 수가 많아진다(이 때문에 메모리와 시간 측면에서 비용이 높다). 예를 들어 VGG-16은 매개변수 저장을 위해 약 93MB가 필요하고 ILSVRC에 제출한 VGG는 4개의 GPU를 사용해 훈련시키는 데 2~2주가 걸렸다. GoogLeNet은 5백만 개의 매개변수를 가지고 있어 AlexNet보다 12배 가볍고 VGG-16보다 21배나 가벼우며 일주일 내에 훈련을 마쳤다. 그 결과 GoogLeNet과 더 최근의 인셉션 네트워크는 좀 더 보통 수준의 시스템(스마트폰 같은)에서 실행될 수 있어 그 인기가 시들지 않고 있다.

여기에서 기억할 것은 GoogLeNet이 매개변수과 연산 수가 상당히 줄었음에도 불구하고 2014년 분류 대회에서 top-5 오차 6.7%로(VGG는 7.3%였다) 우승했다는 사실이다. 이렇게 우수한 성능은 세게디 팀이 '다양한 척도를 처리'하기 위한 병렬 계층 블록을 사용해 깊을 뿐만 아니라 규모도 큰 네트워크를 구상하고자 한 두 번째 목표의 결과다. CNN을 구성하는 것은 복잡합 반복 작업이다. 

### 아키텍처

입력 이미지가 맨 처음 인련의 전형적인 합성곱과 최대-풀링 계층에서 처리된다. 그런 다음 이 정보는 9개의 인셉션 모듈 스택을 통과한다. 이  모듈(종종 하위 네트워크라고도 한다)은 수직 수평으로 겹쳐 놓은 계층 블록이다. 각 모듈에서 입력 특징 맵은 한두개의 서로 다른 계층(다른 크기의 커널이 적용된 합성곱과 최대 풀링)으로 구성된 4개의 병렬 하위 블록에 전달된다.

이 네 개의 병렬 연산의 결과를 차원 깊이에 따라 서로 연결해 하나의 특징 볼륨으로 변환한다.

모든 합성곱과 최대-풀링 계층은 패딩 옵션으로 "SAME"을 사용한다. 합성곱 계층은 별로로 지정하지 않는 한 보폭을 s=1로 사용하고 활성화 함수로 ReLU를 사용한다.

이 네트워크는 병렬 계층(인셉션 모듈)과 유사한 구조를 공유하는 여러 계층 블록으로 구성된다. 첫 번째 인셉션 모듈은 입력으로 28 * 28 * 192 크기의 특징을 받는다. 이 인셉션 모듈의 첫 번째 병렬 하위 블록은 하나의 1 * 1합성곱 출력(N=64, s=1)으로 구성되어 28 * 28 * 64 텐서를 생성한다. 이와 유사하게 두 번째 하위 모듈은 두 개의 합성곱으로 구성되어 28 * 28 * 128 텐서를 출력하고 나머지 두 개의 합성곱은 각각 28 * 28 * 32와 28 * 28 * 32의 특징을 출력한다. 따라서 첫 번째 인셉션 모듈은 최종 차원을 따라 이 4개의 결과를 스택으로 쌓아 28 * 28 * 256 텐서를 출력하고 이 출력이 두 번째 모듈로 전달돼 같은 과정이 계속 반복된다.

마지막 모듈에서 특징은 평균-풀링을 통해 7 * 7 * 1024에서 1 * 1 * 1024로 변환되고 마지막으로 밀집되어 예측 벡터로 변환된다. 이 네트워크는 두 개의 보조 블록을 갖도록 구성될 수 있으며 여기서도 예측을 도출한다.

전체적으로 GoogLeNet은 22-계층의 깊이를 갖는 아키텍처(훈련 가능한 계층만 셈)로 60개 이상의 합성곱과 FC 계층으로 구성된다. 그럼에도 이처럼 커다란 네트워크가 AlexNet보다 12배나 적은 매개변수를 갖는다.

### 기여 - 규모가 큰 블록과 병목을 보편화

### A. 인셉션 모듈로 다양한 세부 특징 잡아내기

Network in Network (NIN) 논문에서 소개한 것처럼 구글팀은 여러 하위 네트워크 모듈로 CNN을 구성하는 아이디어를 조정하면서 철저히 활용했다. 고안한 기본 인셉션 모듈은 4개의 병렬 계층 즉, 3개의 합성곱 계층(필터 크기는 각각 1 * 1, 3 * 3, 5 * 5임)과 하나의 최대-풀링 계층(보폭은 1)으로 구성된다. 각 계층의 결과를 하나로 연결해 최종 결과를 만드는 이 병렬 처리의 이점은 여러 가지가 있다.

이 아키텍처는 척도가 다양한 데이터 처리를 가능하게 해준다. 각 인셉션 모듈의 결과는 다양한 척도의 특징을 결합해 더 광범위한 정보를 잡아낸다. 이 경우 최선의 커널 크기를 선택할 필요가 없다(이러한 선택을 위해서는 훈련과 테스트를 여러 번 반복해야 한다). 즉 네트워크가 스스로 각 모듈에 대해 어느 합성곱 계층에 더 의존하는지 학습한다.

추가로 비선형 활성화 함수를 사용해 수직으로 연결한 계층이 네트워크 성능에 얼마나 긍정적인 영향을 미치는지 설명했지만, 수평으로 계층을 연결하는 경우도 마찬가지다. 서로 다른 계층에서 매핑된 특징을 연결하는 것으로 CNN에 비선형성이 추가된다.

### B. 병목 계층으로 1 * 1 합성곱 계층을 사용

1 * 1 합성곱 계층(보폭은 1)은 대체로 입력의 전체 깊이를 공간 구조에 영향을 주지 않고 변경하기 위해 사용된다. N개의 필터를 갖는 계층은 형상이 H * W * D인 입력을 취해 H * W * N 텐서를 반환한다. 입력 이미지의 각 픽셀에 대해 D개의 채널 값은 해당 계층에서 삽입되어 N개의 채널 값이 된다(필터 가중치에 따라).

이 속성을 적용하면 사전에 특징 깊이를 압축함으로써(N < D를 사용해) 합성곱 계층이 커지더라도 필요한 매개변수 개수를 줄일 수 있다. 기본적으로 이 기법은 병목 계층(즉 차원과 매개변수 개수를 줄이는 중간 계층)으로 1 * 1 합성곱 계층을 사용한다. 신경망에서 활성화 함수가 불필요하거나 사용하지 않는 경우가 많으므로 이러한 병목 계층은 일반적으로 성능에 거의 영향을 주지 않는다(이 계층이 깊이를 획기적으로 줄이지 않는 한). 더구나 GoogLeNet은 깊이 축소를 상쇄하는 병렬 계층이 있다. 실제로 인셉션 네트워크에서 병목 계층은 모든 모듈에서 큰 합성곱 계층 전과 최데-풀링 연산 뒤에 모두 존재한다.

예를 들어 첫 번째 인셉션 모듈에 5 * 5 합성곱 계층이 주어졌을 때 (28 * 28 * 192 크기의 입력을 취함), 이 계층의 필터를 포함한 텐서의 차원은 원시 버전인 경우 5 * 5 * 192 * 32가 된다. 이것은 이 합성곱 계층에서만 매개변수가 153,600개라는 것을 나타낸다. 인셉션 모듈의 첫 번째 버전(즉, 병목 계층이 있는)에서 1 * 1 합성곱 계층은 N=16으로 설정되어 5 * 5 합성곱 계층 앞에 위치한다. 그 결과 두 개의 합성곱 계층은 커널에 대해 전체 1 * 1 * 192 * 16 + 5 * 5 * 16 * 32 = 15,872개의 훈련 가능한 값을 필요로 한다. 이것은 동일한 출력 크기를 제공하면서 이전 버전보다 매개변수 개수는 10배나 적은(이 5 * 5 계층 하나에 대해서만) 수치다! 게다가 이미 언급했듯이 비선형 활성화 함수('ReLU')를 사용한 계층을 추가하면 복잡한 개념을 잡아내는 네트워크의 능력을 더 개선할 수 있다.

:bulb: 이 장에서는 ILSVRC 2014에 제출된 GoogLeNet을 설명한다. 일반적으로 사용하는 명칭은 인셉션 V1으로, 이 아키텍처는 그 이후로 저자들에 의해 개선됐다. 인셉션 V2와 인셉션 V3에는 5 * 5와 7 * 7 합성곱 계층을 그보다 작은 합성곱 계층으로 대체하고(VGG에서와 마찬가지로) 정보 손실을 줄이기 위해 병목 계층의 초매개변수를 개선하거나 'BatchNorm' 계층을 추가하는 등 몇 가지 개선사항이 포함돼 있다. 

### C. 완전 연결 계층 대신 풀링 계층 사용

인셉션 저자가 매개변수 개수를 줄이기 위해 사용한 또 다른 솔루션은 마지막 합성곱 블록 다음에 완전 연결 계층 대신 평균-풀링 계층을 사용하는 것이다. 윈도우 크기로 7 * 7, 보폭으로 1을 설정하면 이 계층은 훈련시킬 매개변수 하나 없이 특징 볼륨을 7 * 7 * 1024에서 1 * 1 * 1024로 줄인다. 밀집 계층이 오면 (7 * 7 * 1024) * 1024 = 51,380,224개의 매개변수가 추가될 것이다. 물론 풀링 계층으로 대체하면 네트워크가 표현력을 약간 잃게 되지만, 계산상으로 얻는 이익이 막대하다(그리고 이미 이 네트워크는 최종 예측에 필요한 정보를 잡아내기에 충분한 비선형 연산을 포함하고 있다). 

:bulb: GoogLeNet에서 마지막에 유일하게 나오는 FC 계층의 매개변수는 1024 * 1000 = 1,024,000개로 이 네트워크 매개변수 전체 중 1/5에 해당한다.

### D. 중간 손실로 경사 소실 문제 해결하기

GoogLeNet에는 훈련에 사용돼(그 후에는 제거된다) 예측을 생성하는 두 개의 보조 분기(branch)가 있다.

이 보조 분기를 두는 목적은 훈련하는 동안 네트워크를 통해 손실을 전파하는 과정을 개선하는 데 있다. 실제로 CNN이 깊어질수록 경사가 소실되어 문제가 되는 경우가 많다. 많은 CNN 연산(예를 들어 시그모이드)에는 진폭이 작은(1보다 작은) 도함수가 있다. 따라서 계층 수가 많을수록 역전파할 때 도함수의 곱은 작아진다(1보다 작은 값을 여러 번 곱하면 그 결과는 0에 가까워지기 때문에). 이렇게 첫 번째 계층에 도착했을 때 대체로 경사는 소실되거나 0에 가까워진다. 경삿값이 매개변수 업데이트에 직접 사용되기 때문에 경사가 너무 작으면 이 계층들은 효과적으로 학습할 수 없다.

:bulb: 네트워크가 깊어지면 이와 정반대되는 현상 즉, 경사가 폭발하는 문제도 발생할 수 있다. 도함수가 크기가 큰 연산을 사용하는 경우, 역전파하는 동안 도함수의 곱이 너무 커져서 훈련을 불안정하게 만들거나(크고 불규칙한 가중치 업데이트로), 때때로 오버플로(NaN 값)가 발생할 수 있다.

이 문제에 대한 해결책으로 여기서 구현한 효과적이면서도 현실적인 솔루션은 다양한 네트워크 깊이에서 추가적인 분류 손실을 도입함으로써 첫 번째 계층과 예측 사이의 거리를 줄이는 것이다. 마지막 손실에서의 경사가 적절하게 첫 번째 계층까지 흐를 수 없더라도 그보다 더 가까운 중간 손실 덕에 분류 작업에 도움이 되게 훈련될 수 있다. 부수적으로 이 솔루션은 여러 손실에 의해 여향을 받는 계층의 견고함도 다소 개선한다. 이는 주요 네트워크뿐만 아니라 그보다 짧은 보조 분기에서도 유용한 차별적 특징을 추출하도록 학습해야 하기 때문이다.

### 텐서플로와 케라스로 구현하기

### 케라스 함수형 API로 Inception 모듈 구현하기

### 텐서플로 모델과 텐서플로 허브

### 케라스 모델

### 4.2.3. ResNet - 잔차 네트워크

ResNet(잔차 네트워크[residual network])은 새로운 유형의 모듈이 잔차 모듈로 구성돼 상당히 깊은 네트워크를 효율적으로 생성할 수 있는 방법을 제공해 인셉션 같은 큰 모델을 성능 측면에서 능가했다.

### ResNet 아키텍처 개요

### 동기

인셉션 네트워크는 이미지 분류나 다른 인식 작업에 있어 네트워크 크기를 키우는 것이 유효한 전략임을 보여준다. 그럼에도 전문가들은 점점 더 복잡해지는 작업을 해켤하기 위해 네트워크 깊이를 증가시키려고 노력했다. 그렇지만 히는 자신의 논문 서두에 '네트워크에서 더 많은 계층을 연결할수록 학습이 더 쉬워질까?'라는 질문을 제기했고 이 질문이 정당함을 증명했다.

앞에서 이미 네트워크가 깊이 내려갈수록 훈련시키기 어렵다는 점을 배웠따. '경사가 소실되거나 폭발하는' 문제를 제외하고도, 히는 더 깊어진 CNN이 당면할 또 다른 문제인 '성능 저하'를 지적했다. 이 모든 것은 새로운 계층을 추가하는 것에 따라 CNN 정확도가 선형으로 증가하지 않는다는 간단한 관측에서 비롯됐다. 성능 저하 문제는 네트워크 깊이가 깊어질수록 더 뚜렷하다. 정확도가 포화 상태가 되다가 결국 저하된다. 너무 많은 계층을 그냥 쌓기만 해도 훈련 손실이 감소하는 것은 이 문제가 과적합으로 인한 것이 아님을 입증하는 것이다. 예를 들어 저자는 18-계층의 깊이를 갖는 CNN의 정확도를 34-계층 CNN과 비교해 훈련 단계와 그 후 단계에서 34-계층 CNN이 18-계층 CNN보다 성능이 낮음을 보여줬다. 이 논문에서 히 팀은 매우 깊지만 성능이 우수한 네트워크를 구성할 수 있는 솔루션을 제안했다.

:bulb: '모델 평균법'(다양한 깊이의 ResNet 모델 적용)과 '예측 평균법'(입력 이미지마다 다양한게 잘라낸 이미지 사용)을 사용해, ResNet 저자들은 ILSVRC 대회에서 top-5 오차율 3.6%로 역사적으로 가장 낮은 기록을 달성했다. 이 모델이 그 데이터셋에서 사람의 능력을 뛰어넘은 최초의 솔루션이었다. 이 대회 주최측에서 사람의 성능을 측정했을 때 최고 오차율은 5.1%였다. 이 작업에서 초인적 성능을 달성하면서 딥러닝 분야에서 획기적인 전환점을 마련했다. 그렇지만 알고리즘은 특정 작업을 전문적으로 해결할 수 있지만, 여전히 사람처럼 자신의 지식을 다른 분야로 확장하거나 자신이 다루고 있는 데이터의 컨텍스트를 이해하는 능력은 없다는 점을 알아두자.

### 아키텍처

인셉션 모델처럼 ResNet은 병목 합성곱 계층을 추가하거나 크기가 작은 커널을 사용하는 등 몇 차례 반복적으로 아키텍처를 개선해왔다. VGG처럼 ResNet도 깊이에 따른 의사 표준화 버전이 몇 가지 있다(ResNet-18, ResNet-50, ResNet-101, ResNet-152 등). 실제로 ILSVRC 2015에서 우승한 ResNet 네트워크는 152개의 훈련 가능한 계층을 수직으로 연결해 구성했는데, 이는 당시 매우 인상적인 결과였다. 

모든 합성곱과 최대-풀링 계층은 특별히 지정하지 않는 한 패딩 옵션으로 "SAME"을, 보폭으로 s=1을 사용한다. 3 * 3 합성곱 계층 다음마다 배치 정규화를 적용하고, 1 * 1 합성곱 계층에는 활성화 함수(항등 함수)가 없다.

ResNet 아키텍처도 인셉션 아키텍처와 비슷하게 병렬 연산을 포함한 계층 블록으로 구성되지만, 그보다 더 얇다. 각 병렬 계층이 입력 정보를 비선형적으로 처리하는 인셉션 모델과 달리, ResNet 블록은 하나의 비선형 경로와 하나의 항등 경로로 구성된다. 비선형 경로는 배치 정규화와 ReLU 활성화 함수와 함께 두 개의 합성곱 계층을 입력 특징 맵에 적용한다. 항등 경로는 어떤 변환도 적용하지 않고 단순히 특징을 앞으로 전달한다.

:bulb: 항상 그런 것은 아니다. 비선형 분기에 의해 깊이가 깊어지면 특징의 깊이를 조정하기 위해 1 * 1 합성곱을 적용한다. 이런 경우 매개 변수가 급격히 증가하는 것을 피하기 위해 보폭을 s=2로 설정해 양쪽 모두에서 공간 차원을 줄인다.

인셉션 모듈처럼 각 분기에서 얻은 특징 맵(즉, 변환된 특징과 원본 특징)은 다음 블록에 전달되기 전에 하나로 합쳐진다. 그렇지만 인셉션 모듈과는 다르게 이 통합은 심도 결합(depth concatenation)을 통해 수행하지 않고 요소 단위 덧셈(추가 매개변수가 필요 없는 단순한 연산)을 통해 수행한다.

:bulb: 대부분의 구현에서 각 잔차 블록의 마지막 3 * 3 합성곱 계층 뒤에는 ReLU 활성화 함수를 두지 않는다. 대신 항등 경로의 결과와 통합한 다음 비선형 함수가 적용된다.

마지막으로 GoogLeNet과 마찬가지로 최종 블록에서 얻은 특징에 퍙균-풀링을 적용하고 밀도가 높은 예측으로 변환한다.

### 기여 - 정보를 더 깊은 계층으로 전방 전달

잔차 블록은 머신러닝과 컴퓨터 비전 분야에 상당한 기여를 했다.

### A. 매핑 대신 잔차 함수 추정하기

ResNet 저자가 지적했듯이, 네트워크 계층이 항등 매핑(identity mapping)을 쉽게 학습할 수 있다면(즉 계층이 가중치를 학습해 계층에서의 일련의 연산이 최종적으로 입력 텐서와 동일한 텐서를 반환한다면) 성능 저하 현상은 발생하지 않을 것이다.

실제로 그 저자들은 CNN 위에 몇 가지 계층을 추가했을 때 그 추가 계층이 항등 함수로 수렴할 수 있다면 최소한 동일한 훈련/검증 오차를 얻을 수 있어야 한다고 주장한다. 그 추가 계층은 최소한 원래 네트워크의 결과를 품질 저하 없이 전달하는 방법을 학습한다. 그렇지 않기 때문에(이미 대체로 성능 저하를 관측할 수 있으므로) CNN 계층에서 항등 매핑을 학습하는 것이 쉬운 일은 아님을 알 수 있다.

여기에서 다음 두 경로로 잔차 블록을 도입하는 아이디어를 얻게 됐다.

- 일부 추가적인 합성곱 계층을 사용해 데이터를 추가로 처리하는 경로
- 항등 매핑(즉, 데이터에 어떤 변경도 가하지 않고 전달)을 수행하는 경로

이 방법이 어떻게 성능 저하 문제를 해결할 수 있는지 직감적으로 알 수 있을 것이다. CNN 위에 잔차 블록을 추가하면 처리 분기를 가중치를 0으로 설정해 사전 정의된 항등 매핑만 남겨 최소한 원래 성능을 유지할 수 있다. 처리 경로는 손실 최소화 효과가 있을 경우만 고려한다.

데이터 전달 경로는 일반적으로 스킵(skip) 혹은 숏컷(shortcut)이라 부른다. 처리 경로는 보통 잔차 경로(residual path)라고 부른다. 그 이유는 그 경로 연산의 출력을 원본 입력에 더하는데, 이때 항등 매핑이 최적값에 가까울 때 처리된 텐서의 크기가 입력 텐서보다 훨씬 작기 때문이다(이 때문에 '잔차'라는 용어를 사용한다). 전반적으로 이 잔차 경로는 입력 데이터에 약간의 변화만 가져오므로 더 깊은 계층으로 패턴을 전달할 수 있다.

히 팀은 자신의 논문에서 성능 저하 문제를 해결할 뿐만 아니라 ResNet 모델이 계층 수가 동일한 전통적인 모델보다 정확도가 우수함을 입증했다.

### B. '극단적으로 깊이' 들어가기

잔차 블록은 전통 블록보다 매개변수가 많지 않은데, 스킵과 덧셈 연산에는 어떤 매개변수도 필요 없기 때문이다. 따라서 잔차 블록은 '상당히 깊은' 네트워크를 구성할 때 효율적이다.

ImageNet에 적용된 152-계층 네트워크 외에도 인상적인 1,202-계층 네트워크를 훈련시키는 성과를 보여줬다. 그렇게 거대한 CNN을 어려움 없이 훈련시켰음을 발표했다(이른바 과적합 때문에 검증 정확도가 152-계층 네트워크보다 약간 낮지만).

더 최근에는 하이웨이 네트워크(Highway network, 각 잔차 블록에서 훈련 가능한 스위치 값을 사용해 어느 경로를 사용할지 결정하는)나 DenseNet 모델(블록 사이에 스킵 연결을 추가한)처럼 잔차 계산을 사용해 더 깊고 더 효율적인 네트워크를 구성하는 방법에 대한 연구가 진행되고 있다.

### 텐서플로와 케라스로 구현하기

### 케라스 함수형 API로 잔차 블록 구현하기

### 텐서플로 모델과 텐서플로 허브

### 케라스 모델

시각 인식 분야의 연구가 빠른 속도로 발전하면서, 이전 솔루션을 기반으로 구성하고(예를 들어 ResNet을 위해 하이웨이와 DenseNet 기법이 하는 것처럼), 통합해서(Inception-ResNet 솔루션처럼) 특정 용도에 맞게 최적화한(스마트폰에서 실행할 수 있게 구성된 가벼운 MobileNet처럼) 보다 진화된 아키텍처가 제안되고 있다. 따라서 이미 있는 모델을 다시 만드느라 시간을 낭비하기 전에 항상 최신 모델이 무엇을 제공하는지 점검하는(예를 들어 공식 저장소나 연구 저널에서) 것이 좋다.

## :pencil: 4.3. 전이학습 활용

다른 분야에서 제공하는 지식을 재사용하는 것은 컴퓨터 과학에서만 중요한 것은 아니다.

인공 신경망과 전이학습(transfer learning)의 관계와 전이학습을 모델에 적용하는 방법에 대해 설명하겠다.

### 4.3.1. 개요

### 정의

ImageNet 분류 작업을 위해 개발된 몇 가지 유명한 CNN을 소개했다. 이 모델은 일반적으로 더 광범위한 애플리케이션에 사용될 수 있다고 말했다. 뒤에서 마침내 전이학습에서 재조정을 하는 이유와 그 성능에 대해 자세히 설명한다.

### 인간으로부터 영감 얻기

전이학습도 복잡한 작업을 해결하고 지식을 모으는 인류의 방식에서 영감을 받았다.

기존에 보유한 지식을 기반으로 복잡한 작업에 숙달하거나 비슷한 행동에 이미 가지고 있는 기술을 바꿔 적용하는 능력은 인간 지능에서 가장 중요한 부분이다. 머신러닝 연구원들은 이 능력을 복제하는 꿈을 꾸고 있다.

### 동기

CNN은 특정 특징을 추출해 해석하도록 훈련됐기 때문에 특징 분포가 바뀌면 그 성능은 떨어지게 된다. 따라서 네트워크를 새로운 작어베 적용하려면 어느 정도의 변환 작업이 필요하다.

그 해법에 대해 수십년간 연구됐다. 1998년 세바스찬 스런(Sebastian Thrun)과 로리엔 프랫(Lorien Pratt)은 이 주제에 기초한 널리 알려진 연구를 엮어 Learning to Learn이라는 책을 편집했다. 더 최근에는 이안 굿펠로(Ian Goodfellow)와 요슈아 벤지오(Yoshua Bengio), 애런 쿠빌(Aaron Courille)이 심층 학습(Deep Learning)에서 전이학습을 다음과 같이 정의했다. *어떤 설정(예를 들어, 분포 P_1)에서 학습된 내용이 다른 설정(분포 P_2라고 하자)에서 일반화를 개선하기 위해 활용되는 상황*

:bulb: 머신러닝에서 작업(task)는 주어진 입력(예를 들어, 스마트폰으로 찍은 사진)과 예상 출력(예를 들어, 특정 클래스 집합에 대한 예측 결과)에 의해 정의된다. 예를 들어, ImageNet에서 분류하거나 탐지하는 작업은 입력 이미지는 동일하지만 출력은 다르기 때문에 서로 다른 두 개의 작업으로 봐야 한다. 경우에 따라 알고리즘은 유사한 작업(예를 들어, 보행자 탐지)을 목표로 하지만 다른 데이터셋(예를 들어, 다양한 위치의 CCTV 이미지나 다양한 품질의 카메라로 찍은 이미지)를 사용하기도 한다. 따라서 이 기법은 다양한 도메인(즉, 데이터 분포)에서 훈련된다. 전이학습은 이미 갖춘 지식을 하나의 작업에서 다른 작업으로 또는 한 도메인에서 다른 도메인으로 적용하는 것을 목표로 한다. 이 중 한 도메인에서 다른 도메인으로 적용하는 형태의 전이학습을 도메인 적응(Domain Adaption)이라고 한다.

전이학습은 새로운 작업을 적절하게 학습하기에 충분한 데이터가 확보되지 않았을 때(즉, 분포를 추정하기에 이미지 샘플이 충분하지 않을 때) 매력적이다. 특히 지도 학습을 위해 레이블이 붙은 데이터셋을 수집하는 일은 불가능하지 않더라도 지루하고 따분한 작업이다.

:bulb: ImageNet(최근에는 COCO)은 수많은 카테고리에서 나온 주석이 달른 이미지를 수백만 개 포함하고 있어 특히 풍부한 데이터셋이다. 이 데이터셋에서 훈련된 CNN은 시각 인식 작업에서 상당한 전문 역량을 습득했다고 가정하므로 케라스과 텐서플로 허브에서도 이 데이터셋에서 이미 훈련된 표준 모델(인셉션, ResNet-50 등)을 제공한다. 지식전이할 모델을 찾는 사람들은 일반적으로 이 표준 모델을 사용한다.

### CNN 지식 전이

인공 신경망이 사람의 뇌보다 나은 점 중 하나는 저장과 복제가 쉽다는 점이다. CNN이 갖고 있는 전문지식은 훈련 이후 매개변수가 취한 값, 즉 쉽게 복원되고 유사한 네트워크에 전이될 수 있는 값이 전부다.

CNN을 위한 전이학습은 주로 다른 작업을 위한 새로운 모델을 인스턴스화하기 위해 풍부한 데이터셋에서 훈련된 성능 좋은 네트워크의 아키텍처 전체 혹은 일부와 가중치를 재사용하는 것으로 구성된다. 새로운 모델은 이 조건에 따라 인스턴스화한 다음 '미세 조정'될 수 있다. 즉 새로운 작업/도메인에 대해 활용할 수 있는 데이터에서 더 훈련될 수 있다.

네트워크의 첫 번째 계층은 저차원 특징(선, 테두리, 색 변화 등)을 추출하는 경향이 있지만 마지막 합성곱 계층은 더 복잡한 개념(특정 형태나 패턴 같이)에 반응한다. 분류 작업을 위해 마지막 풀링 또는 완전 연결 계층에서 클래스를 예측하기 위해 이 고차원 특징 맵(병목 특징, Bottleneck Feature)을 처리한다.

이 일반적인 구성과 관련 관측을 통해 다양한 전이학습 전략이 도출됐다. 마지막 예측 계층을 제거한 사전 훈련된 CNN은 효율적으로 '특징을 추출'하는 용도로 사용되기 시작했다. 새로운 작업이 이 추출기가 훈련된 목적과 충분히 비슷한 경우 적절한 특징을 출력하기 위해 바로 사용될 수 있다(이 목적에 정확히 부합하는 '이미지 특정 벡터' 모델을 텐서플로 허브에서 찾아볼 수 있다). 그런 다음 이 특징은 작업과 관련된 예측을 출력하도록 훈련된 한두 개의 새로 추가된 밀집 계층에서 처리될 수 있다. 추출된 특징의 품질을 유지하기 위해 대체로 이 훈련 단계 동안 특징 추출기의 계층을 '고정'시킨다. 즉, 그 계층의 매개변수는 경사 하강이 일어나는 동안 업데이트되지 않는다. 이와 다르게 작업/도메인이 유사하지 않은 경우 특징 추출기의 마지막 계층 중 일부 또는 전체를 '미세 조정'한다. 즉, 이 계층들을 작업 데이터에서 새로운 예측 계층과 함께 훈련시킨다.

### 활용 사례

사전 훈련된 모델 중 어떤 모델을 재사용할지, 어느 계층을 고정시키고 어느 계층을 미세 조정할 지는 목표한 작업과 모델이 이미 훈련한 작업과 얼마나 비슷한지, 그리고 새로운 애플리케이션을 위한 훈련 샘플이 얼마나 풍부한지에 따라 다르다.

#### A. 제한적 훈련 데이터로 유사한 작업 수행

전이학습은 특정 작업을 해결하고 싶고 선은 좋은 모델을 제대로 훈련시킬 만큼 훈련 샘플이 충분하지 않지만 그보다 크고 유사한 훈련 데이터셋에 접근할 수 있을 때 특히 유용하다.

이 모델은 이 큰 데이터셋에서 수렴할 때까지 사전 훈련시킬 수 있다(또는 가능하고 적절하다면, 제공되는 사전 훈련된 모델을 가져올 수도 있다). 그런 다음 마지막 계층을 제거하고(목표한 작업이 다른 경우, 즉 그 출력이 사전 훈련의 목표 작업의 출력과 다른 경우) 목표한 작업에 맞춰 조정한 계층으로 교체해야 한다. 예를 들어, 벌 사진과 말벌 사진을 구분하는 모델을 구분하는 모델을 훈련시키고 싶다고 하자. ImageNet에는 이 두 클래스에 해당하는 이미지가 포함돼 있어 훈련 데이터셋으로 사용될 수 있지만, 그 이미지 수가 효율적인 CNN이 과적합을 일으키지 않고 학습할 만큼 충분히 크지 않다. 그렇지만 먼저 더 광범위한 전문 지식을 개발하기 위해 전체 ImageNet 데이터셋에서 1000개의 카테고리로 분류하도록 이 네트워크를 훈련시킬 수 있다. 이 사전 훈련 과정을 거친 다음 마지막 밀집 계층을 제거하고 목표한 두 개의 클래스에 대해 예측을 출력하도록 설정된 계층으로 교체할 수 있다.

이 새로운 모델은 미리 훈련된 계층을 고정시키고 상단에 위치한 밀집 계층만 훈련시킴으로써 목표한 작업을 수행하도록 준비할 수 있다. 사실 목표 훈련 데이터셋이 너무 작기 때문에 모델에서 특징 추출기의 구성 요소를 고정시키지 않으면 모델이 과적합될 수 있다. 이 매개변수를 고정시킴으로써 네트워크가 더 풍부한 데이터셋에서 개발한 표현력을 유지할 수 있게 된다.

### B. 풍부한 훈련 데이터로 유사한 작업 수행

:bulb: 모델은 이미 유사한 데이터셋에서 첫 번째 훈련 단계를 거쳤고 아마도 이미 수렴에 가까워져 있을 것이다. 따라서 미세 조정 단계에서는 학습률을 낮게 설장하는 것이 일반적이다.

### C. 풍부한 훈련 데이터로 유사하지 않은 작업 수행

:bulb: 전이학습은 작업 또는 도메인이 최소한 어느 정도 기초적인 유사성을 공유할 때 당위성을 갖는다. 예를 들어 이미지와 오디오 파일 모두 2차원 텐서로 저장될 수 있고 CNN(ResNet 같은)은 두 파일 모두에 공통적으로 적용된다. 그렇지만 그 모델은 시각 인식과 오디오 인식을 위해 전혀 다른 특징에 의거해 훈련된다. 이 경우 오디오 관련 작업을 위해 훈련된 네트워크의 가중치를 받는 것은 시각 인식을 위한 모델에 도움이 되지 않는다.

### D. 제한적 훈련 데이터로 유사하지 않은 작업 수행

마지막으로 목표 작업이 너무 특수해서 훈련 샘플이 거의 없고 사전에 훈련된 가중치가 그다지 의미가 없는 경우, 먼저 심층 모델을 적용하고 용도에 맞게 조정하는 것이 적절한지 재검토할 필요가 있다. 그러한 모델을 작은 데이터셋에서 훈련시키면 과적합이 일어나고 깊이가 깊은 사전 훈련된 추출기는 특정 작업과는 매우 무관한 특징을 반환하게 된다. 하지만 CNN의 첫 번째 계층이 저차원 특징에 반응한다는 점을 감안하면 여전히 전이학습에서 혜택을 볼 수 있다. 사전 훈련된 모델의 최종 예측 계층만 제거하는 것이 아니라,작업에 너무 특화된 최종 합성곱 블록의 일부도 제거할 수 있다. 그런 다음 남은 계층 위에 얕은 분류기를 추가해 새로운 모델을 미세 조정할 수 있다.

### 4.3.2. 텐서플로와 케라스로 전이학습 구현

### 모델 수술

### 계층 제거

처음으로 할 일은 사전 훈련된 모델의 마지막 계층을 제거해 특징 추출기로 변환하는 것이다. Sequential 모델의 경우 model.layers 속성을 통해 계층 리스트에 접근할 수 있다. 이 구조에는 모델의 가장 마지막 계층을 제거하는 pop() 메서드가 있다. 따라서 네트워크를 특정 특징 추출기로 변환하기 위해 제거해야 할 마지막 계층의 개수를 안다면(예를 들어 표준 ResNet 모델의 경우 2개 계층), 다음 코드로 제거할 수 있다.

```Pythons
for i in range(num_layers_to_remove):
  model.layers.pop()
```

순수한 텐서플로에서 모델을 지원하는 연산 그래프를 편집하는 일은 단순하지도 않으며 추천할 만한 방법도 아니다. 그렇지만 사용되지 않는 그래프 연산은 런타임에 실행되지 않는다는 점에 유의해야 한다. 따라서 컴파일된 그래프에 예전 계층이 있더라도 새로운 모델에서 그 계층을 호출하지 않는 이상 계산 성능에 영향을 주지 않는다. 그러므로 계층을 제거하는 대신 이전 모델에서 유지하고자 하는 마지막 계층/연산을 정확히 특정하면 된다. 어쨋든 그 마지막 계층에 대응하는 파이썬 객체를 잃어도 그 이름을 안다면(예를 들어, 텐서보드에서 그래프를 확인해서) 이를 대표하는 텐서는 모델 계층마다 돌면서 이름을 확인함으로써 복원될 수 있다.

```Python
for layer in model.layers:
  if layer.name == name_of_last_layer_to_keep:
    bottleneck_feats = layer.output
    break
```

그렇지만 케라스는 추가 메서드를 제공해 이 절차를 단순화했다. 유지할 최종 계층의 이름을 알면(예를 들어, model.summary()로 이름을 출력한 다음) 다음 코드 2줄로 특징 추출기 모델을 구성할 수 있다.

```Python
bottleneck_feats = model.get_layer(last_layer_name).output
feature_extractor = Model(inputs=model.input, outputs=bottleneck_feats)
```

이 특징 추출 모델은 원본 모델과 이 가중치를 공유해서 사용할 준비가 됐다.

### 계층 이식

특징 추출기 상단에 새로운 예측 계층을 추가하는 일은 텐서플로 허브를 사용했던 이전 예제에 비해 단순한데, 그에 대응하는 모델 상단에 새로운 계층을 추가하기만 하면 되기 때문이다. 예를 들어 케라스 API를 사용해 다음과 같이 추가할 수 있다.

```Python
dense1 = Dense(...)(feature_extractor.output) # ...
new_model = Model(model.input, dense1)
```

여기서 볼 수 있듯이, 텐서플로 2는 케라스를 통해 모델 길이를 줄이거나 확장하거나 결합하는 일을 단순화했다.

### 선택적 훈련

전이학습을 사용하면 먼저 사전 훈련된 계층을 복원하고 어느 계층을 고정할지 정의해야 하기 때문에 훈련 단계가 다소 복잡해진다.

### 사전 훈련된 매개변수 복원하기

텐서플로에는 에스티메이터를 웜스타트(warm-start)하는, 즉 사전에 훈련된 가중치를 사용해 일부 계층을 초기화하는 유틸리티 함수가 있다. 다음 코드를 사용하면 텐서플로에서 새로운 에스티메이터를 위해 동일한 이름을 공유하는 계층의 경우 사전 훈련된 에스티메이터의 저장된 매개변수를 사용할 수 있다.

```Python
def model_function():
  # ... 새로운 모델 정의, 사전 훈련된 모델을 특징 추출기로 재사용

ckpt_path = '/path/to/pretrained/estimator/model.ckpt'
ws = tf.estimator.WarmStartSetting(ckpt_path)
estimator = tf.estimator.Estimator(model_fn, warn_start_from=ws)
```

:bulb: WarmStartSetting 초기화 함수는 vars_to_warm_start를 선택적 매개변수로 취하는데, 이 변수는 체크포인트 파일에서 복원하고자 하는 특정 변수(리스트 또는 정규식으로) 이름을 제공할 때도 사용될 수 있다.

케라스를 사용하면 새로운 작업에 맞춰 변환하기 전에 사전 훈련된 모델을 복원할 수 있다.

```Python
# 사전 훈련된 모델이 `model.save()`를 사용해 저장됐다고 가정
model = tf.keras.models.load_model('/path/to/pretrained/model.h5')
# ... 그런 다음 새로운 모델을 얻기 위해 계층을 빼거나 추가함
```

일부 계층을 제거하기 위해 전체 모델을 복원하는 것이 최적은 아니지만, 이 방법이 간결하다는 장점이 있다.

### 계층 고정하기

텐서플로에서 계층을 고정하기 위해 가장 다양하게 사용되는 기법은 최적화기에 전달되는 매개변수 리스트에서 tf.Variable 특성을 제거하는 것이다.

```Python
# 예를 들어, 이름에 "conv"가 포함된 모델 계층을 고정하고자 함

vars_to_train = model.trainable_variables
vars_to_train = [v for v in vars_to_train if "conv" in v.name]
```

케라스 계층에는 .trainable 특성이 있고 그 계층을 고정하기 위해 이 속성을 False로 설정하면 된다.

```Python
for layer in feature_extractor_model.layers:
  layer.trainable = False # 전체 추출기를 고정
```

## 4.4. 요약

- 최신 솔루션을 재사용하는 방법
- 알고리즘 자체가 이전 작업에서 획득한 지식을 통해 어떤 혜택을 얻을 수 있는지
- 전이학습을 사용하면 특정 애플리케이션을 위한 CNN 성능을 크게 향상시킬 수 있음
  - 객체 탐지를 위해 데이터셋에 주석을 다는 일은 이미지 단위 인식을 위한 주석 작업보다 더 지루해서 일반적으로 이 기법들은 더 작은 데이터셋에서 훈련됨
- 효율적인 모델을 얻기 위한 솔루션으로 전이학습을 고려하는 것이 중요함

## 4.5. 질문

## 4.6. 참고 문헌

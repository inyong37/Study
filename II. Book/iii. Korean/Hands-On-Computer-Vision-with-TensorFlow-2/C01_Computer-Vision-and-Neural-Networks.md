# Chapter 1. 컴퓨터 비전과 신경망

## 1.1. 기술적 요구사항

## 1.2. 컴퓨터 비전

### 1.2.1. 컴퓨터 비전 소개

### 1.2.2. 주요 작업 및 애플리케이션

## 1.3. 컴퓨터 비전의 약력

### 1.3.1. 최초 성공을 위한 첫 걸음

### 1.3.2. 딥러닝의 출현

## 1.4. 신경망 시작하기

### 1.4.1. 신경망 구성하기

### Activation Functions

입력 크기가 바뀌고 더해져서 결과를 만들면, 뉴런의 츨력을 얻기 위해 그 결과에 활성화 함수를 적용해야 한다.

Step Function:
- 퍼셉트론에서 사용하는 y가 임계값 t보다 크면 전기 자극을 반환하고 그렇지 않으면 0을 반환하는 이진 함수다.
- y = f(z) = 0 if z < t or 1 if z >= t
- 비선형성과 연속형 식별 가능성 같이 더 유리한 특성을 갖춘 발전된 활성화 함수가 소개됐다.

Sigmoid function:
- s(z) = 1/(1 + exp(-z))

Hyperbolic tangent:
- tanh(z) = (exp(z) - exp(-z)) / (exp(z) + exp(-z))

Rectified Linear Unit (ReLU):
-  ReLU(z) = max(0, z) = 0 if z < 0 or z if z >= 0

인공 뉴런은 신호를 받아 처리해서 다른 뉴런에 '전달(forward)'될 값을 출력으로 만들어서 네트워크를 구성할 수 있다.

:bulb: 비선형 활성화 함수를 사용하지 않고 뉴런을 연결하는 것은 단일 뉴런을 갖는 것과 마찬가지다. 따라서 복잡한 모델을 생성하려면 비선형 활성화 함수는 불가피하다.

```Python
import numpy as np

class Neuron(object):
  """간단한 전방 전달 인공 뉴런.
  Args:
    num_inputs (int): 입력 벡터 크기 / 입력 값 개수.
    activation_fn (callable): 활성화 함수.
  Attributes:
    W (ndarray): 각 입력에 대한 가중치.
    b (float): 편향값, 가중합에 더해짐
    activation_fn (callable): 활성화 함수.
  """
  
  def __init__(self, num_inputs, activation_fn):
    super().__init__()
    # 랜덤값으로 가중치 벡터와 편향값을 초기화함:
    self.W = np.random.rand(num_inputs)
    self.b = np.random.rand(1)
    self.activation_fn = activation_fn
    
  def forward(self, x):
    """뉴런을 통해 입력 신호를 전달."""
    z = np.dor(x, self.W) + self.b
    return self.activation_fn(z)
```

인스턴화해서 임의의 입력값을 이 퍼셉트론을 통해 전달하자.

```Bash
# 결과를 복제할 수 있도록 랜덤 숫자 생성기의 시드 값을 고정
np.random.seed(42)
# 3개의 랜덤 입력을 칼럼으로 받을 수 있는 배열 (shape = `(1, 3)`)
x = np.random.rand(3).reshape(1, 3)
# > [[0.37454012 0.95071431 0.73199394]]

# 퍼셉트론을 인스턴스화(계단 함수를 사용하는 간단한 뉴런):
step_fn = lambda y: 0 if y <= 0 else 1
perceptron = Neuron(num_inputs=x.size, activation_fn=step_fn)
# > perceptron.W = [0.59865848 0.15601864 0.15599452]
# > perceptron.b = [0.05808351]
out = perceptron.forward(x)
# > 1
```

일반적으로 신경망은 '계층', 즉 일반적으로 동일한 입력을 받고 동일한 연산을 적용하는 뉴런 집합으로 구성된다.

각 뉴런이 이전 계층에서 나온 모든 값에 연결돼 있는 계층을 완전 연결 계층(fully-connected layer) 또는 밀집 계층(dense layer)이라고 한다.

MNIST(Modified National Institute of Standards and Technology) 데이터셋이 수년간 이 인식 문제를 해결하는 기법을 테스트하기 위한 참고자료롤 사용됐다(얀 르쿤과 코리나 코르테스가 다음 이미지의 데이터셋에 대한 저작권을 보유하고 있다).

숫자를 분류하기 위해 필요한 작업은 이 이미지 중 하나를 입력으로 받아 '네트워크가 해당 이미지가 각 클래스에 대응하는지 확신하는 정도'를 출력 벡터로 반환하는 것이다. 여기서 우리가 할 일은 은닉 계층의 개수와 그 크기를 정의하는 것이다. 그런 다음 이미지의 클래스를 예측하기 위해 '이미지 벡터를 네트워크를 통해 전달하고, 출력을 수집해서 확신 점수가 가장 높은 클래스를 반환'하기만 하면 된다.

:bulb: 이 '확신' 점수(belief score)는 보통 추가 계산이나 해석을 단순화하기 위해 확률로 변환된다.

### 1.4.2. 신경망 훈련시키기

신경망은 가용 데이터로부터 학습해서 '훈련돼야'하는, 즉 신경망의 매개변수가 특정 과제에 맞게 최적화돼야 하는 특수한 알고리즘이다. 네트워크가 이 '훈련 데이터셋'에서 잘 동작하게 최적화되고 나면 비슷하지만 새로운 데이터에 사용돼 만족할 만한 수준의 결과를 제공할 수 있다.

### 지도 학습(Supervised Learning)

### 비지도 학습(Unsupervised Learning)

이 전략은 클러스터링(비슷한 속성을 갖는 이미지끼리 그룹으로 나누는)이나 압축(콘텐츠의 일부 속성은 유지하면서 크기를 줄이는) 같은 애플리케이션에 매우 적합하다. 클러스터링의 경우 손실 함수는 하나의 클러스터의 비슷한 이미지가 다른 클러스터의 이미지와 얼마나 다른지 측정할 수 있다. 압축의 경우 손실 함수는 원본 데이터와 비교해 압축된 데이터의 중요한 속성이 얼마나 잘 보존돼 있는지를 측정할 수 있다.

### 강화 학습(Reinforcement Learning)

### 네트워크 훈련

학습 전략에 상관없이 전체 훈련 단계는 동일하다. 일부 훈련 데이터가 주어지면 네트워크는 예측을 하고 피드백(손실 함수의 결과 같은)을 받아 이를 네트워크 매개변수를 업데이트하는 데 사용한다. 이 단계는 네트워크가 더이상 최적화될 수 없을 때까지 반복된다.

### 손실 평가

'손실 함수'의 목표는 네트워크가 현재의 가중치로 얼마나 잘 동작하는지 평가하는 것이다. 더 공식적으로 말하자면 이 함수는 '네트워크 매개변수(가중치와 편향값 같은)의 함수로 예측의 품질'을 나타낸다. 손실이 작을수록 선택된 과제를 위한 매개변수로 더 적합하다.

손실 함수는 네트워크의 목표를 나타내기 때문에 주어진 과제만큼 다양한 함수가 존재한다. 지도 학습 어디에서나 볼 수 있는 L2 손실(L2 노름 기반)이라고 하는 '제곱합'의 경우가 그렇다. 이 함수는 단순히 출력 벡터 y의 각 요소(네트워크가 추정한 클래스별 확률)와 실제 값 벡터 y_true(정확한 클래스를 제외한 클래스는 모두 널 값인 타깃 벡터)의 각 요소 간 차이의 제곱을 계산한다.

L_2(y, y_true) = sum(y_true - y)^2

이외에도 벡터 간 '차이의 절댓값'을 계산하는 L1 손실이나 기댓값과 비교하기 전에 예측 확률을 로그 척도로 변환하는 이진 교차 엔트로피(BCE, binary cross-entropy) 손실 같은 서로 다른 속성을 갖는 다양한 손실함수가 있다.

L_1(y, y_true) = sum(y_true - y)

BCE(y, y_ture) = sum(-y_ture * log(y) + (1 - y_true) * log(1-y))

:bulb: 로그 연산은 확률을 [0, 1]에서 [-inf, 0]으로 변환한다. 따라서 결과에 -1을 곱합으로써 신경망이 제대로 예측하는 법을 배우면서 손실값은 +inf에서 0으로 옮겨가게 된다. 교차 엔트로피 함수는 분류해야 할 클래스가 여러 개(두 개뿐 아니라)인 문제에도 적용될 수 있다.

:bulb: 이 외에도 보편적으로 사용되는 방법으로는 벡터 요소의 개수를 기준으로 손실을 나누는 방법, 즉 합계 대신에 평균을 계산하는 방법이 있다. 평균 제곱 오차(MSE, mean-square error)는 L2 손실의 평균을 구한 버전이며 평균 절댓값 오차(MAE, mean absolute error)는 L1 손실의 평균을 구한 버전이다.

### 손실을 역전파하기

매개변수 값을 조정해서 손실을 약간 줄일 수 있다면 이 조정된 값을 반영해 최솟값에 도달할 때까지 반복하면 된다. 이것이 바로 손실 함수 '경사'이며 '경사 하강' 절차를 묘사한 것이다.

훈련을 반복할 때마다 네트워크의 각 매개변수에 관한 손실 도함수가 계산된다. 이 도함수는 조정된 매개변수 값 중 어느 것을 적용해야 할지 알려준다(경사는 함수의 증가 방향을 가리키지만 여기서는 이를 감소시키기 원하기 때문에 a-1 계수를 사용해 적용한다). 각 매개변수에 대한 손실 함수의 '경시'를 따라 이것이 단계별로 내려가는 것으로 볼 수 있다. 따라서 이 반복 절차에서 경사 하강이라는 이름을 붙인 것이다.

매개 변수 P: P_i -> P_(i+1), 손실 L: L_i -> L_(i+1) => dLi/dP

연쇄 법칙(chain rule)

연쇄 법칙은 계층 k의 매개변수와 관련한 도함수가 해당 계층의 출력값 (x_k, y_k)와 다음 계층 k+1의 도함수를 가지고 간단히 계산될 수 있음을 알려준다. 공식으로 표현하면 계층 가중치 W_k에 대해 다음과 같이 표현할 수 있다.

dL/dW_k = dL/dy_k * dy_k/dW_k

dL/dW_k = dL/dy_k * dy_k/dz_k * dz_k/dW_k

dL/dW_k = dL/dx_(k+1) * dy_k/dz_k * d(W_k * x_k + b_k)/dW_k

dL/dW_k = l'_(k+1) * f'_k d(W_k * x_k + b_k)/dW_k

dL/dW_k = x_k^T * (l'_(k+1) * f'_k)

각 매개변수가 계층마다 손실에 얼마나 영향을 미치는지 재귀적으로 되돌아가면서 계산하기만 하면 된다(이전 계층에 대한 도함수를 계산하기 위해 이번 계층의 도함수를 사용하는 방식). 이 개념은 신경망을 '계산 그래프', 즉 서로 연결된 수학 연산의 그래프로 표현해 나타낼 수 있다(첫 번째 계층의 가중합이 계산되고 그 결과가 첫 번째 활성화 함수에 전달된 다음 그 출력이 두 번째 계층의 연산으로 전달되는 식으로 계속된다). 따라서 입력에 대해 전체 신경망의 결과를 계산하는 것은 데이터를 이 계산 그래프를 통해 '전달하는 것'으로 구성되며, 각 매개변수에 대한 도함수를 구하는 것은 그래프에서 결과 손실을 반대 방향으로 전파하는 것(역전파라는 용어가 여기에서 비롯됐다)으로 구성된다.

출력 계층에서 이 프로세스를 시작하려면 각 출력값에 대한 손실 자체의 도함수가 필요하다. 따라서 손실 함수를 쉽게 유도할 수 있는 것이 가장 중요하다. 예를 들어 L2 손실의 도함수는 다음처럼 간단하다. 

dL2(y, y_true)/dy = 2(y-y_true)

각 매개변수에 대해 손실 함수의 도함수를 구하면 그에 따라 매개변수를 업데이트하면 된다.

W_k <- W_k - epsilon * dL/dW_k

b_k <- b_k - epsilon * dL/db_k

도함수는 매개변수 업데이트에 사용되기 전에 계수 epsilon으로 곱한다. 이 계수를 학습률(learning rate)이라 한다. 이 계수는 매회 얼마의 강도로 업데이트돼야 하는지를 제어한다. 학습률이 크면 네트워크가 빠르게 학습하지만 조정폭이 너무 커서 최소 손실값을 '놓칠' 수 있다는 위험이 있다. 따라서 이 계수 값은 신중하게 정해야 한다.

1. n개의 다음 훈련 이미지를 선택해 네트워크에 제공한다.
2. 연쇄 법칙을 사용해 손실을 계산하고 역전파해서 계층 매개변수와 관련된 미분값을 얻는다.
3. 해당 미분값으로 매개변수를 업데이트한다(학습률로 조정됨).
4. 전체 훈련 집합에 대해 1~3까지의 단계를 반복한다.
5. 수렴하거나 정해진 반복 횟수에 도달할 때까지 1~4단계를 반복한다.

전체 훈련 집합을 1회 반복하는 것(1~4단계)을 세대(epoch)라고 한다. n=1이고 남은 이미지에서 훈련 샘플을 무작위로 선택하는 경우, 이 프로세스를 확률적 경사 하강법(SGD, stochastic gradient descent)이라고 하는데, 이는 구현하고 시각화하기는 쉽지만 훈련 속도가 느리고(업데이트 과정이 많을수록) '노이즈가 많다'. 보통 '미니 배치 확률적 경사 하강법(mini-batch stochastic gradient descent)'을 선호하는 경향이 있다. 이는 n 값이 커질수록(컴퓨터 성능에 따라 제한됨) 무작위로 추출한 n개의 훈련 샘플의 '미니 배치'(간단히 '배치'라고도 함)마다 평균 경사를 구하는 방법이다(따라서 노이즈가 적다).

:bulb: 현재 용어 SGD는 n 값과 상관없이 일반적으로 사용된다.

### 훈련 시 고려사향 - 과소적합과 과적합

다양한 '초매개변수'(계층 크기, 학습 속도, 배치 크기 등)를 활용해 테스트해보자.

네트워크 계층이 너무 적거나 너무 작은 계층으로 구성되면 정확도가 향상되지 않을 것이다. 이는 네트워크가 과소적합(underfitting)됐다는 뜻이다. 즉, 과제의 복잡도를 다룰 만큼 충분한 매개변수를 갖지 못했음을 뜻한다.

반면에 네트워크가 너무 복잡하거나 훈련 데이터셋이 너무 작으면 네트워크는 훈련 데이터에 과적합(overfitting)되기 시작한다. 이는 네트워크가 훈련 분포(그 고유의 노이즈, 세부 항목 등)에는 너무 잘 적합되게 학습하지만, 새로운 샘플에 적용될 만큼 일반화되지 않는다. 

## 1.5. 요약

1. 컴퓨터 비전, 그 도전 과제, SIFT, SVM 같은 역사적 기법을 소개
2. 신경망, 신경망을 구성하고 훈련시키고 적용하는 방법
3. MNIST 분류 네트워크 구현, 머신러닝 프레임워크 동작에 대한 이해

## 1.6. 질문

## 1.7. 참고 문헌

# Chapter 3. 현대 신경망

## 3.1. 기술 요구사항

## 3.2. 합성곱 신경망의 발견

### 3.2.1. 다차원 데이터를 위한 신경망

### 완전 연결 네트워크의 문제점

이미지를 처리할 때 기초 네트웤가 갖는 두 가지 주요 단점은 다음과 같다.

- 매개변수의 폭발적인 증가
- 공간 추론의 부족

### 매개변수의 폭발적인 증가

이미지는 H * W * D 값으로 이루어진다. H는 이미지 높이, W는 이미지 너비, D는 이미지의 깊이 혹은 채널 개수(RGB 이미지의 경우 D=3)이다. 예를 들어, MNIST 이미지의 경우 작은 단일 채널 이미지도 28 * 28 * 1 = 784개의 값으로 이루어진 입력 벡터를 가지고, 첫 번째의 계층이 64개의 노드로 이루어져 있으면 (784, 64) 형상의 weight vector를 가진다. 이 때 이 변수만을 최적화해야 할 매개변수의 값은 784 * 64 = 50176개이다. RGB 이미지가 커지거나 네트워크가 깊어질수록 '이 매개변수 개수는 매우 급격히 증가한다.'

### 공간 추론의 부족

이 네트워크의 뉴런이 어떤 구분 없이 이전 계층의 모든 값을 받기 때문에('뉴런이 모두 연결되어 있다.) 이 신경망은 '거리/공간성'이 없다. 데이터의 공간 관계를 잃는다. 이미지 같은 다차원 데이터는 밀접 계층에 칼럼 벡터로 전달될 수 있기 때문에 그 연산은 데이터 차원이나 입력값의 위치를 고려하지 않는다. 더 정확하게는 모든 픽셀 값이 계층별로 '원래 위치와 상관없이' 결합되므로 픽셀 사이의 근접성 개념이 완전 연결(FC, fully-connected) 계층에서 손실된다.

:bulb: 평면화(flatten)를 해도 밀집 계층의 행위가 바뀌지 않으므로 밀집 계층의 계산과 매개변수 표현을 단순화하기 위해 밀집 계층에 전달하기 전에 다차원 입력을 '1차원으로 변환'하는 것(즉 컬럼 벡토로 형상을 바꾸는 것)이 보편적이다.

### CNN 도입

CNN은 다차원 데이터를 처리할 수 있다. 이미지의 경우, CNN은 '3차원 데이터(높이 * 너비 * 깊이)'를 입력으로 취하고 뉴런을 그와 비슷한 볼륨으로 정렬한다. 뉴런이 이전 계층의 모든 요소에 연결된 완전 연결 네트워크와 달리 CNN의 각 뉴런은 이전 계층에서 이웃한 영역에 속한 일부 요소에만 접근한다. 이 영역을 뉴런의 수용 영역(또는 '필터 크기')이라고 한다. 뉴런을 이전 계층의 이웃한 뉴런과만 연결함으로써 CNN은 훈련시킬 '매개변수 개수를 급격히 줄일'뿐 아니라 '이미지 특징의 위치 정보를 보존'한다.

### 3.2.2. CNN 작업

이 아키텍처 패러다임으로 새로운 유형의 계층도 도입해 '다차원성'과 '지역적 연결성'을 효율적으로 활용한다.

### :hammer_and_wrench: 합성곱 계층

CNN이라는 이름은 그 아키텍처의 핵심에 해당하는 '합성곱 계층'에서 비롯됐다. 이 계층에서는 동일한 출력 채널에 연결된 모든 뉴런이 똑같은 가중치와 편향값을 공유함으로써 매개변수의 개수를 더 줄일 수 있다.

### 개념

가중치와 편향값을 공유하는 특정 뉴런은 '공간적으로 제한된 연결성'을 통해 전체 입력 행렬에서 슬라이딩하는 단일 뉴런으로 생각할 수도 있다. 각 단계에서 이 뉴런은 현재 슬라이딩하고 있는 입력 볼륨(H * W * D)의 일부 영역에만 공간적으로 연결된다. 필터 크기가 (k_H, k_W)인 뉴런에 대해 이 제한된 입력 차원 k_H * k_W * D가 주어지면 이 뉴런은 첫 번째 장에서 모델링했던 뉴런처럼 동작한다. 즉 합계에 활성화 함수(선형 또는 비선형 함수)를 적용하기 전에 입력 값(k_H * k_W * D개의 값)을 선형으로 결합한다. 수학적으로 (i, j) 위치에서 시작한 입력 패치에 대한 뉴런의 응답 z_ij는 다음과 같이 표현할 수 있다.

z_ij = delta * (b + sum(l=0 ~ k_H - 1 (sum (m=0 ~ k_W - 1 sum(n=0 ~ D - 1(w_(l,m,n) * x_(i+l,j+m,n) ))))

:bulb: 실제로 대부분 정사각형 필터를 사용한다. 이는 이 필터의 크기가 (k, k)이고, k=k_H=k_W라는 뜻이다.

합성곱 계층에는 여전히 N개의 다른 뉴런 집합(즉 같은 매개변수를 공유하는 N개의 뉴런 집합)이 있으므로, 그에 대한 응답 맵이 함께 쌓여서 형상이 H_o * W_o * N인 출력 텐서가 된다.

완전 연결 계층에서 행렬 곱셈을 적용한 것과 동일한 방식으로 여기에서 합성곱 연산을 사용해 모든 응답 맵을 한번에 계산할 수 있다(그래서 이 계층의 이름이 합성곱 계층이다).

:bulb: 머신러닝 분야에서는 '합성곱'이라는 말을 보편적으로 쓰지만, 이 연산을 수학적 용어로 적절하게 표현하자면 실제로 '교차 상관 관계(cross-correlation)'이라고 볼 수 있다.

### 속성

N개의 다양한 뉴런의 집합을 갖는 합성곱 계층은 형상이 D * k * k(필터가 정사각형인 경우)인 N개의 가중치 행렬(필터 또는 커널이라고도 함)과 N개의 편향값으로 정의된다. 따라서 이 계층에서 훈련시킬 값은 N * (D * K^2 + 1)개 뿐이다. 반면 완전 연결 계층이라면 유사한 입력과 출력 차원을 가질 때 (H * W * D) * (H_o * W_o * N)개의 매개변수가 필요하다. 완전 연결 계층에서 매개변수 개수는 데이터 차원에 영향을 받는 반면 합성곱 계층에서는 데이터 차원이 매개변수 개수에 영향을 주지 않는다.

합성곱 계층은 어떤 이미지에도 '그 차원 수와 상관없이' 적용될 수 있다는 점이다. 완전 연결 계층을 가진 네트워크와 달리 순수 합성곱 네트워크에서는 입력 크기가 다양하더라도 별도의 조정이나 재 훈련 과정을 거칠 필요가 없다.

:bulb: CNN을 다양한 크기의 이미지에 적용하는 경우, 입력 배치를 샘플링할 때 주의할 점이 있다. 실제로 이미지 하위 집합은 모두 동일한 차원을 가질 때만 함께 쌓여서 일반 배치 텐서가 될 수 있다. 따라서 실제로 이미지 배치를 나누기 (대체로 훈련 단계에 수행) 전에 정렬하거나 단순히 각 이미지를 개별로 처리(일반적으로 테스트 단계에서 수행)해야 한다. 하지만 데이터 처리와 네트워크 작업을 모두 단순화하기 위해 일반적으로는 이미지를 전처리해서 이미지가 모두 동일한 크기를 갖게 한다(크기를 조정하거나 자르는 작업을 통해).

### 초매개변수

합성곱 계층은 우선 필터 개수 N, 입력 깊이 D(즉 입력 채널의 개수), 필터/커널 크기 (k_H, k_W)로 정의된다. 일반적으로 정사각형 필터를 사용하기 때문에 보통 필터 크기는 간단하게 k로 정의된다.

필터가 움직이는 '보폭(stride)'을 다양하게 적용할 수 있다. 따라서 보폭이라는 초매개변수는 필터가 움직일 때 이미지 패치와 필터 사이의 내적을 위치마다 계산할지(stride=1), s 위치마다 계산할 지 (stride=s) 정의한다. 보폭이 커지면 결과 특징 맵은 희소해진다. 

이미지는 합성곱을 적용하기 전에 '0으로 패딩'될 수도 있다. 즉, 이미지 크기를 원본 콘텐츠 주변에 0으로 된 행과 열을 추가해 인위적으로 키울 수 있다. 패딩은 필터가 이미지를 차지할 수 있는 위치의 수를 증가시킨다. 따라서 적용할 패딩 값(즉, 입력 주변에 추가할 빈 행과 열의 개수)을 지정할 수 있다.

:bulb: 문자 k는 보통 필터/커널 크기(k는 커널 kernel의 앞 글자를 따온 것이다)를 뜻한다. 마찬가지로 s는 보통 보폭(stride), p는 패딩(padding)을 뜻한다. 필터 크기에 대해 말하자면, 일반적으로 수평 및 수직 보폭(s=s_H=s_W)은 물론 수평 및 수직 패딩에도 동일한 값이 사용된다. 그렇지만 일부 특정 사례에서는 다른 값을 가질 수도 있다.

이 모든 매개변수는 계층 연산 뿐만 아니라 그 계층의 출력 형상에도 영향을 준다. 지금까지 여기서는 이 형상을 (H_O, W_O, N)으로 정의했고, 여기에서 'H_O와 W_O'는 뉴런이 입력에서 수직/수평적으로 움직일 수 있는 횟수'를 말한다. 

H_O = (H - k + 2p) / s + 1

W_O = (W - k + 2p) / s + 1

크기가 k인 필터는 크기가 H * W인 이미지에서 수직으로는 최대 H-k+1개의 위치를 취하고 수평으로 W-k+1개의 위치를 취할 수 있다. 게다가 이 이미지의 모든 변에 p만큼 패딩하면 이 위치 개수는 H-k+2p+1 (W-k+2p+1)까지 커진다. 마지막으로 보폭 s를 증가시키는 것은 s 중 하나의 위치만 고려한다는 뜻이며, 이는 위 공식에서 나눗셈을 설명한다(정수 나눗셈임을 주목하자).

이 초매개변수로 계층의 출력 크기를 쉽게 제어할 수 있다. 이것은 객체 분할 같은 애플리케이션 즉, 출력 분할 마스크가 입력 이미지와 동일한 크기를 갖기를 원할 때 특히 편리하다.

### 텐서플로/케라스 메서드

### :hammer_and_wrench: 풀링 계층

### 개념 및 초매개변수

이 풀링 계층에는 '훈련 가능한 매개변수가 없어서' 다소 특이하다. 각 뉴런은 자기 '윈도우'(수용 영역)의 값을 취하고 사전에 정의된 함수로 계산한 하나의 출력을 반환한다. 가장 보편적으로 사용되는 두 개의 풀링 기법으로는 최대 풀링(max pooling)과 평균 풀링(average pooling)이 있다. 최대 풀링 계층은 풀링된 영역의 깊이마다 최댓값만 반환하며 평균 풀링 계층은 풀링된 영역의 깊이마다 평균을 계산한다.

보통 풀링 계층은 풀링 함수를 패치에 서로 겹치지 않게 적용하기 위해 '윈도우/커널 크기'와 동일한 크기의 '보폭' 값을 사용한다. 이는 '데이터의 공간 차원을 줄여서' 네트워크에서 필요한 매개변수의 전체 개수를 줄이고 계산 시간을 단축시키는 것을 목적으로 한다. 

합성곱 계층과 마찬가지로 이 연산을 적용하기 전에 텐서에 패딩을 붙일 수 있다.

패딩(padding)과 보폭(stride) 매개변수를 통해 결과 텐서의 차원을 제어할 수 있다.

따라서 훈련 가능한 커널이 없다는 점만 빼면 합성곱 계층과 비슷한 초매개변수를 가지고 있는 풀링 계층은 데이터 차원을 제어하는 사용하기 쉽고 가벼운 솔루션이다.

### 텐서플로/케라스 메서드

### :hammer_and_wrench: 완전 연결 계층

### CNN에서의 사용법

이 계층에 전달되는 입력 텐서는 먼저 배치로 나뉜 칼럼 벡터로 형상을 조정(높이, 너비, 깊이 차원을 단 차원으로 평면화)해야 함을 뜻한다.

:bulb: FC 계층은 밀집 연결된 계층 또는 단순히 밀집 계층이라고도 한다(연결 범위를 좀 더 제한한 다른 CNN 계층과는 반대되는 의미로).

때에 따라 예를 들어 공간적으로 거리가 먼 특징을 결합하기 위해 뉴런이 전체 입력 맵에 접근하는 것이 유리할 수 있지만, 완전 연결 계층은 공간 정보의 손실이나 매개변수가 엄청 많아진다는 등의 몇 가지 단점이 있다. 게다가 다른 CNN 계층과는 달리 밀집 계층은 입력과 출력 크기에 의해 정의된다. 특정 밀집 계층은 그 계층의 설정과 다른 형상을 갖는 입력에는 동작하지 않는다. 따라서 신경망에서 FC 계층을 사용한다면 다양한 크기의 이미지에 적용될 가능성을 잃게 됨을 의미한다.

이 계층은 일반적으로 네트워크의 마지막 계층에서 예를 들어 다차원 특징을 1차원 분류 벡터로 변환하기 위해 사용된다.

### 텐서플로/케라스 메서드

다차원 텐서를 밀집 계층에 전달하기 전에 '평면화(flattening)'해야 한다는 점을 기억하자.

### 3.2.3. 유효 수용 영역

신경망의 유효 수용 영역(ERF, effective receptive field)은 입력 이미지에서 거리가 먼 요소를 상호 참조하고 결합하는 네트워크 능력에 영향을 줄 수 있으므로 딥러닝에서 중요한 개념이다.

### 정의

수용 영역은 뉴런이 연결된 이전 계층의 로컬 영역을 나타내지만, ERF는 '입력 이미지의 영역'(이전 계층의 영역만이 아니라)을 정의해 주어진 계층을 위한 뉴런의 활성화에 영향을 미친다.

RF가 단순히 한 계층의 필터 크기나 윈도우 크기로 불리기 때문에 ERF 대신 RF(receptive field, 수용 영역)이라는 용어를 사용하는 것을 흔히 볼 수 있다. 사람에 따라 출력 계층(네트워크의 중간 계층이 아니라)의 각 단위에 영향을 미치는 입력 영역을 구체적으로 정의하기 위해 RF나 EFR를 사용하기도 한다.

### 공식

### 3.2.4. 텐서플로로 CNN 구현하기

### 첫 CNN 구현

### LeNet-5 아키텍처

최초 LeNet-5는 두 개의 블록으로 구성돼 있으며 각 블록은 합성곱 계층(커널 크기 k=5, 보폭 s=1)과 뒤따라 나오는 최대 풀링 계층(k=2, s=2)을 포함한다. 첫 번째 블록에서 입력 이미지는 합성곱 계층에 전달되기 전에 각 변마다 2만큼 0으로 패딩하고(p=2, 따라서 실제 입력 크기는 32 * 32) 합성곱 계층에는 6개의 필터가 있다(N=6). 두 번째 합성곱 계층 앞에서는 패딩 과정이 없으며(p=0) 필터 개수는 16으로 설정한다(N=16). 두 블록 다음에 세 개의 완전 연결 계층은 특징을 함께 합쳐 최종 클래스 추정값(10개의 숫자 클래스)을 도출한다. 첫 번째 밀집 계층 전에 5 * 5 * 16개의 특징 볼륨이 400개 값의 벡터로 평면화된다.

원래는 마지막 계층을 제외하면 각 합성곱 계층과 밀집 계층은 활성화 함수로 tanh 함수를 사용한다. 그렇지만 최근에는 tanh보다 ReLU를 선호해서 대부분 LeNet-5 구현에서 ReLU가 tanh을 대체하고 있다. 마지막 계층의 경우 softmax 함수가 적용된다. 이 함수는 N개의 값으로 구성된 벡터를 취해서 동일한 크기의 벡터 y를 확률 분포로 정규화해 반환한다. 다른 말로 softmax는 벡터를 정규화해 전체 합이 1이 되도록 각 값을 0과 1 사이의 값으로 만든다. 따라서 이 함수는 분류 작업을 하는 신경망에서 네트워크 예측을 클래스별 확률로 변환하기 ㅜ이해 신경망의 끝부분에서 사용한다(즉, 출력 센서 y=[y0, ..., yi, ..., yN]가 주어지면 샘플이 네트워크에 따라 클래스 i에 속할 확률을 나타낸다).

:bulb: 네트워크의 원시 예측(즉, 정규화 전)을 일반적으로 로지트(logit)라고 부른다. 이러한 제한되지 않은 값은 일반적으로 softmax 함수를 사용해 확률로 전환된다. 이 정규화 프로세스는 예측에 대한 가독성을 좀 더 좋게 만들고(각 값은 네트워크가 해당 클래스로 얼마나 확신하는지를 나타낸다.) 훈련 손실(즉, 분류 작업에서 범주형 교차 엔트로피) 계산을 단순화한다.

### 텐서플로와 케라스 구현

### MNIST에 적용

## 3.3. 훈련 프로세스 개선

### 3.3.1. 현대 네트워크 최적화 기법

### 경사 하강법의 까다로운 점

학습률 초매개변수 값 epsilon을 사용하면 훈련이 반복될 때마다 손실 경사에 따라 네트워크 매개변수가 업데이트되는 방식을 강화하거나 약화시킨다. 학습률 값은 신중하게 설정해야 한다고 언급했지만, 그 방법과 이유에 대해서는 자세히 설명하지 않았다. 이렇게 주의해서 설정해야 할 이유는 세 가지다.

### A. 훈련 속도와 트레이드오프

학습률을 높게 설정하면 훈련된 네트워크가 빠르게 수렴하지만(즉 훈련이 반복될 때마다 매개변수가 크게 업데이트되므로 반복 횟수가 줄어든다). 네트워크가 적절한 최소 손실값을 구하지 못할 수 있다. 

학습률을 과도하게 낮게 잡으면 수렴하는 데까지 오래 걸리고 과도하게 높게 잡으면 극솟값을 지나쳐 버릴 수 있다.

잘 알려진 방법으로 훈련시키는 동안 학습률을 동적으로 조정하는 방법이 있는데, 큰 값으로 시작해서(처음에는 손실 도메인을 빠르게 학습하기 위해) 세대가 넘어갈 때마다 학습률을 감소시킨다(최솟값에 가까워질수록 좀 더 주의를 기울여 업데이트하기 위해). 이 과정을 학습률 감소(learning rate decay)라고 한다. 여전히 수많은 구현에서 수작업으로 학습률을 감소시키지만, 오늘날 텐서플로에서는 더 진화된 형태의 '학습률 스케줄러'와 '적응형 학습률을 적용하는 최적화기'를 제공한다.

### B. 준최적 극솟값(Suboptimal local minima)

복잡한(즉, '볼록하지 않은, non-vonvex') 메서드를 최적화할 때 나타나는 일반적인 문제는 최적이 아닌 준최적 극솟값에 막힌다는 점이다. 실제로 경사 하강법은 '더 나은' 최솟값이 가까이 있더라도 벗어날 수 없는 극솟값으로 귀결될 수 있다.

SGD는 훈련 샘플을 랜덤 샘플링하기 때문에(경사가 종종 미니 배치마다 다르기 때문에) 얕은 극솟값에서 '벗어날 수 있다'.

경사 하강 프로세스를 사용한다고 최솟값으로 수렴한다는(즉 가능한 모든 조합 중에 최선의 매개변수 집합으로 수렴한다는) 보장은 없다. 그런 보장을 하려면 주어진 최솟값이 실제로 '최선'(이는 예르르 들어 모든 가능한 매개변수 조합에 대해 손실을 계산함을 의미한다)인지 확인하기 위해 전체 손실 도메인을 스캔해야 함을 뜻한다. 시각 작업의 복잡도와 이를 해결하는 데 필요한 수많은 매개변수를 고려할 때 데이터 과학자는 일반적으로 만족할 만한 수준의 극솟값을 구하기만 해도 조하할 것이다.

### C. 이기종 매개변수를 위한 단일 초매개변수

전통적인 경사 하강법에서는 동일한 학습률이 네트워크의 모든 매개변수를 업데이트하는 데 사용된다. 그렇지만 이 모든 변수가 변화에 동일한 민감도를 갖지 않으며, 반복할 때마다 모든 변수가 손실에 영향을 주지 않는다.

결정적인 매개변수를 좀 더 신중하게 업데이트하기 위해 학습률을 다르게 적용하고(예를 들어, 매개변수 하위집합 단위로), 네트워크 예측에 충분히 기여하지 않는 매개변수는 좀 더 과감하게 업데이트하는 것이 이로울 수 있다.

### 고급 최적화 기법

### A. 모멘텀 알고리즘

모멘텀 알고리즘은 SGD을 기반으로 하며 물리학 개념인 모멘텀(물체가 내리막길을 따라 움직이는 동안 단계마다 속도가 증가한다)에서 영감을 얻었다. 이 개념을 경사 하강법에 적용하면 이전에 업데이트한 매개변수 v_(i-1)을 받아 새로운 업데이트 항 v_i에 다음과 같이 더한다.

v_i = epsilon * dL_i/dP_i + mu * v_(i-1)

여기에서 mu는 모멘텀 측정값(0~1 사이 값)으로 이전 업데이트 값을 어느 정도 비율로 적용할지 정의한다. 이전과 현재 단계가 같은 방향이라면 모멘텀을 더해서 SGD를 그 방향으로 가속화시킨다. 방향이 다르다면 모멘텀은 이 진동을 약화시킬 것이다. 

모멘텀 메서드의 주요 문제는 네트워크가 손실 최솟값에 실제로 가까이 다가갈 때 누적 모멘텀이 일반적으로 너무 높아서 메서드가 타깃 최솟값을 놓치거나 그 주변을 왔다갔다할 수 있다는 점이다.

네스테로프 가속 경사(NAG, Nesterov accelerated gradient, 네스테로프 모멘텀)가 이 문제에 해결책을 제공한다. 1980년대에 유리 네스테로프(Yurri Nesterov)는 최적화기가 미리 경사를 확인할 수 있게 해 경사가 가팔라지면 속도를 늦춰야 한다는 것을 '알게 하자'는 아이디어를 제시했다. 좀 더 공식화해서 설명하면, 네스테로프는 이 방향을 계속 따를 경우 매개변수 P_(i+1)이 어느 값을 취하게 될지 추정하기 위해 직접 과거항 v_(i-1)을 재활용할 것을 제안한다. 그런 다음 이 추정한 미래 매개변수와 관련해 경사를 평가하고 마지막으로 실제 업데이트를 계산할 때 다음과 같이 사용한다.

P_(i+1) <- P_i - v_i

여기에서

v_i = epsilon * dL_i/d(P_i - mu * v_(i-1)) + mu * v_(i-1)

이 버전의 모멘텀 최적화기(손실이 이전 단계에 따라 업데이트된 매개변수 값에 대해 유도되는)는 경사 변화에 좀 더 적응해 경사 하강 프로세스의 속도를 상당히 높일 수 있다.

### B. Ada 군

Adagrad, Adadelta, Adam 등은 각 뉴런의 민감도 및 활성화 빈도에 따라 학습률을 조정하는 아이디어에 몇 가지 반복과 변형을 준 알고리즘이다.

'Adagrad' 최적화기(적응형 경사를 위한)는 깔끔한 공식을 사용해 일반적으로 발견할 수 있는 특징과 연결된 매개변수에 대해서는 자동으로 학습률을 더 빠르게 감소시키고, 드물게 발견되는 특징은 더 천천히 감소시킨다. 다른 말로 케라스 문서에서 설명한 대로 '매개변수 업데이트가 잦을수록 업데이트 크기는 작아진다'. 이 최적화 알고리즘을 사용하면 직접 학습률을 감소(adapt/decay)시키지 않아도 되고, SGD 프로세스는 특히 희소 표현을 갖는 데이터셋에 대해 좀 더 안정적으로 수행된다.

'Adadelta'는 'Adagrad'에 내재된 한 가지 문제에 대한 해답으로 제안한 방법이다. 반복할 때마다 학습률을 계속 감소시키면 어느 시점에는 학습률이 너무 작아 네트워크가 더이상 학습할 수 없게 된다(흔치 않은 매개변수를 제외하고). 'Adadelta'는 매개변수마다 학습률을 나누기 위해 사용되는 요인을 지속적으로 확인함으로써 이 문제를 방지한다.

:bulb: 제프리 힌튼의 RMSprop는 잘 알려진 또 다른 최적화기다. 동시에 'Adagrad'의 결함을 수정하기 위해 'Adadelta'와 유사한 'RMSprop'도 개발됐다.

Adam(Adaptive moment estimation, 적응형 모멘트 추정)은 또 다른 반복 계산법이다. 'Adam'은 매개변수마다 학습률을 조정하기 위해 이전 업데이트 항 v_i를 저장할 뿐 아니라 과거 모멘텀 값을 기록한다. 따라서 이 방법은 종종 'Adadelta'와 '모멘텀'의 혼합형으로 이해하기도 한다. Nadam은 'Adadelta'와 'NAG'로부터 상속받은 최적화기다.

부족한 데이터에서의 효과성 때문에 수많은 컴퓨터 비전 전문가들은 'Adam'을 선호한다. 'RMSprop'은 대체로 순환 신경망에 사용하기 적절한 것으로 간주된다.

### 3.3.2. 정규화 기법

신경망을 효율적으로 가르쳐서 훈련 데이터에서 손실을 최소화하는 것만으로 충분하지 않다. 이 네트워크를 새로운 이미지에 적용했을 때도 잘 수행돼야 한다. 다시 말하면 훈련 집합에 과적합 되지 않아야 한다. 네트워크 일반화에 성공하려면 풍부한 훈련 집합(가능한 테스트 시나리오를 다루기에 충분한 다양성을 갖춘)과 잘 정의된 아키텍처(과소적합을 피하기에 너무 얕거나 과적합을 방지하기에 너무 복잡하지 않은)가 핵심이다. 그렇지만 이와 별개로 과적합을 피하기 위한 최적화 단계를 정교화하는 프로세스인 정규화(Regularization)를 위한 다른 기법들도 수년간 개발돼 왔다.

### A. 조기 중단

신경망은 동일한 작은 훈련 샘플 집합에 대해 너무 여러 번 반복하면 과적합되기 시작한다. 따라서 이 문제를 피하기 위한 단순한 해법은 모델에서 필요한 적정한 훈련 세대 수를 알아내는 것이다. 훈련 세대 수는 네트워크가 과적합되기 시작하기 전에 종료시킬 수 있을 만큼 충분히 낮아야 하지만, 그 훈련 집합에서 모든 것을 배울 수 있을 만큼은 높아야 한다.

훈련 과정이 중단될 때를 검증하는 데 있어 핵십은 교차 검증(Cross-validation)이다. 검증 데이터셋을 최적화기에 제공함으로써 네트워크가 직접 최적화되지 않았던 이미지에서 모델 성능을 측정할 수 있다. 예를 들어, 각 세대 이후 네트워크를 '검증'함으로써 훈련을 계속해야 할지(즉, 검증 정확도가 여전히 증가하는 것으로 보이는 경우) 중단해야 할지(즉, 검증 정확도가 정체되거나 떨어지는 경우)를 측정할 수 있다. 후자를 조기 중단(early-stopping)이라 한다.

실제로도 훈련을 반복할 때마다 일반적으로 검증 손실과 메트릭을 모니터링하고 그래프를 그리고 최적의 수준에서 저장된 가중치를 복원한다(따라서 훈련하는 동안 네트워크를 정기적으로 저장하는 것이 중요하다). 이 모니터링, 조기 중단, 최적 가중치의 복원은 앞선 훈련에서 이미 보여줬듯이 선택적인 케라스 '콜백' 중 하나(`tf.keras.callbacks.EarlyStop`)에서 자동으로 처리한다.

### B. L1, L2 정규화

### 원리

### 텐서플로와 케라스 구현

### C. 드롭아웃

### 정의

### 텐서플로 및 케라스 메서드

### D. 배치 정규화

### 정의

#### 텐서플로 및 케라스 메서드

## 3.4. 요약

- CNN은 현대 컴퓨터 비전과 머신러닝에서 가장 중요한 위치를 차지하기 때문에 CNN이 어떻게 동작하고 어떤 종류의 계층으로 구성되는지 이해하는 것이 중요함
- 텐서플로와 케라스는 그러한 네트워크를 효율적으로 구성할 수 있는 쉬운 인터페이스를 제공함
- 모든 애플리케이션에서 염두에 둬야 할 중요한 점인 훈련된 모델의 성능과 견고함을 개선하기 위해 몇 가지 고급 최적화 기법과 정규화 기법(다양한 최적화기, L1/L2 정규화, 드롭아웃, 배치 정규화 등)을 구현함

## 3.5. 질문

## 3.6. 참고 문헌

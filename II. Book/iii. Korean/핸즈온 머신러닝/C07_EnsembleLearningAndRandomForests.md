# CHAPTER 7 앙상블 학습과 랜덤 포레스트
무작위로 선택된 수천 명의 사람에게 복잡한 질문을 하고 대답을 모든다고 가정합시다. 많은 경우 이렇게 모은 답이 전문가의 답보다 낫습니다. 이를 대중의 지혜<sup>wisdom of the crowd</sup>라고 합니다. 이와 비슷하게 일련의 예측기(즉, 분류나 회귀 모델)로부터 예측을 수집하면 가장 좋은 모델 하나보다 더 좋은 예측을 얻을 수 있을 것입니다. 일련의 예측기를 앙상블이라고 부르기 때문에 이를 앙상블 학습<sup>Ensemble Learning</sup>이라고 하며, 앙상블 학습 알고리즘을 앙상블 방법<sup>Ensemble method</sup>이라고 합니다.

예를 들어 훈련 세트로부터 무작위로 각기 다른 서브셋을 만들어 일련의 결정 틜 분류기를 훈련시킬 수 있습니다. 예측을 하려면 모든 개별 트리의 예측을 구하면 됩니다. 그런 다음 가장 많은 선택을 받은 클래스를 예측으로 삼습니다. 결정 트리의 앙상블을 랜덤 포레스트<sup>Random Forest</sup>라고 합니다. 간단한 방법임에도 랜덤 포레스트는 오늘날 가장 강력한 머신러닝 알고리즘 중 하나입니다.

게다가 프로젝트의 마지막에 다다르면 흔히 앙상블 방법을 사용하여 이미 만든 여러 괜찮은 예측기를 연결하여 더 좋은 예측기를 만듭니다. 사실 머신러닝 경연 대회에서 우승하는 솔루션은 여러 가지 앙상블 방법을 사용한 경우가 많습니다. 이는 특히 넷플릭스 대회에서 가장 인기 있습니다.

이 장에서는 배깅, 부스팅, 스태킹 등 가장 인기 있는 앙상블 방법을 설명하겠습니다. 랜덤 포레스트도 다룰 것입니다.

## 7.1 투표 기반 분류기

## 7.2 배깅과 페이스팅
훈련 세트에서 중복을 허용하여 샘플링하는 방식을 배깅<sup>bagging</sup>(bootstrap aggregating의 줄임말)이라 하며, 중복을 허용하지 않고 샘플링하는 방식을 페이스팅<sup>pasting</sup>이라고 합니다. 통계학에서는 중복을 허용한 리샘플링(resampling)을 부트스트래핑(bootstrapping)이라고 합니다.

다시 말해 배깅과 페이스팅에서는 같은 훈련 샘플을 여러 개의 예측기에 걸쳐 사용할 수 있습니다. 하지만 배깅만이 한 예측기를 위해 같은 훈련 샘플을 여러 번 샘플링할 수 있습니다.

모든 예측기가 훈련을 마치면 앙상블은 모든 예측기의 예측을 모아서 새로운 샘플에 대한 예측을 만듭니다. 수집 함수는 전형적으로 분류일 때는 통계적 최빈값<sup>statistical mode</sup>(즉, 직접 투표 분류기처럼 가장 많은 예측 결과)이고 회귀에 대해서는 평균을 계산합니다. 개별 예측기는 원본 훈련 세트로 훈련시킨 것보다 훨씬 크게 편향되어 있지만 수집 함수를 통과하면 편향과 분산이 모두 감소합니다.

예측기는 모두 동시에 다른 CPU 코어나 서버에서 병렬로 학습시킬 수 있습니다. 이와 유사하게 예측도 병렬로 수행할 수 있습니다. 이런 확장성 덕분에 배깅과 페이스팅의 인기가 높습니다.

### 7.2.1 사이킷런의 배깅과 페이스팅
사이킷런은 배깅과 페이스팅을 위해 간편한 API로 구성된 BaggingClassifier(회귀의 경우에는 BaggingRegressor)를 제공합니다. 다음은 결정 트리 분류기 500개의 앙상블을 훈련시키는 코드입니다. 각 분류기는 훈련 세트에서 중복을 허용하여 무작위로 선택된 100개의 샘플로 훈련됩니다(이는 배깅의 경우이고, 대신 페이스팅을 사용하려면 boostarp=False로 지정하면 됩니다). n_jobs 매개변수는 사이킷런이 훈련과 예측에 사용할 CPU 코어 수를 지정합니다(-1로 지정하면 가용한 모든 코어를 사용합니다).

```Python
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier

bag_clf = BaggingClassifier(
  DecisionTreeClassifier(), n_estimators=500,
  max_samples=100, bootstrap=True, n_jobs=-1
)
bag_clf.fit(X_train, y_train)
y_pred = bag_clf.predict(X_test)
```

:bulb: NOTE_ BaggingClassifier는 기반이 되는 분류기가 결정 트리 분류기처럼 클래스 확률을 추정할 수 있으면(즉, predict_proba() 함수가 있으면) 직접 투표 대신 자동으로 간접 투표 방식을 사용합니다.

앙상블의 예측이 결정 트리 하나의 예측보다 일반화가 훨씬 잘된 것 같습니다. 앙상블은 비슷한 편향에서 더 작은 분산을 만듭니다(훈련 세트의 오차 수가 거의 비슷하지만 결정 경계는 덜 불규칙합니다).

부트스프래핑은 각 예측기가 학습하는 서브셋에 다양성을 증가시키므로 베깅이 페이스팅보다 편향이 조금 더 높습니다. 하지만 이는 예측기들의 상관관계를 줄이므로 앙상블의 분산을 감소시킵니다. 전반적으로 베깅이 더 나은 모델을 만들기 때문에 일반적으로 더 선호합니다. 그러나 시간과 CPU 파워에 여유가 있다면 교차 검증으로 베깅과 페이스팅을 모두 평가해서 더 나은 쪽을 선택하는 것이 좋습니다.

### 7.2.2 oob 평가
베깅을 사용하면 어떤 샘플은 한 예측기를 위해 여러 번 샘플링되고 어떤 것은 전혀 선택되지 않을 수 있습니다. BaggingClassifier는 기본값으로 중복을 허용하여(bootstrap=True) 훈련 세트의 크기 만큼인 m개 샘플을 선택합니다. 이는 평균적으로 각 예측기에 훈련 샘플의 63% 정도만 샘플링된다는 것을 의미합니다. 선택되지 않은 훈련 샘플의 나머지 37%를 oob<sup>out-of-bag</sup> 샘플이라고 부릅니다. 예측기마다 남겨진 37%는 모두 다릅니다.

예측기가 훈련되는 동안에 oob 샘플을 사용하지 않으므로 검증 세트나 교차 검증을 사용하지 않고 oob 샘플을 사용해 평가할 수 있습니다. 앙상블의 평가는 각 예측기의 oob 평가를 평균하여 얻습니다.

사이킷런에서 BaggingClassifier를 만들 때 oob_score=True로 지정하면 훈련이 끝난 후 자동으로 oob 평가를 수행합니다. 다음 코드는 이 과정을 보여줍니다. 평가 점수 결과는 oob_score_ 변수에 저장되어 있습니다.

```Python
>>> bag_clf = BaggingClassifier(
...   DecisionTreeClassifier(), n_estimators=500,
...   bootstrap=True, n_jobs=-1, oob_score=True)
...
>>> bag_clf.fit(X_train, y_train)
>>> bag_clf.oob_score_
0.90133333
```

oob 평가 결과를 보면 이 BaggingClassifier는 테스트 세트에서 약 90.1%의 정확도를 얻을 것으로 보입니다.

```Python
>>> from sklearn.metrics import accuracy_score
>>> y_pred = bag_clf.predict(X_test)
>>> accuracy_score(y_test, y_pred)
0.912
```

테스트 세트에서 91.2%의 정확도를 얻었습니다.

oob 샘플에 대한 결정 함수의 값도 oob_decision_function_ 변수에서 확인할 수 있습니다. 이 경우 결정 함수는 각 훈련 샘플의 클래스 확률을 반환합니다(기반이 되는 예측기가 predict_proba() 메서드를 가지고 있기 때문에). 다음 예를 보면 oob 평가는 첫 번째 훈련 샘플이 양성 클래스에 속할 확률을 68.25%로 추정하고 있습니다(그리고 음성 클래스에 속할 확률은 31.75%입니다).

```Python
>>> bag_clf.oob_decision_function_
array([[ 0.31746032, 0.68253968],
       [       ... ,        ...],
       ...
       [       ... ,        ...]])
```

## 7.3 랜덤 패치와 랜덤 서브스페이스

## 7.4 랜덤 포레스트

### 7.4.1 엑스트라 트리

### 7.4.2 특성 중요도

## 7.5 부스팅
부스팅<sup>boosting</sup>(원래는 가설 부스팅<sup>hypothesis boosting</sup>이라 불렀습니다)은 약한 학습기를 여러 개 연결하여 강한 학습기를 만드는 앙상블 방법을 말합니다. 부스팅 방법의 아이디어는 앞의 모델을 보완해나가면서 일련의 예측기를 학습시키는 것입니다. 부스팅 방법에는 여러 가지가 있지만 가장 인기 있는 것은 아다부스트<sup>AdaBoost</sup>(Adaptive Boosting의 줄임말)와 그래디언트 부스팅<sup>Gradient Boosting</sup>입니다.

### 7.5.1 아다부스트

### 7.5.2 그래디언트 부스팅

## 7.6 스태킹
이 장에서 이야기할 마지막 앙상블 모델은 스태킹<sup>stacking</sup>(stacked generalization의 줄임말)입니다. 이는 '앙상블에 속한 모든 예측기의 예측을 취합하는 간단한 함수(직접 투표 같은)를 사용하는 대신 취합하는 모델을 훈련시킬 수 없을까요?'라는 기본 아이디어로 출발합니다. 각각 다른 값을 예측하고 마지막 예측기 (블렌더<sup>blender</sup> 또는 메타 학습기<sup>meta learner</sup>라고 합니다)가 이 예측을 입력으로 받아 최종 예측을 만듭니다.

블렌더를 학습시키는 일반적인 방법은 홀드 아웃<sup>hold-out</sup> 세트를 사용하는 것입니다. 어떻게 작동하는지 살펴보겠습니다. 먼저 훈련 세트를 두 개의 서브셋으로 나눕니다. 첫 번째 서브셋은 첫 번째 레이어의 예측을 훈련시키기 위해 사용됩니다.

그런 다음 첫 번째 레이어의 예측기를 사용해 두 번째 (홀드 아웃) 세트에 대한 예측을 만듭니다. 예측기들이 훈련하는 동안 이 샘플들을 전혀 보지 못했기 때문에 이때 만들어진 예측은 완전히 새로운 것입니다. 이제 홀드 아웃 세트의 각 샘플에 대해 세 개의 예측값이 만들어집니다. 타깃값은 그대로 쓰고 앞에서 예측한 값을 입력 특성으로 사용하는 새로운 훈련 세트를 만들 수 있습니다(새로운 훈련 세트는 3차원이 됩니다). 블렌더가 새 훈련 세트로 훈련됩니다. 즉, 첫 번째 레이어의 예측을 가지고 타깃값을 예측하도록 학습됩니다.

사실 이런 방식의 블렌더를 여러 개 훈련시키는 것도 가능합니다(예를 들어 하나는 선형 회귀로, 다른 하나는 랜덤 포레스트 회귀로, 등등). 그러면 블렌더만의 레이어가 만들어지게 됩니다. 이렇게 하려면 훈련 세트를 세 개의 서브셋으로 나눕니다. 첫 번째 세트는 첫 번째 레이어를 훈련시키는 데 사용되고 두 번째 세트는 (첫 번째 레이어의 예측기로) 두 번째 레이어를 훈련시키기 위한 훈련 세트를 만드는 데 사용됩니다. 그리고 세 번째 세트는 (두 번째 레이어의 예측기로) 세 번째 레이어를 훈련시키기 위한 훈련 세트를 만드는 데 사용됩니다. 작업이 끝나면 각 레이어를 차례대로 실행해서 새로운 샘플에 대한 예측을 만들 수 있습니다.

안타깝게도 사이킷런은 스태킹을 직접 지원하지 않습니다. 하지만 직접 구현하는 것이 그리 어렵지는 않습니다. 아니면 brew 같은 오픈소스 구현을 사용할 수 있습니다.

## 7.7 연습문제

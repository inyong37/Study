# CHAPTER 2 머신러닝 프로젝트 처음부터 끝까지
이 장에서는 여러분이 부동산 회사에 막 고용된 데이터 과학자라고 가정하고 예제 프로젝트의 처음부터 끝까지 진행해보겠습니다. 진행할 주요 단계는 다음과 같습니다.

1. 큰 그림을 봅니다.
2. 데이터를 구합니다.
3. 데이터로부터 통찰을 얻기 위해 탐색하고 시각화합니다.
4. 머신러닝 알고리즘을 위해 데이터를 준비합니다.
5. 모델을 선택하고 훈련시킵니다.
6. 모델을 상세하게 조정합니다.
7. 솔루션을 제시합니다.
8. 시스템을 론칭하고 모니터링하고 유지 보수합니다.

:bulb: 파이프라인

데이터 처리 컴포넌트(Component)들이 연속되어 있는 것을 데이터 파이프라인(Pipeline)이라고 합니다. 머신러닝 시스템은 데이터를 조작하고 변환할 일이 많아 파이프라인을 사용하는 일이 매우 흔합니다.

보통 컴포넌트들은 비동기적으로 동작합니다. 각 컴포넌트는 많은 데이터를 추출해 처리하고 그 결과를 다른 데이터 저장소로 보냅니다. 그러면 일정 시간 후 파이프라인의 다음 컴포넌트가 그 데이터를 추출해 자신의 출력 결과를 만드는 식입니다. 각 컴포넌트는 완전히 독립적입니다. 즉, 컴포넌트 사이의 인터페이스는 데이터 저장소뿐입니다. 이는 (데이터 흐름도 덕분에) 시스템을 이해하기 쉽게 만들고, 각 팀은 각자의 컴포넌트에 집중할 수 있습니다. 한 컴포넌트가 다운되더라도 하위 컴포넌트는 문제가 생긴 컴포넌트의 마지막 출력을 사용해 (적어도 한동안은) 평상시와 같이 계속 동작할 수 있습니다. 그래서 시스템이 매우 견고해집니다.

한편 모니터링이 적절히 되어 있지 않으면 고장 난 컴포넌트를 한동안 모를 수 있습니다. 데이터가 만들어진지 오래 되면 전체 시스템의 성능이 떨어집니다.

### 2.2.2 성능 측정 지표 선택
회귀 문제의 전형적인 성능 지표는 평균 제곱근 오차(Root Mean Square Error, RMSE) 입니다. 오차가 커질수록 이 값은 더욱 커지므로 예측에 얼마나 많은 오류가 있는지 가늠하게 해줍니다.

RMSE(X, h) = squr( 1/m * sum( h(x[i] - y[i] ) **2 ) ... [eq.2.1]

:bulb: 표기법

- m은 RMSE를 측정할 데이터셋에 있는 샘플 수 입니다. 예를 들어 2000개의 구역의 검증 세트에 대해 RMSE를 평가한다면 m=2000입니다.
- x[i]는 데이터셋에 있는 i번째 샘플(레이블은 제외한)의 전체 특성값의 벡터이고, y[i]는 해당 레이블(해당 샘플의 기대 출력값)입니다. 예를 들어 데이터셋에 있는 첫 번째 구역이 경도 -118.29, 위도 33.91에 위치하고, 중간 소득이 $38372이며, 주민이 1416명, 중간 주택 가격이 $156400이라면 x[i]과 y[i]는 다음과 같습니다.

x[1] = (-118.29, 33.91, 1416, 38372).T

y[1] = 156400

- X는 데이터셋에 있는 모든 샘플의 모든 특성값(레이블은 제외)을 포함하는 행렬입니다. 샘플 하나가 하나의 행이어서 i번째 행은 x[i]의 전치와 같고 x[i].T으로 표기합니다. 예를 들어 첫 번째 구역이 앞의 예와 같다면 행렬 X는 다음과 같습니다.

X = ( x[1].T, x[2].T, ..., x[1999].T, x[2000].T ).T = (-118.29 33.91 1416 38372 , ... )

- h는 시스템의 예측 함수며 가설(hypothesis)이라고도 합니다. 시스템이 하나의 샘플 특성 벡터 x[i]를 받으면 그 샘플에 대한 예측값 y-hat[i] = h(X[i])를 출력합니다. 예를 들어 시스템이 첫 번째 구역의 중간 주택 가격을 $158400이라고 예측한다면 y-hat[i] = h(X[i]) = 158400입니다. 이 구역에 대한 예측 오차는 y-hat[1] - y[1] = 2000입니다.
- RMSE(X, h)는 가설 h를 사용하여 일련의 샘플을 평가하는 비용 함수입니다.

이 책에서는 스칼라 값이나 함수를 나타낼 때는 이탤릭체 소문자, 벡터를 나타낼 때는 굵은 소문자, 행렬을 나타낼 때는 굵은 대문자를 사용합니다.

RMSE가 일반적으로 회귀 문제에 선호되는 성능 측정 방법이지만 경우에 따라 따른 함수를 사용할 수도 있습니다. 예를 들어 이상치로 보이는 구역이 많다고 가정합시다. 이런 경우에는 평균 절대 오차(Mean Absolute Error, 평균 절대 편차, Mean Absolte Deviation)를 고려해볼 수 있습니다.

MAE(X, h) = 1/m * sum( abs( h(x[i] - y[i]) ) ... [eq.2.2]

RMSE와 MAE 모두 예측 값의 벡터와 타깃값의 벡터 사이의 거리를 재는 방법입니다. 거리 측정에는 여러 가지 방법 (또는 노름, Norm)이 가능합니다.

- 제곱항을 합한 것의 제곱근(RMSE) 계산은 유클리디안 노름(Euclidean Norm)에 해당합니다. 우리와 친숙한 거리 개념입니다. 또는 l2 노름이라고도 부르며 ||.||2 (또는 그냥 ||.||)로 표시합니다.
- 절댓값의 합을 계산하는 것은 l1 노름에 해당하며 ||.||1로 표기합니다. 이는 도시의 구획이 직각으로 나뉘어 있을 때 이 도시의 두 지점 사이의 거리를 측정하는 것과 같아 맨해튼 노름(Manhattan Norm)이라고도 합니다.
- 일반적으로 원소가 n개인 벡터 v의 lk 노름은 ||v||k = (|v[0]| ** k + |v[1]| ** k + ... + |v[n]| ** k) ** (1/k)으로 정의합니다. l0은 단순히 벡터에 있는 0이 아닌 원소의 수이고, l inf는 벡터에서 가장 큰 절댓값이 됩니다.
- 노름의 지수가 클수록 큰 값의 원소에 치우치며 작은 값은 무시됩니다. 그래서 RMSE가 MAE보다 조금 더 이상치에 민감합니다. 하지만 (종 모양 분포의 양 끝단처럼) 이상치가 매우 드물면 RMSE가 잘 맞아 일반적으로 널리 사용됩니다.

## 2.6 모델 선택과 훈련
문제를 정의한 후 데이터를 읽어 들이고 탐색했습니다. 그리고 훈련 세트와 테스트 세트로 나누고 머신러닝 알고리즘에 주입할 데이터를 자동으로 정제하고 준비하기 위해 변환 파이프라인을 작성했습니다. 이제 머신러닝 모델을 선택하고 훈련시킬 준비가 되었습니다.

### 2.6.1 훈련 세트에서 훈련하고 평가하기

### 2.6.2 교차 검증을 사용한 평가

## 2.7 모델 세부 튜닝

### 2.7.1 그리드 탐색
가장 단순한 방법은 만족할 만한 하이퍼파라미터 조합을 찾을 때까지 수동으로 하이퍼파라미터를 조정하는 것입니다. 이는 매우 지루한 작업이고 많은 경우의 수를 탐색하기에는 시간이 부족할 수도 있습니다.

대신 사이킷런의 GirdSearchCV를 사용하는 것이 좋습니다. 탐색하고자 하는 하이퍼파라미터와 시도해볼 값을 지정하기만 하면 됩니다. 그러면 가능한 모든 하이퍼파라미터 조합에 대해 교차 검증을 사용해 평가하게 됩니다. 예를 들어 다음 코드는 RandomForestRegressor에 대한 최적의 하이퍼파라미터 조합을 탐색합니다.

:bulb: 어떤 하이퍼파라미터 값을 지정해야 할지 모를 때는 연속된 10의 거듭제곱 수로 시도해보는 것도 좋습니다(더 세밀하게 탐색하려면 위 예제의 n_estimators 하이퍼파라미터처럼 더 작은 값을 지정합니다).

```Python
>>> grid_search.best_params_
{'max_features': 8, 'n_estimators': 30}
```

:bulb: 8과 30은 탐색 범위의 최댓값이기 때문에 계속 점수가 향상될 가능성이 있으므로 더 큰 값으로 다시 검색해야 합니다.

최적의 추정기에 직접 접근할 수도 있습니다.

```Python
>>> grid_search.best_estimator_
```

:bulb: NOTE `GridSearchCV`가 (기본값인) refit=True로 초기화되었다면 교차 검증으로 최적의 추정기를 찾은 다음 전체 훈련 세트로 다시 훈련시킵니다. 일반적으로 데이터가 많을수록 성능이 향상되므로 좋은 방법입니다.

물론 평가 점수도 확인할 수 있습니다.

```Python
>>> cvres = grid_search.cv_results_
>>> for mean_score, params in zip(cvres["mean_test_score"], cvres["params"]):
...   print(np.sqrt(-mean_score), params)
...
```

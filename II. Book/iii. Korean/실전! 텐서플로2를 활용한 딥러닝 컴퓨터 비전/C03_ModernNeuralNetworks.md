# 03 현대 신경망

## 기술 요구사항

## 합성곱 신경망의 발견

### 다차원 데이터를 위한 신경망

#### 완전 연결 네트워크의 문제점
이미지를 처리할 때 기초 네트웤가 갖는 두 가지 주요 단점은 다음과 같다.

- 매개변수의 폭발적인 증가
- 공간 추론의 부족

#### 매개변수의 폭발적인 증가
이미지는 H * W * D 값으로 이루어진다. H는 이미지 높이, W는 이미지 너비, D는 이미지의 깊이 혹은 채널 개수(RGB 이미지의 경우 D=3)이다. 예를 들어, MNIST 이미지의 경우 작은 단일 채널 이미지도 28 * 28 * 1 = 784개의 값으로 이루어진 입력 벡터를 가지고, 첫 번째의 계층이 64개의 노드로 이루어져 있으면 (784, 64) 형상의 weight vector를 가진다. 이 때 이 변수만을 최적화해야 할 매개변수의 값은 784 * 64 = 50176개이다. RGB 이미지가 커지거나 네트워크가 깊어질수록 '이 매개변수 개수는 매우 급격히 증가한다.'

#### 공간 추론의 부족
이 네트워크의 뉴런이 어떤 구분 없이 이전 계층의 모든 값을 받기 때문에('뉴런이 모두 연결되어 있다.) 이 신경망은 '거리/공간성'이 없다. 데이터의 공간 관계를 잃는다. 이미지 같은 다차원 데이터는 밀접 계층에 칼럼 벡터로 전달될 수 있기 때문에 그 연산은 데이터 차원이나 입력값의 위치를 고려하지 않는다. 더 정확하게는 모든 픽셀 값이 계층별로 '원래 위치와 상관없이' 결합되므로 픽셀 사이의 근접성 개념이 완전 연결(FC, Fully-Connected) 계층에서 손실된다.

:bulb: 평면화(Flatten)를 해도 밀집 계층의 행위가 바뀌지 않으므로 밀집 계층의 계산과 매개변수 표현을 단순화하기 위해 밀집 계층에 전달하기 전에 다차원 입력을 '1차원으로 변환'하는 것(즉 컬럽 벡토로 형상을 바꾸는 것)이 보편적이다.

CNN은 다차원 데이터를 처리할 수 있다. 이미지의 경우, CNN은 3차원 데이터(높이 * 너비 * 깊이)를 입력으로 취하고 뉴런을 그와 비슷한 볼륨으로 정렬한다. CNN의 각 뉴런은 이전 계층에서 이웃한 영역에 속한 일부 요소에만 접근한다. 이 영역을 뉴런의 '수용 영역' 또는 '필터 크기'라 한다. 뉴런을 이전 계층의 이웃한 뉴런과만 연결함으로써 CNN은 훈련시킬 '매개변수 개수를 급격히 줄일'뿐 아니라 '이미지 특징의 위치 정보를 보존'한다.

### CNN 작업
이 아키텍처 패러다임으로 새로운 유형의 계층도 도입해 '다차원성'과 '지역적 연결성'을 효율적으로 활용한다.

### 유효 수용 영역

### 텐서플로로 CNN 구현하기

## 훈련 프로세스 개선

### 현대 네트워크 최적화 기법

### 정규화 기법

## 요약
- CNN은 현대 컴퓨터 비전과 머신러닝에서 가장 중요한 위치를 차지하기 때문에 CNN이 어떻게 동작하고 어떤 종류의 계층으로 구성되는지 이해하는 것이 중요함
- 텐서플로와 케라스는 그러한 네트워크를 효율적으로 구성할 수 있는 쉬운 인터페이스를 제공함
- 모든 애플리케이션에서 염두에 둬야 할 중요한 점인 훈련된 모델의 성능과 견고함을 개선하기 위해 몇 가지 고급 최적화 기법과 정규화 기법(다양한 최적화기, L1/L2 정규화, 드롭아웃, 배치 정규화 등)을 구현함

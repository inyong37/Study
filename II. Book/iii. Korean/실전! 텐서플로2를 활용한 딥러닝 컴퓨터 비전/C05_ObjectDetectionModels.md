# 05 객체 탐지 모델
최신 기법 중 가장 일반적으로 사용되는 두 모델인 YOLO(You Only Look Once)와 R-CNN(Regions with Convolutional Neural Networks) 아키텍처를 설명한다.

- 객체 탐지 기법의 역사
- 주요 객체 탐지 방법
- YOLO 아키텍처를 사용해 빠른 객체 탐지 구현하기
- Faster R-CNN 아키텍처를 사용해 객체 탐지 성능 개선하기
- 텐서플로 객체 탐지 API로 Faster R-CNN 사용하기

## 기술 요구사항

## 객체 탐지 소개

### 배경
객체 탐지(Object Detection) 또는 객체 위치 특정(Object Localization)이라고도 하는 이 프로세스는 한 이미지에서 객체와 그 경계 상자를 탐지한다. 경계 상자(Bounding Box)는 이미지에서 하나의 객체 전체를 포함하는 가장 작은 직사각형이다.

객체 탐지 알고리즘에서는 일반적으로 이미지를 입력으로 받고 경계 상자와 객체 클래스 리스트를 출력한다. 모델은 각 경계 상자에 대해 그에 대응하는 예측 클래스와 해당 클래스의 신뢰도(Confidence)를 출력한다. 

#### 애플리케이션

#### 약력
객체 탐지는 전통적인 컴퓨터 비전 기법인 이미지 설명자(Image Descriptors)를 기반으로 한다. 예를 들어 자전거 같은 객체를 탐지하려면 이 객체가 포함된 몇 장의 사진으로 시작한다. 자전거에 해당하는 설명자는 이미지로부터 추출된다. 그 설명자는 이미지로부터 추출된다. 그 설명자는 자전거의 특정 부분을 나타낸다. 알고리즘이 이 객체를 찾을 때 목표 이미지에서 다시 설명자를 찾으려고 할 것이다.

이미지에서 자전거를 찾기 위해 가장 일반적으로 사용되는 기법은 플로팅 윈도우(Floating Window)다. 이미지의 작은 직사각형 영역이 차례로 검사된다. 가장 일치하는 설명자를 가진 부분이 해당 객체를 포함하는 것으로 간주된다.

이 기법은 이미지를 회정하거나 색이 바뀌더라도 성능에 영향을 주지 않고 훈련 데이터가 많이 필요하지 않으며 대부분의 객체에 동작한다. 하지만 정확도는 만족스럽지 않다.

성능은 알고리즘이 다음 항목에서 얼마나 우수한지를 나타낸다.

- 경계 상자 정밀도(Bounding Box Precision): 정확한 경계 상자(너무 크지도, 너무 작지도 않은)를 제공하는가?
- 재현율(Recall): 모든 객체를 찾았는가? (어떤 객체도 놓치지 않았는가?)
- 클래스 정밀도(Class Precision): 객체마다 정확한 클래스를 출력했는가? (고양이를 개로 착각하지 않았는가?)

성능 개선은 모델이 결과를 계산하는 속도가 빨라졌음(특정 입력 이미지에 대해 특정 컴퓨팅 파워로)을 뜻하기도 한다. 초기 모델은 객체를 탐지하는 데 상당한 시간(몇 초보다 오랜 시간)이 걸렸지만, 지금은 실시간으로 사용될 수 있다. 컴퓨터 비전에서 실시간이란 일반적으로 1초에 5개 이상 탐지하는 속도를 뜻한다.

### 모델 성능 평가

#### 정밀도와 재현율
일반적으로 정밀도와 재현율은 객체 탐지 모델 평가에 사용되지 않지만, 다른 지표를 계샇나는 기본 지표 역할을 한다.

정밀도와 재현율을 측정하기 위해서는 먼저 각 이미지에 대해 다음을 계산해야 한다.

- 참긍정 수: 참긍정(True Positive, TP)은 얼마나 많은 예측이 동일 클래스의 실제 상자와 일치하는지 측정한다.
- 거짓긍정 수: 거짓긍정(False Positive, FP)은 얼마나 많은 예측이 동일 클래스의 실제 상자와 일치하지 않는지 측정한다.
- 거짓부성 수: 거짓부정(False Negative, FN)은 얼마나 많은 실제 분류 값이 그와 일치하는 예측을 갖지 못하는지 측정한다.

정밀도(Precision)와 재현율(Recall)은 다음과 같이 정의된다.

precision = TP / (TP + FP)

recall = TP / (TP + FN)

예측이 실제 분류와 정확히 일치하면 거짓긍정이나 거짓부정이 없을 것이다. 따라서 정밀도와 재현율에서 만점은 1이다. 대체로 모델이 안정적이지 않은 특징을 기반으로 객체 존재를 예측하면 거짓긍정이 많아져 정밀도가 낮아진다. 반대로 모델이 너무 엄격해서 정확한 조건을 만족할 때만 객체가 탐지된 것으로 간주한다면 거짓부정이 많아져서 재현율이 낮아질 것이다.

#### 정밀도-재현율 곡선
정밀도-재현율 곡선(Precision-Recall Curve)은 수많은 머신러닝 모델에서 사용된다. 일반적인 개념은 신뢰도 임곗값마다 모델의 정밀도와 재현율을 시각화하는 것이다. 모델은 모든 경계 상자와 함께 모델이 예측의 정확성을 얼마나 확신하는지를 0과 1 사이의 숫자로 나타내는 신뢰도(Confidence)를 출력한다.

신뢰도가 낮은 예측은 유지할 필요가 없으므로 일반적으로 특정 임곗값 T 이하의 예측은 제거한다. 예를 들어 T=0.4라면 이 숫자 이하의 신뢰도를 갖는 예측은 고려 대상에서 제외한다.

임곗값을 바꾸면 정밀도와 재현율도 달라진다.

- T가 1에 가까우면: 정밀도는 높지만 재현율은 낮다. 객체를 많이 걸러내기 때문에 놓치는 객체가 많아져 재현율이 낮아진다. 신뢰도가 높은 예측만 유지하므로 거짓긍정 수가 많지 않아 정밀도는 높아진다.
- T가 0에 가까우면: 정밀도는 낮지만 재현율은 높다. 대부분의 예측을 유지하므로 거짓부정이 없어져 재현율이 높아진다. 모델이 자신의 예측에 대한 확신이 낮기 때문에 거짓긍정이 많아져 정밀도가 낮아진다.

:bulb: 임곗값은 정확도(Accuracy)와 재현율 사이의 트레이드오프를 고려해 정해야 한다. 모델이 보행자를 탐지하고 있다면 때때로 마땅한 이유 없이 차를 세우더라도 어떤 보행자도 놓치지 않도록 재현율을 높여야 한다. 모델이 투자 기회를 탐지하고 있다면 일부 기회를 놓치게 되더라도 잘못된 기회에 돈을 거는 일을 피하기 위해 정밀도를 높여야 한다.

#### AP와 mAP
정밀도-재현 곡선이 모델에 대해 많은 것을 말해줄 수 있지만, 대체로 하나의 숫자로 이해하는 것이 더 편리하다. AP(Average Precision, 평균 정밀도)는 곡선의 아래 영역에 해당한다. 이 영역은 항상 1 * 1 정사각형으로 구성되므로 AP는 항상 0에서 1 사이의 값을 갖는다.

AP는 단일 클래스에 대한 모델 성능 정보를 제공한다. 전역 점수를 얻기 위해 mAP(Mean Average Precision)를 사용한다. 이는 각 클래스에 대한 AP의 평균에 해당한다. 데이터셋이 10개의 클래스로 구성된다면 각 클래스에 대한 AP를 계산하고 다시 그 숫자의 평균을 구한다.

:bulb: mAP는 최소 2개 이상의 객체를 탐지하는 대회인 PASCAL Visual Object Classes(일반적으로 Pascal VOC라고도 함)와 Common Objects in Context(일반적으로 COCO라고 함)에서 사용된다. COCO 데이터셋이 더 크고 많은 클래스를 포함하고 있으므로 여기에서 얻는 점수는 Pascal VOC보다 더 낮다.

#### AP 임곗값
TP과 FP가 실제 상자와 일치하거나 일치하지 않는 예측 개수에 의해 정의된다고 설명했다. 그렇지만 예측과 실제가 언제 일치하는지 어떻게 결정할까? 일반적으로 두 집합(여기에서는 상자로 표현되는 픽셀 집합)이 얼마나 겹치는지 측정하는 자카드 지표(Jaccard Index)를 메트릭으로 사용한다. IoT(Intersection over Union)라고도 알려진 이 지표는 다음과 같이 정의된다.

IoU(A, B) = | intersection(A, B) | / | union(A, B) | = | intersection(A, B) | / (|A| +|B| - | intersection(A, B)|)

|A|와 |B|는 각 집합의 카디널리티(Cardinality)로, 각 집합이 포함한 요소의 개수를 말한다. intersection(A, B)는 두 집합의 교집합으로 분자 |intersection(A, B)|는 두 집합이 공통으로 갖고 있는 요소 개수를 나타낸다. 마찬가지로 union(A, B)는 두 집합의 합집합으로 분모 |union(A, B)|는 두 집합이 함께 가지고 있는 전체 요소 개수를 나타낸다.

교집합은 두 집합/상자가 얼마나 겹치는지를 보기에는 좋은 지표지만, 이 값은 절대적인 수치일 뿐 상대적이지 않다. 따라서 두 개의 큰 상자가 아마 두 개의 작은 상자보다 훨씬 많은 픽셀이 겹칠 것이다. 그렇기 때문에 이 비율을 사용한다. 이 비율은 항상 0(두 상자가 전혀 겹치지 않는 경우)과 1(두 상자가 완전히 겹치는 경우) 사이의 값을 갖는다.

AP를 계산할 때 IoU가 특정 임곗값을 넘으면 두 상자가 겹친다고 말한다. 일반적으로 이 임곗값은 0.5로 정한다.

:bulb: Pascal VOC 대회에서도 0.5를 사용하며 mAP@0.5라고 부른다. COCO 대회에서는 약간 다른 지표로 mAP@[0.5:0.95]를 사용한다. 이는 mAP@0.5, mAP@0.95를 계산해 평균을 구한다는 뜻이다. IoU를 평균하면 모델의 위치 측정 성능이 좋아진다.

## 빠른 객체 탐지 알고리즘 - YOLO
최신 버전은 YOLOv3은 크기가 256x256인 이미지에 대해 최신 GPU에서 초당 170프레임(170FPS, frames per second)의 속도로 실행될 수 있다.

### YOLO 소개
2015년에 최초로 공개된 YOLO는 속도와 정확도 측면 모두에서 거의 모든 객체 탐지 아키텍처를 능가했다. 그 이후로 이 아키텍처는 몇 차례 개선됐다.

- You Only Look Once: Unified, real-time object detection (2015), Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhad
- YOLO9000: Better, Faster, Stronger (2016), Joseph Redmon, Ali Farhadi
- YOLOv3: An Incremental Improvement (2018), Joseph Redmon, Ali Farhadi

:bulb: YOLO 논문의 1저자는 다크넷(Darknet)이라는 딥러닝 프레임워크를 관리한다. 이 프레임워크는 YOLO의 공식 구현을 제공하고 있어 논문의 결과를 재현하는 데 사용될 수 있다. 이 코드는 C++로 구현됐으며 텐서플로를 기반으로 하지 않는다.

#### YOLO의 강점과 한계

#### YOLO의 주요 개념

### YOLO로 추론하기

#### YOLO 백본

#### YOLO의 계층 출력

#### 앵커 박스 소개

#### YOLO가 앵커 박스를 개선하는 방법

#### 상자를 사후 처리하기

#### NMS

#### YOLO 추론 요약

### YOLO 훈련시키기

#### YOLO 백본 훈련 방법

#### YOLO 손실

##### 경계 상자 손실

##### 객체 신뢰도 손실

##### 분류 손실

##### 전체 YOLO 손실

#### 훈련 기법

## Faster R-CNN - 강력한 객체 탐지 모델

### Faster R-CNN의 일반 아키텍처

#### 1단계 - 영역 제안

#### 2단계 - 분류

##### Fast R-CNN 아키텍처

##### RoI 풀링

### Faster R-CNN 훈련

#### RPN 훈련시키기

#### RPN 손실

#### Fast R-CNN 손실

#### 훈련 계획

### 텐서플로 객체 탐지 API

#### 사전 훈련된 모델 사용하기

#### 맞춤 데이터셋에서 훈련하기

## 요약

## 질문

## 참고 문헌

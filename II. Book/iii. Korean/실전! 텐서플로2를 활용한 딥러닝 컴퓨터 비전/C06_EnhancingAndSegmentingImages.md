# 06 이미지 보강 및 분할

- 인코더-디코더 개념과 픽셀-수준의 예측을 위해 훈련시키는 방법
- 고차원 데이터를 출력하기 위해 인코더-디코더에서 어떤 신규 계층(언풀링, Unpooling, 전치합성곱, Transposed Convolutions, 아트루스 합성곱, Atrous Convolutions)을 사용하는가
- FCN과 U-Net 아키텍처는 어떻게 의미론적 분할을 해결하는가
- 지금까지 알아본 모델이 인스턴스 분할을 다루기 위해 어떻게 확장될 수 있는가

## 기술 요구사항

## 인코더-디코더로 이미지 변환

### 인코더-디코더 소개

#### 인코딩과 디코딩
이 프레임워크는 인코더는 입력 샘플을 잠재 공간, 즉 인코더에 의해 정의된 숨겨둔 구조화된 값 집합에 매핑하는 함수다. 디코더는 이 잠재 공간의 요소를 사전 정의된 타깃 도메인으로 매핑하는 여함수다. 예를 들어 인코더는 미디어 파일을 파싱하기 위해 생성되고(콘텐츠는 잠재 공간의 요소로 표시됨), 가령 미디어 콘텐츠를 다른 파일 포맷으로 출력하도록 정의된 디코더와 쌍을 이룰 수 있다. 잘 알려진 예로는 오늘날 보편적으로 사용하는 이미지와 오디오 압축 포맷을 들 수 있다. JPEG 도구는 미디어 파일을 보다 가벼운 이진 파일로 압축하여 인코딩하고, 표시할 때 픽셀 값을 복원하기 위해 디코딩한다.

머신러닝에서 인코더-디코더 네트워크는 오랫동안 사용돼 왔다(예: 텍스트 번역). 인코더 네트워크는 출발어(source language)의 문장을 입력으로 취하고(예: 프랑스어 문장), 문장의 의미가 특징 벡터로 인코딩된 잠재 공간으로 이 문장을 투사하는 것을 학습한다. 디코더 네트워크는 인코딩된 벡터를 도착어(target language, 예: 영어 번역)의 문장으로 변환하기 위해 인코더와 함께 훈련된다.

:bulb: 인코더-디코더 모델에서 잠재 공간의 벡터를 일반적으로 코드(code)라고 한다.

#### 오토인코딩
오토인코더(Auto-encoder, AE)는 특수한 유형의 인코더-디코더다. 오토인코더의 입력과 타깃 도메인이 동일해서 이 모델의 병목 계층(저차원의 잠재 공간)에도 불구하고 적절하게 인코딩한 다음 품질에 영향을 주지 않고 이미지를 디코딩하는 것을 목표로 한다. 입력은 압축된 표현(특징 벡터)으로 줄어든다. 원본 입력이 나중에 요청되면 디코더에 의해 압축된 표현으로부터 재구성될 수 있다. 

:bulb: 오토인코더와 관련해 머신러닝 전문가들의 의견이 나뉜다. 일부는 이 모델이 비지도 학습이라고 주장하는데, 훈련에 추가 레이블이 필요하지 않기 때문이다. 다른 전문가들은 순수 비지도 기법(전통적으로 레이블이 없는 데이터셋에서 패턴을 발견하기 위해 복잡한 손실 함수를 사용하는)과는 다르며 AE에는 명확하게 정의된 타깃(즉, 입력 이미지)이 있다고 주장한다. 따라서 이 모델을 자기 지도 학습(Self-Supervised Learning)이라고도 한다(즉 이 모델의 타깃이 입력에서 직접 파생될 수 있다).

:bulb: 병목 조건을 제외하면 이 항등 매핑은 ResNet 같은 숏컷 경로가 있는 네트워크에서 간단하다. 인코더에서 디코더로 전체 입력 정보를 전달하기만 하면 된다. 저차원 잠재 공간(병목)을 사용하면 이 너트워크는 적절히 압축된 표현을 학습해야 한다.

#### 목적

### 기본 예제 - 이미지 노이즈 제거

#### 간단한 완전 연결 오토인코더

#### 이미지 노이즈 제거에 적용

### 합성곱 인코더-디코더

#### 언풀링, 전치, 팽창
전치 합성곱(Transposed Convolution, 디컨볼루션, Deconvolution), 팽창된 합성곱(Dilated Convolution), 언풀링(Unpooling)

##### 전치 합성곱(디컨볼루션)
형상이 (H, W, D)인 텐서 입력에 대해 출력 형상(H_o', W_o', N)을 평가하기 위해 다음 공식을 이용했다(커널 크기 k, 입력 깊이 D, 커널 개수 N, 패딩 p, 보폭 s).

H_o = (H - k + 2p) / s + 1

W_o = (W - k + 2p) / s + 1

이제 합성곱의 공간 변환을 역으로 수행하는 계층을 개발해야 한다고 가정하자. 다른 말로, 형상이 (H_o', W_o', N)인 특징 맵과 동일한 초매개변수 k, D, N, p, s가 주어졌을 때 형상이 (H, W, D)인 텐서를 복원하기 위해 합성곱과 유사한 연산이 필요하다. 이전 공식의 H와 W를 따로 분리해 보면 다음 속성을 유지하는 연산이 필요하다.

H = (H_o - 1) * s + k - 2p

W = (W_o - 1) * s + k - 2p

이것이 전치 합성곱이 정의된 방식이다. 이 새로운 유형의 계층은 ILSVRC 2013에서 우승한 기법인 ZFNet(Visualizing and Understanding Convolutional Networks)을 개발한 연구원인 매튜 제일러(Matthew Zeiler)와 롭 퍼거스(Rob Fergus)에 의해 제안됐다.

이 계층은 k * k * D * N 커널 스택을 사용해 H_o * W_o * N 텐서에 합성곱을 적용해 H * W * D 맵으로 변환한다. 이를 달성하기 위해 먼저 입력 텐서는 팽창(Dilation) 과정을 거쳐야 한다. 비율 d에 의해 정의된 팽창 연산은 입력 텐서의 행과 열의 쌍에서(개별적으로) d-1개의 0으로 채워진 행과 열을 추가하는 것으로 구성된다. 전치 합성곱에서 팽창 비율은 s(전치 합성곱이 반전시킨 표준 합성곱에서 사용된 보폭)로 설정된다. 이 재표본 추출 후에는 텐서는 p' = k - p - 1에 의해 패딩된다. 팽창과 패딩 매개변수는 모두 원본 형상 (H, W, D)를 복원하기 위해 그렇게 정의된다. 그런 다음 보폭 s'=1을 사용해 실제 텐서를 해당 계층의 필터와 합성곱을 수행하고 그 결과 H * W * D 맵을 얻게 된다.

:bulb: 컨볼루션 레이어에서 패치와 커널 사이에 실제로 일어나는 수학 연산은 교차 상관관계다.

:bulb: 디컨볼루션 레이어에서 패치와 커널 사이에 적용되는 연산은 수학적 합성곱이다.

이 프로세스가 다소 추상적으로 보일 수 있지만, 전치 합성곱 계층은 일반적으로 표준 합성곱 계층을 반전시켜 특징 맵의 콘텐츠와 훈련 가능한 필터 사이의 합성곱을 통해 특징 맵의 공간 차원을 증가시키기 위해 사용된다는 점만 기억해도 충분하다. 따라서 이 계층은 디코더 아키텍처에 상당히 부합한다. 전치 합성곱 계층은 tf.layers.conv2d_transpose()와 tf.keras.layers.Conv2DTranspose()를 사용해 인스턴스화될 수 있으며, 이 둘은 표준 conv2d 계층으로 동일한 시그니처를 갖는다.

:bulb: 표준 합성곱과 전치 합성곱 사이에는 실제로는 아무 영향이 없지만 알아두면 좋을 또 다른 미묘한 차이가 있다. CNN에서 합성곱 계층은 실제로는 교차 상관관계를 수행한다. 전치 합성곱 계층은 커널 인덱스를 거꾸로 하여 수학적 합성곱 연산을 사용한다. 전치 합성곱은 잘못된 명칭이기는 하지만 일반적으로 디컨볼루션이라고도 한다. '디컨볼루션'이라는 이름의 수학 연산이 있지만, 이는 전치 합성곱과는 다르다. 디컨볼루션은 실제로 합성곱을 완전히 되돌려 원본 텐서를 반환한다. 전치 합성곱은 이 절차와 거의 비슷해 원본과 형상이 같은 텐서를 반환할 뿐이다. 원본 텐서와 마지막 결과 텐서의 형상이 일치하지만, 그 값까지 동일하지는 않다. 경우에 따라 전치 합성곱을 보폭을 1 이하로 적용하는 합성곱(fractionally stride convolutions)라고도 한다. 실제로 입력 텐서의 팽창은 합성곱에 1 이하의 보폭을 사용하는 것과 동일하다고 볼 수 있다.

##### 언풀링
보폭이 적용된 합성곱이 CNN 아키텍처에 종종 사용된다면 이미지의 공간 차원을 축소하기 위해 가장 보편적으로 사용되는 연산은 평균-풀링과 최대-풀링이다. 따라서 제일러와 퍼거스도 최대-풀링을 유사-반전하기 위해 최대-언풀링 연산(종종 언풀링으로만 부른다)을 제안했다. 이들은 deconvnet이라고 하는 네트워크 내에서 이 연산을 사용해 'convnet'(즉, CNN)을 특징을 디코딩하고 시각화했다. ILSVRC 2013에서 우승한 뒤 이들의 솔루션을 설명하는 논문(Visualizing and Understanding Convolutional Networks)에서 최대-풀링이 역으로 뒤집을 수 없지만(즉 수학적으로 최대-풀링에서 폐기한 비최댓값들을 모두 복원할 수 없지만) 최소한 공간 샘플링 관점에서 그에 가깝게 연산을 정의할 수 있다고 설명했다.

이 유사-역연산을 구현하기 위해 먼저 각 최대-풀링 계층을 수정해 결과 텐서를 따라 풀링 마스크를 출력한다. 다시 말해서 이 마스크는 선택된 최댓값의 원래 위치를 가리킨다. 최대-언풀링 연산은 풀링된 텐서(이 텐서는 그 사이에 다른 형상 보존 연산을 거쳤을 수도 있다)와 풀링 마스크를 취한다. 이 연산은 풀링 마스크를 사용해 입력 값을 풀링되기 전의 형상으로 업스케일링된 텐서에 뿌린다. 풀링 계층처럼 언풀링 연산은 고정된/훈련할 수 없는 연산이다.

##### 업샘플링과 크기 조정
마찬가지로 평균-언풀링 연산은 평균-풀링 연산을 반전시키기 위해 개발됐다. 평균-풀링 연산은 k * k개의 요소를 갖는 풀링 영역을 위해 그 요소 값의 평균을 내 단일 값으로 만든다. 따라서 평균-언풀링 계층은 텐서의 각 값을 취해 이를 k * k 영역으로 복제한다. 평균-언풀링 연산이 최대-언풀링 연산보다 더 자주 사용되지만, 더 일반적으로는 업샘플링(Upsampling)으로 알려져 있다. 예를 들어 이 연산은 tf.keras.layers.UpSampling2D()를 통해 인스턴스화될 수 있다. 이 메서드 자체로는 최근접 이웃 보간법(이름이 뜻하는 대로)을 사용해 이미지 크기를 조정하기 위해 method=tf.image.ResizeMethod.NEAREST_NEIGHBOR 인수로 호출될 때는 tf.image.resize()의 래퍼 함수일 뿐이다. 마지막으로 경우에 따라 훈련시킬 매개변수를 추가하지 않고 특징 맵을 업스케일링 하기 위해, 예를 들어 interpolation="bilinear"(기본값인 "nearest" 대신) 인수를 사용해 tf.keras.layers.UpSampling2D()를 인스턴스화함으로써 양선형 보간법도 사용된다. 이는 기본 속성인 method=tf.image.ResizeMethod.BILINEAR를 사용해 tf.image.resize()를 호출하는 것과 동일하다.

디코더 아키텍처에서 최근접 이웃 방식이나 양선형 방식 뒤에는 일반적으로 보폭이 s=1이고 패딩 옵션이 "SAME"(새 형상을 보존하기 위해)인 합성곱 계층이 따른다. 사전에 업스케일링과 합성곱 연산의 조합은 인코더를 구성하는 합성곱과 풀링 계층을 반전시킴으로써 디코더가 자신만의 특징을 학습해 타깃 시그널을 더 잘 복원할 수 있게 한다.

:bulb: 아우구스투스 오데나(Augustus Odena) 같은 일부 연구원들은 특히 이미지 해상도 개선과 같은 작업에서 전치 합성곱보다 이 연산을 주로 사용한다. 사실 전치 합성곱을 사용하면 바둑판 아티팩트가 생겨서(커널 크기가 보폭의 배수가 아닐 떄 특징이 서로 겹쳐서) 출력 품질에 영향을 주는 경향이 있다(Deconvolution and Checkerboard artifacts).

##### 팽창된/아트루스 합성곱
이 연산은 제공된 특징 맵을 업샘플링하는 용도로 쓰이지 않는다. 대신 이 연산은 데이터의 공간 차원을 더 희생시키지 않고 합성곱의 수용 영역을 인위적으로 증가시키기 위해 제안된다. 이를 달성하기 위해 상당히 다른 방식이긴 하지만 여기에도 팽창(Dilation) 연산이 적용된다.

사실 팽창된 합성곱(Dilated Convolution)은 추가적으로 커널에 적용될 팽창률을 정의하는 초매개변수가 있다는 점을 제외하면 표준 합성곱이랑 비슷하다. 

:bulb: 이 계층을 프랑스어로 '구멍이 난'이라는 뜻인 atrous에서 따온 아트루스 합성곱이라고도 한다. 실제로 커널 팽창률이 수용 영역을 증가시키지만, 수용 영역에 구멍을 만들어 증가시키기 때문이다.

이러한 속성을 갖춘 이 연산은 현대 인코더-디코더에서 한 도메인의 이미지를 다른 도메인으로 매핑하기 위해 자주 사용된다. 텐서플로와 케라스에서 팽창된 합성곱을 인스턴스화하려면 tf.layers.conv2d()와 tf.keras.layers.Conv2D()에서 dilation_rate 매개변수에 기본 값인 1 이상의 값을 제공하기만 하면 된다.

특징 맵의 공간성을 보존하거나 증가시키기 위해 개발된 이 다양한 연산들 때문에 픽셀 단위의 밀집된 예측과 데이터 생성을 위한 다양한 CNN 아키텍처가 만들어졌다.

#### 대표적인 아키텍처 - FCN과 U-Net
2015년에 출시된 FCN과 U-Net 모델은 여전히 인기가 많고 일반적으로 더 복잡한 시스템(의미론적 분할, 도메인 적응 등)을 위한 구성 요소로 사용된다.

##### FCN(Fully Convolutional Networks)
FCN(Fully Convolutional Networks)은 VGG-16 아키텍처에 기반해 마지막 밀집 계층을 1 * 1 합성곱 계층으로 대체해 구성된다. 여기에서 언급하지 않은 것은 이 네트워크가 일반적으로 업샘플링 블록을 사용해 확장되어 인코더-디코더로 사용된다는 점이다. 캘리포니아 대학교 버클리의 조나단 롱(Jonathan Long), 에반 셸하머(Evan Shelhamer), 트레버 대럴(Trevor Darrell)이 제안한 FCN 아키텍처는 앞에서 고안한 개념을 완벽하게 보여준다.

- 특징 추출을 위한 CNN을 효율적인 인코더로 사용할 수 있는 방법
- 그 다음 방금 소개한 연산을 사용해 CNN의 특징 맵을 효율적으로 업샘플링하고 디코딩하는 방법

사실 조나단 롱 팀은 사전 훈련된 VGG-16을 특징 추출기로 재사용할 것을 제안했다. VGG-16은 5개의 합성곱 블록을 사용해 이미지를 효율적으로 특징 맵으로 변환하지만 매 블록 다음에 공간 차원을 반으로 나눈다. 마지막 블록의 특징 맵을 디코딩하기 위해(예를 들어 의미론적 마스크로) 분류를 위해 사용되던 완전 연결 계층을 합성곱 계층으로 대체한다. 그런 다음 최종 계층으로 데이터를 입력 형상으로 업샘플링하기 위한 전치 합성곱을 적용한다(즉, VGG를 통해 공간 차원이 32로 나눠졌기 때문에 보폭을 s=32로 설정).

그렇지만 롱은 FCN-32s라는 이 아키텍처가 너무 조악한 결과를 낸다는 사실을 곧 깨달았다. 논문에서 설명했듯이(Fully Convolutional Networks for Semantic Segmentation), 최종 계층의 보폭이 크면 세부 사항의 크기를 제한한다. 마지막 VGG 블록의 특징에 풍부한 컨텍스트 정보를 포함하고 있더라도 공간을 정의하는 정보 대부분은 유실됐다. 그래서 저자는 마지막 블록의 특징 맵을 이전 블록의 더 큰 특징 맵과 결합하는 방법을 고안했다.

그에 따라 FCN-16s에서는 FCN-32s의 마지막 계층이 보폭 s=2밖에 되지 않는 전치 계층으로 대체돼 결과 텐서가 네 번째 블록의 특징 맵과 동일한 차원을 갖게 된다. 스킵 연결(skop connection)을 사용해 두 텐서에서 나온 특징이 서로 합쳐진다(요소-단위 덧셈). 마지막으로 이 결과를 s=16인 또 다른 전치 합성곱을 사용해 입력 형상으로 크기를 되돌린다. FCN-8s에서는 동일한 절차가 반복되는데, 대신 결과 텐서가 세 번째 블록의 특징과 같은 차원을 갖게 되며 마지막 전치 합성곱에서 보폭은 s=8을 사용한다. FCN-32s와 FCN-16s가 단 하나의 스킵 연결이 있거나 그마저도 없는 단순하고 가벼운 아키텍처임을 강조한다.

FCN-8s는 전치 학습을 사용하고 다양한 크기의 특징 맵을 결합함으로써 세부적인 부분까지 자세히 드러나는 이미지를 출력할 수 있다. 게다가 FCN의 본질 때문에 다양한 크기의 이미지를 인코딩/디코딩하는 데 FCN-8s를 적용할 수 있다. 성능이 뛰어나고 다재다능한 FCN-8s는 여러 다른 아키텍처에도 영감을 주면서 여전히 수많은 애플리케이션에서 보편적으로 사용된다.

##### U-Net

#### 중간 예정 - 이미지 해상도 개선

##### FCN 구현

##### 이미지 업스케일링에 적용

## 의미론적 분할 이해하기
의미론적 분할(Semantic Segmentation)은 이미지를 의미 있는 부분으로 분할하는 작업을 지칭하는 좀 더 포괄적인 용어다. 객체 분할과 인스턴스 분할을 모두 아우른다. 이미지 분류와 객체 탐지와는 달리, 분할 작업에는 밀도 높은 픽셀 단위의 예측을 반환하는, 즉 입력 이미지의 각 픽셀마다 레이블을 할당하는 기법이 필요하다.

### 인코더-디코더를 사용한 객체 분할

#### 개요

##### 레이블 맵으로 디코딩하기

##### 분할 손실과 지표를 사용해 훈련하기

##### 조건부 랜덤 필드로 후처리

#### 고급 예제 - 자율 주행 자동차를 위한 이미지 분할

##### 작업 설명
자율 주행 자동차는 사람처럼 환경을 이해하고 주변을 둘러싼 요소들을 인지해야 한다. 전방 카메라로부터 유입되는 동영상 이미지에 의미론적 분할을 적용함으로써 시스템은 다른 자동차가 주변에 있는지 또는 보행자나 자전거가 길을 건너고 있지는 않은지를 알 수 있고 차선과 교통 신호를 지킬 수 있다.

##### 대표적인 솔루선

### 더 까다로운 인스턴스 분할

#### 객체 분할에서 인스턴스 분할까지

##### 경계를 고려하기

##### 사후 처리를 통해 인스턴스 마스크로 변환

#### 객체 탐지부터 인스턴스 분할까지 - Mask R-CNN

##### 의미론적 분할을 경계 상자에 적용하기

##### Faster R-CNN으로부터 인스턴스 분할 모델 구성하기

:bulb: 카이밍 히는 ResNet과 Faster R-CNN의 주 저자이다.

## 요약
픽셀 단위의 정확도를 필요로 하는 애플리케이션을 위한 다양한 패러다임을 다뤘다. 인코더-디코더와 일부 특수 아키텍처를 소개했고 이를 이미지 노이즈 제거에서 의미론적 분할에 이르기까지 여러 작업에 적용해 봤다. 또한 인스턴스 분할처럼 진화된 문제를 해결하기 위해 다양한 솔루션을 결합하는 방법도 보여줬다.

점점 더 복잡한 작업을 해결할수록 새로운 도전 과제들이 등장한다. 예를 들어 의미론적 분할의 경우 모델을 훈련시키기 위해 이미지에 정확하게 주석을 다는 일은 시간이 많이 걸린다. 따라서 활용할 수 있는 데이터셋은 부족하기 때문에 과적합을 피하기 위해 특별한 측정 기준이 필요하다. 게다가 훈련 이미지와 해당 이미지의 실제 정보가 더 무겁기 때문에 효율적인 훈련을 위해서는 잘 설계된 데이터 파이프라인이 필요하다.

## 질문

## 참고 문헌

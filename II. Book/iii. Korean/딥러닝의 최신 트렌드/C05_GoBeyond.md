# Chapter 05 딥러닝의 한계를 뛰어넘는 최신 기술
## 01 메타 학습 (Meta-Learning)
### 메타 학습의 개념

### 메타 최적화 학습 (Meta Optimizer Learning)

### 모델에 자유로운 메타 학습 (Model-Agnostic Meta Learning, MAML)
Meta Congnition, Learning to Learn, Meta Optimizer Learning, Meta Loss, Model-Agnostic Meta Learning(MAML), Model-Agnostic, MAML

## 02 원샷 학습 (One-Shot Leanring)
### 원샷 학습의 개념

### 원샷 학습의 기본 '웨이 (Way)와 샷 (Shot)'

### 원샷 학습의 과정

### 원샷 학습의 한계와 전망
Way, Shot, Few-Shot Learning, Pre-Trained Network, Feature, Zero-Shot, Similarity Function, Clustering Algorithm

## 03 지속적인 학습 (Continual Learning)
### 지속적인 학습의 의미

### 인공신경망과 치명적 망각

### 생성 모델을 활용하 지속적인 학습

### 동적으로 확자 가능한 인공신경망(Dynamically Expandable Network, DEN)
Catastrophic Forgetting, Elastic Weight Consolidation (EWC), Dynamically Expandable Network (DEN)

## 04 신경망 구조 탐색 (Neural Architecture Search)
### 신경망 구조 탐색의 개념

### 신경망 구조 탐색의 과정

### 신경망 구조 탐색의 응용 (AutoML)
Hyper-Parameter, AutoML

## 05 스파이킹 신경망 (Spiking Neural Network)
### 스파이킹 신경망의 개념

### 스파이크와 스파이크 트레인

### 스파이킹 신경망의 비지도 학습

### 스파이킹 신경망의 지도 학습
Neuron, Spike, Spike Train, Layer-Wise, Synaptic Timing Dependent Plasticity (STDP), Gradient-Descent Method, Firing, Fire

## 06 활성 학습 (Active Learning)
### 활성 학습의 개념

### 활성 학습과 불확실성
Uncertainty, 활성 학습은 이러한 문제를 해결하기 위해 라벨이 주어지지 않은 데이터에 자동으로 라벨을 붙일 수 있도록 고안된 방법이다.

## 07 그래프 신경망 (Graph Neural Network)
### 그래프의 기본 개념

### 그래프 신경망의 개념

### 그래프 신경망의 연구 동향
Vertex, Edge, Attribute, Node, Invariance, 인공신경망으 입력 값을 선정함에 있어 그 순서에도 영향을 받는다.

## 08 메모리 네트워크 (Memory Network)
### 메모리 네트워크의 개념

### 메모리 네트워크의 구조

### 종단간 (End-to-End) 메모리 네트워크
Long-Term Dependency, Question & Answer, Input Feature Map, Generalization, Output, Response, Supporting Fact, Embedding, IGOR

## 09 뉴럴 튜링 머신 (Neural Turing Machine)
### 뉴럴 튜링 머신의 개념

### 뉴럴 튜링 머신의 제어기

### 주소 지정 메커니즘
Alan Turing, Controller, Read Head, Write Head, Addressable Memory, Turing-Complete, Differentiable Neural Computer, Content Addressing, Interpolation, Convolutional Shift, Sharpening

## 10 BERT 모델
### 자연어 처리 알고리즘의 성능

### BERT 구조의 개념적 이해

### BERT의 학습 방법과 결과
Bidrectional Encoder Representations from Transformer, BERT, Fine-Tuning, Masked Language Model, Pre-Trained, korBERT, MNLI, QQP. QNLI, SST-2, CoLA, STS-B, MRPC, RTE, SQuAD v1.1, SQuAD v2.0, SWAG, Google

## 11 생성적 사전 학습 모델
### GPT의 개념

### GPT-2 (재학습 과정이 없는 언어 모델)

### GPT-3 (퓨삿 학습을 통한 성능 향상)
OpenAI, Generative Pre-Training, GPT, Semi-Supervised Learning, Fine-Tuning, 10, Zero-shot, 100, Few-shot, Language Model, Scale-up

## 12 캡슐 네트워크 (Capsule Network)
### 캡슐 네트워크의 개념

### 캡슐 네트워크의 구조
Entity, Property, Primary Capsule, Dynamic Routing, Reconstruction

## :bulb: 인공지능의 미중 기술 패권

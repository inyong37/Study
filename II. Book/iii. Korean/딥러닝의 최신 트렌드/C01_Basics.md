# Chapter 01 딥러닝의 기본
## 01 퍼셉트론(Perceptron)과 엣지(Edge)
### 인공신경망의 기본 구성 요소

### 인공 신경 세포인 퍼셉트론

### 퍼셉트론을 연결하는 엣지

### 퍼셉트론과 엣지의 다양한 표현

## 02 인공신경망(Artificial Neural Network)
### 퍼셉트론의 진화

### 인공신경망의 구조

### 은닉층의 내용과 역할

## 03 손실 함수(Loss Function)
### 손실 함수의 개념

### 손실의 계산

### 다양한 손실 함수

## 04 학습 과정
### 학습의 개념

### 학습 방법의 종류

### 학습의 과정

## 05 딥러닝의 부상
### 빅 데이터의 출현

### 딥러닝의 출현

## 06 심층신경망(Deep Neural Network)
### 심층신경망의 의미

### 심층신경망의 활용 예시

### 심층신경망의 최적화

## 07 합성곱신경망(Convolutional Neural Network)
### 합성곱의 의미

### 합성곱신경망의 구조적 특징

### 합성곱신경망의 활용

## 08 순환신경망(Recurrent Nerual Network)
### 순환신경망의 개념

### 순환신경망의 구조

### 순환신경망의 활용

## 09 적대적생성신경망(Generative Adversarial Network)
### 적대적생성신경망의 개념

### 적대적생성신경망의 구조와 학습 과정

### 적대적생성신경망의 활용

## 10 강화 학습(Reinforcement Learning)
### 강화 학습의 개념

### 심층 Q학습(Deep Q-Learning)

### 강화 학습의 활용

## 11 어텐션 메커니즘(Attention Mechanism) :star:
### 어텐션 메커니즘의 개념
어텐션 매커니즘은 칵테일 파티 효과로 쉽게 설명할 수 있다. 칵테일 파티 효과는 수많은 대화가 오고가는 혼잡한 상황에서 특정 대화에 집중한다는 것이다. 예를 들면 자신의 관심사나 자신의 이름이 언급되는 상황을 주로 듣게 되는데, 이것은 사람의 인지 과정이 특정 정보에 집중한다는 것을 의미한다. 이러한 현상이 인지 과학과 심리학에서 파생된 어텐션 매커니즘이다. 인공지능에 대한 성능은 사람의 지능적인 능력과 비교되기 때문에 사람의 인지 구조를 역으로 구현하는 것은 자연스러운 접근 방법이다. 인공신경망은 이러한 입장에 따라 신경 세포의 구조를 모사한 것인데, 어텐션 메커니즘 역시 사람의 인지 구조를 구현하기 위한 노력이라고 볼 수 있다.

### 어텐션 메커니즘의 구조
어텐션 메커니즘의 핵심은 '어디를 집중적으로 볼 것인가'를 구현하는 것이다. 한글을 영어로 번역하는 기계 번역에서 '사과'라는 한글 단어의 영어 번역을 'apple'이라고 가정하자. 그렇다면 '사과'를 'apple'로 번역하기 위해 문장에서 주목해야 할 단어를 찾는 것이 바로 어텐션이다. 어텐션 역시 일종의 확률 분포로 생각할 수 있는데, 이것은 '사과'라는 단어를 번역하기 위해 확률적으로 집중하는 부분을 나타낸다고 볼 수 있다. 어텐션 메커니즘은 시계열 데이터를 처리하는 순환신경망에 활용되면서 어텐션 모수(Parameter)로 표현된다. 이런 어텐션 모수를 추정하기 위해 소규모 인공신경망이 활용된다. 인공신경망은 수학적으로 매우 복잡한 비선형 함수를 근사할 수 있는 방법론으로 분포(Distribution)를 예측하는데 활용할 수 있다.

### 어텐션 메커니즘의 예시
어텐션 메커니즘은 기계 번역의 성능을 개선하는 기술로 주목받았다. 최근 구글, 네이버를 비롯한 검색 포털의 번역 서비스가 괄목할만한 성장을 한 이유도 어텐션 메커니즘의 출현으로 해석할 수 있다. 어텐션 메커니즘의 또 다른 사례는 이미지 설명이다. 해당 기술은 이미지의 객체와 환경을 설명하는 것으로 인공지능 시스템이 상황을 묘사하기 위해 활용된다. 이미지 설명에서의 어텐션 메커니즘은 주목하고자 하는 이미지의 영역을 변화하는 방법론이다. 그 밖에 스타크래프트의 인공지능인 알파스타에서도 어텐션 메커니즘이 활용되었는데 이는 게임 공간에서 어느 곳을 주목해서 보아야 할지의 여부를 구현하는 것으로 이해할 수 있다.

### 어텐션 메커니즘의 기술
어텐션 메커니즘은 현상을 예측하는데 있어서 어느 부분을 주목해야 할 것인지를 구현하는 기술이다.

어텐션 모델은 일반적으로 확률 분포인데, 해당 모델에서 주목해야 할 부분을 추출하는 과정은 인공신경망으로 구현할 수 있다.

추가 데이터는 이미지, 오디오, 텍스트 등 다양한 형태로 주어질 수 있으며, 어디에 집중할 것인지에 대한 단서를 제공한다. 추가 데이터가 없는 경우에는 인공신경망으로 추출된 데이터의 특성이 어텐션 모델의 입력으로 들어간다. 

### 어텐션 메커니짐의 구조적 특성
기계 번역에 활용되는 인공신경망은 양방향 순환신경망으로 순방향과 역방향의 은닉 상태가 존재한다. 은닉 상태는 입력 데이터를 수치화한 특성으로 볼 수 있고, 어텐션 모수는 출력값을 계산하기 위해 주목해야 할 은닉 상태가 어떤 것인지를 결정한다. 예를 들어 '사과를'에 해당하는 번역인 'apple'을 강조하기 위해 해당 parameter가 높은 값으로 나오도록 학습하는 것이 인공신경망 기반의 어텐션 메커니즘이다. 어텐션 모수는 출력값에서 파생되는 상태와 입력값의 특성인 은닉 상태에 따른 분포로 결정되는데, 이런 분포를 근사하기 위해 인공신경망을 활용한다.

## 딥러닝의 3대 석학 :bulb:
2015년 Natuer에 Deep Learning을 주제로 논문을 게재한 딥러닝의 3대 석학은 토론토 대학교의 제프리 힌튼 교수, 뉴욕 대학교의 얀 르쿤 교수, 몬트리올 대학교의 요슈아 벤지오 교수이다. 이러한 3대 석학은 2018년 컴퓨터 과학의 노벨상인 튜링상을 수상하여 그 업적을 인정받았다.

### 토론토 대학교 제프리 힌튼 교수
1986년에 Backpropagation, 2006년에 Deep Belief Network를 제안하였다.

### 뉴욕 대학교 얀 르쿤 교수
1989년에 최초로 CNN을 사용한 LeNet을 제안하였다.

### 몬트리올 대학교 요슈아 벤지오 교수
Deep Learning 책을 저술했으며, 이안 굿펠로우와 함께 GAN을 제안하고, Machine Translation, Word Embedding, Natural Language Processing 분야에서 최고의 석학으로 인정받고 있다.
